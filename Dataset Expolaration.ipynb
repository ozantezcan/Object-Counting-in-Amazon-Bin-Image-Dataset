{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_red = pd.read_csv(\"./dataset/ordinal/Wine Quality/winequality-red.csv\", sep=';')\n",
    "train_df_white = pd.read_csv(\"./dataset/ordinal/Wine Quality/winequality-white.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  label  \n",
       "0      8.8      6  \n",
       "1      9.5      6  \n",
       "2     10.1      6  \n",
       "3      9.9      6  \n",
       "4      9.9      6  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df_white.copy()\n",
    "columns = list(train_df.columns)\n",
    "columns[-1] = 'label'\n",
    "train_df.columns = columns\n",
    "train_df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,     0.,    20.,   163.,  1457.,  2198.,   880.,\n",
       "          175.,     5.,     0.]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       " <a list of 11 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQFJ6pgRkKSOGQFJ6tj/AkAnTDhxQhtuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f288f184518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label=train_df.label.values\n",
    "plt.hist(label, bins=range(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f39768d2a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAF6CAYAAAD1UEqsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f397c1db278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,c=np.sort(label_ord[sorted_idx]))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f3976846c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHmCAYAAABanLmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIABAhoAAAb8P2Iil4E9SJSCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f397c2023c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>label</th>\n",
       "      <th>label_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  label  label_ord  \n",
       "0      8.8      6          1  \n",
       "1      9.5      6          1  \n",
       "2     10.1      6          1  \n",
       "3      9.9      6          1  \n",
       "4      9.9      6          1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat=train_df.values[:,:-2]\n",
    "\n",
    "#Normalize the features\n",
    "\n",
    "feat_max = np.amax(feat,axis=0)\n",
    "feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "feat=feat*2-1\n",
    "\n",
    "'''feat_mean = np.mean(feat,axis=0)\n",
    "feat_std = np.std(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_mean)/feat_std\n",
    "'''\n",
    "label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "print(np.mean(feat,axis=0))\n",
    "print(np.min(feat,axis=0))\n",
    "print(feat.shape)\n",
    "print(label_ord)\n",
    "\n",
    "fvec=feat.copy()\n",
    "#label=np.eye(num_classes)[label_ord]\n",
    "#print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(7192,)\n",
      "(1000, 32)\n",
      "(7192, 32)\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "test_idx=sorted_idx[np.floor(np.linspace(0,len(label_ord)-1,test_size)).astype(np.int)]\n",
    "train_idx = np.setdiff1d(np.arange(0,len(label_ord)),test_idx)\n",
    "\n",
    "\n",
    "\n",
    "label_ord_test=label_ord[test_idx]\n",
    "label_ord_train=label_ord[train_idx]\n",
    "#label_test=np.eye(num_classes)[label_ord_test]\n",
    "#label_train=np.eye(num_classes)[label_ord_train]\n",
    "fvec_test=fvec[test_idx,:]\n",
    "fvec_train=fvec[train_idx,:]\n",
    "\n",
    "print(label_ord_test.shape)\n",
    "print(label_ord_train.shape)\n",
    "print(fvec_test.shape)\n",
    "print(fvec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -1.88317491e-02   1.64733924e-02  -1.00358358e-01  -7.12058869e-02\n",
      "  -1.01446282e-02   2.00886136e+00   7.72151419e-03   1.67966693e-03\n",
      "  -1.51213653e-01  -3.32255414e-01  -3.06772015e-03   3.00310220e+00\n",
      "  -1.85726251e-02   3.62893444e-02  -9.81725267e-02  -6.81625413e-02\n",
      "   1.99362178e-03   2.35966383e+00  -1.72680852e-01   2.79800411e-03\n",
      "  -9.64941303e-03   1.53275991e-01  -1.90156013e-01  -3.18897837e-02\n",
      "  -5.37415994e-02   2.62896193e-01  -2.63141216e-02  -1.45610755e-02\n",
      "   2.80541112e-02   3.04330277e-01   1.19621218e-02  -5.93394855e-01]\n",
      "Training\n",
      "Mean absolute error: 0.74\n",
      "Accuracy: 0.38\n",
      "Validation\n",
      "Mean absolute error: 0.72\n",
      "Accuracy: 0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.Ridge(alpha = .5)\n",
    "\n",
    "# Train the model using training sets\n",
    "regr.fit(fvec_train, label_ord_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "label_ord_pred = np.round(regr.predict(fvec_test)).astype(np.int)\n",
    "label_ord_pred[label_ord_pred<0]=0\n",
    "label_ord_pred[label_ord_pred>=num_classes]=num_classes-1\n",
    "\n",
    "label_ord_tr_pred = np.round(regr.predict(fvec_train)).astype(np.int)\n",
    "label_ord_tr_pred[label_ord_tr_pred<0]=0\n",
    "label_ord_tr_pred[label_ord_tr_pred>=num_classes]=num_classes-1\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([241,   0, 181,   0,   0, 221,   0, 174,   0, 183]), array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]))\n",
      "(array([203,   0, 199,   0,   0, 199,   0, 199,   0, 200]), array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]))\n",
      "Coefficients: \n",
      " [ -1.88317491e-02   1.64733924e-02  -1.00358358e-01  -7.12058869e-02\n",
      "  -1.01446282e-02   2.00886136e+00   7.72151419e-03   1.67966693e-03\n",
      "  -1.51213653e-01  -3.32255414e-01  -3.06772015e-03   3.00310220e+00\n",
      "  -1.85726251e-02   3.62893444e-02  -9.81725267e-02  -6.81625413e-02\n",
      "   1.99362178e-03   2.35966383e+00  -1.72680852e-01   2.79800411e-03\n",
      "  -9.64941303e-03   1.53275991e-01  -1.90156013e-01  -3.18897837e-02\n",
      "  -5.37415994e-02   2.62896193e-01  -2.63141216e-02  -1.45610755e-02\n",
      "   2.80541112e-02   3.04330277e-01   1.19621218e-02  -5.93394855e-01]\n",
      "Training\n",
      "Mean absolute error: 0.69\n",
      "Accuracy: 0.53\n",
      "Validation\n",
      "Mean absolute error: 0.79\n",
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(fvec_train, label_ord_train)\n",
    "label_ord_pred = clf.predict(fvec_test)\n",
    "label_ord_tr_pred = clf.predict(fvec_train)\n",
    "print(np.histogram(label_ord_pred))\n",
    "print(np.histogram(label_ord_test))\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "label_test=np.eye(num_classes)[label_ord_test]\n",
    "label_train=np.eye(num_classes)[label_ord_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(x, hidden_sizes, activation_fn=tf.nn.relu,dropout_rate=.5,std_dev=1.0):\n",
    "    if not isinstance(hidden_sizes, (list, tuple)):\n",
    "        raise ValueError(\"hidden_sizes must be a list or a tuple\")\n",
    "        \n",
    "    scope_args = {'initializer': tf.random_normal_initializer(stddev=std_dev)}\n",
    "    \n",
    "    for k in range(len(hidden_sizes)-1):\n",
    "        layer_name=\"weights\"+str(k)\n",
    "        #FC layers\n",
    "        with tf.variable_scope(layer_name, **scope_args):\n",
    "            W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[k]])\n",
    "            b = tf.get_variable('b', shape=[hidden_sizes[k]])\n",
    "            x = activation_fn(tf.matmul(x, W) + b)\n",
    "            #Dropout before the last layer\n",
    "            x = tf.nn.dropout(x, keep_prob=dropout_rate)\n",
    "    #Softmax layer\n",
    "    with tf.variable_scope('outlayer', **scope_args):\n",
    "        W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[-1]])\n",
    "        b = tf.get_variable('b', shape=[hidden_sizes[-1]])\n",
    "        return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''fvec_n=fvec/np.round(np.max(label))\n",
    "label_n = label/np.round(np.max(label))'''\n",
    "def test_classification(model_function, learning_rate=0.1,num_iter=30000,num_log=2000):\n",
    "\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # where are you going to allocate memory and perform computations\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            \n",
    "            # define model \"input placeholders\", i.e. variables that are\n",
    "            # going to be substituted with input data on train/test time\n",
    "            x_ = tf.placeholder(tf.float32, [None, fvec.shape[1]])\n",
    "            y_ = tf.placeholder(tf.float32, [None, num_classes])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_logits))\n",
    "            '''train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)'''\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "           \n",
    "            y_pred = tf.argmax(y_logits, 1)\n",
    "            y_true = tf.argmax(y_,1)\n",
    "            correct_prediction = tf.equal(y_pred, y_true)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            mae_error = tf.reduce_mean(tf.cast(tf.abs(y_pred-y_true), tf.float32))\n",
    "\n",
    "    with g.as_default(), tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # train\n",
    "        ids=[i for i in range(128)]\n",
    "        for iter_i in range(num_iter+1):\n",
    "            batch_xs = fvec_train[ids,:] \n",
    "            batch_ys = label_train[ids]\n",
    "            ids=[(ids[0]+100+i)%label_train.shape[0] for i in range(100)]\n",
    "            sess.run(train_step, feed_dict={x_: batch_xs, y_: batch_ys})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % num_log == 0:\n",
    "                tf_feed_dict = {x_: fvec_train, y_: label_train}\n",
    "                loss_tr, acc_tr, mae_tr, y_pred_tr,y_true_tr= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                tf_feed_dict = {x_: fvec_test, y_: label_test}\n",
    "                loss_val, acc_val, mae_val, y_pred_val,y_true_val= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t Training: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t, Validation: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_tr, mae_tr, acc_tr, loss_val, mae_val, acc_val))\n",
    "                '''loss_val= sess.run(loss, feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_val, loss_val, loss_val))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\t Training: loss: 1.61273\t MAE: 1.35623\t acc: 0.19702\t, Validation: loss: 1.61241\t MAE: 1.35700\t acc: 0.19200\t\n",
      "iteration 2000\t Training: loss: 1.47498\t MAE: 1.13140\t acc: 0.35053\t, Validation: loss: 1.44077\t MAE: 1.10400\t acc: 0.36000\t\n",
      "iteration 4000\t Training: loss: 1.42999\t MAE: 1.10428\t acc: 0.35428\t, Validation: loss: 1.45174\t MAE: 1.10300\t acc: 0.35800\t\n",
      "iteration 6000\t Training: loss: 1.40367\t MAE: 0.99486\t acc: 0.37625\t, Validation: loss: 1.37136\t MAE: 0.93600\t acc: 0.40500\t\n",
      "iteration 8000\t Training: loss: 1.38688\t MAE: 0.99819\t acc: 0.38181\t, Validation: loss: 1.45761\t MAE: 0.96700\t acc: 0.39100\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e2b1cd43df2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_classification(\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     learning_rate=1e-3,num_iter=100000,num_log=2000)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-39ff4550697f>\u001b[0m in \u001b[0;36mtest_classification\u001b[0;34m(model_function, learning_rate, num_iter, num_log)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# test trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;31m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;31m# of a handle from a different device as an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m     \u001b[0mfinal_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mfinal_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_update_with_movers\u001b[0;34m(self, feed_dict, feed_map)\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mhandle_movers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m       \u001b[0mmover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handle_mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mhandle_movers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 16, 12, 12, 8, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=100000,num_log=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-4,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=1000000,num_log=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=5e-4,num_iter=300000,num_log=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
