{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data\n",
    "\n",
    "Before running the code, the data should be downloaded and foldered in the way that is usable for imagefolder function of the PyTorch. The following code assumes that the main directory for the dataset is 'data_dir' and it includes subdirectories for all of the separate classes.\n",
    "\n",
    "For details on how to create those folders, pleaserefer to 'dataset/Folder_images.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Macros\n",
    "'''\n",
    "#uniform_sampler=False\n",
    "batch_size=64\n",
    "split=1000\n",
    "random_seed=1\n",
    "shuffle=True\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "'''Create ImageFolder objects for training and test'''\n",
    "data_dir = '../images/0to5'\n",
    "#data_dir = '/home/mtezcan/Documents/amazon/bin_images/0to5'\n",
    "dset_train = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "dset_val = datasets.ImageFolder(data_dir, data_transforms['val'])\n",
    "\n",
    "'''Validation split'''\n",
    "num_train = len(dset_train)\n",
    "indices = list(range(num_train))\n",
    "val_idx=np.loadtxt('./dataset/validation.txt').astype(np.int)\n",
    "train_idx=np.setdiff1d(indices,val_idx)\n",
    "\n",
    "if shuffle == True:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "'''Sampler functions for validation and training'''\n",
    "sampler_train = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val,\n",
    "                                                    num_workers=12)}\n",
    "\n",
    "\n",
    "dset_sizes={'train':len(dset_train)-1000,'val':1000}\n",
    "dset_classes = dset_train.classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dset_loaders['val']))\n",
    "out = torchvision.utils.make_grid(inputs,nrow=8)\n",
    "print('Size of the input tensors in one batch after grid is  '+str(out.size()))\n",
    "plt.figure(figsize=(12,12))\n",
    "ft.imshow(out, title=[dset_classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Log Keeping\n",
    "\n",
    "This section includes the functions defined for the log keeping. Since CNNs require lots of trials, I found it easy to record the properties of the each trial with their performances in an excel file. I also added tnesorboard summaries for every trial and individual text files for showing the details of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code declares the required parameters for the network which will be also used inside log keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network='resnet34' #Initial network archtiecture.'loaded'forusing a saved network\n",
    "networkName='resnet18_real_sgd_multisoft_August29  19:06:27' #Directory for the saved network\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=14 #Number of the first column in the excel file for writing the results.\n",
    "end_to_end=True #Booolean to decide whether to train the network end-to-end or not.\n",
    "lr=0.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "pretrained=True \n",
    "mse_loss=False #Scalar MSE loss\n",
    "nclasses=6 #Number of output classes\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the functions for creating a text file and adding networkproperties to an excel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('runs/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Validation size: '+str(split)+'\\n')\n",
    "    f.write('Random seed: '+str(random_seed)+'\\n')\n",
    "    f.write('Shuffle: '+str(shuffle)+'\\n')\n",
    "    f.write('Validation size: '+str(split)+'\\n')\n",
    "    f.write('Network: '+network+'\\n')\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.write('Network is pretrained: '+str(pretrained)+'\\n')\n",
    "    f.write('Network laoded from: '+networkName+'\\n')\n",
    "    f.write('MSE loss function: '+str(mse_loss)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='logs.xlsx',iter_loc=14):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    if network=='loaded':\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'),networkName,str(split),str(random_seed),str(shuffle),\n",
    "               optimizer, crt,str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),str(pretrained),\n",
    "               str(batch_size))\n",
    "    else:\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'),network,str(split),str(random_seed),str(shuffle),\n",
    "               optimizer, crt,str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),str(pretrained),\n",
    "               str(batch_size))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Training and Validation\n",
    "\n",
    "In this part we will define the functions for training a CNN with different properties and loss functions.\n",
    "\n",
    "The following function takes bunch of properties defined in the beginning of Section-2 as input and creates network using those properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    network=network,\n",
    "                    networkName=networkName,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    end_to_end=end_to_end,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    pretrained=pretrained,\n",
    "                    mse_loss=mse_loss,\n",
    "                    nclasses=nclasses):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    if(network=='resnet18'):\n",
    "        model_ft = models.resnet18(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features #Change the last layer to adapt new classes\n",
    "        if(mse_loss): #For MSE loss last layer should be a scalar\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet34'):\n",
    "        model_ft = models.resnet34(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet50'):\n",
    "        model_ft = models.resnet50(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet101'):\n",
    "        model_ft = models.resnet101(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='alexnet'):\n",
    "        model_ft = models.alexnet(pretrained=pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].out_features\n",
    "        setattr(model_ft.classifier, '7', nn.ReLU(inplace=True))\n",
    "        setattr(model_ft.classifier, '8', nn.Dropout())\n",
    "        setattr(model_ft.classifier, '9', nn.Linear(num_ftrs,nclasses))\n",
    "\n",
    "    elif(network=='loaded'):#Use the saved network when network='loaded'\n",
    "        model_ft = torch.load('./saved_models/'+networkName)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    else:\n",
    "        raise ValueError('Undefined network '+network)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a simple function to be able to run our training in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "\n",
    "def run_network():\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            network=network,\n",
    "                                            networkName=networkName,\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            end_to_end=end_to_end,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            pretrained=pretrained,\n",
    "                                            mse_loss=mse_loss,\n",
    "                                            nclasses=nclasses)\n",
    "    \n",
    "    '''Name of the trial'''\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname=network+'_'+'_'+optimizer+'_'+crt+'_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('runs/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    best_model, last_model = ft.train_model(model_ft,optimizer_ft, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=30,batch_size=batch_size,num_log=250,\n",
    "                            multi_prob=False,lr_decay_epoch=lr_decay_epoch,init_lr=lr,mse_loss=mse_loss,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'./saved_models/'+logname+'_best')\n",
    "    torch.save(last_model,'./saved_models/'+logname+'_last')\n",
    "    \n",
    "    '''Frre up the memory'''\n",
    "    del model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function we used in the experiments is the following,\n",
    "\n",
    "$$loss(\\mathbf{y},\\hat{y})=(1-\\lambda )loss_{single}(\\mathbf{y},\\hat{y})+\\lambda loss_{multi}(\\mathbf{y},\\hat{y})$$\n",
    "where $\\mathbf{y}$ is the ground truth and $\\hat{y}$ is the prediction.\n",
    "\n",
    "Now lets test our function for different values of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse_loss=False\n",
    "for lmbda in [0., 0.7, 1.]:\n",
    "    single_loss=1.-lmbda\n",
    "    multi_loss = lmbda\n",
    "run_network()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
