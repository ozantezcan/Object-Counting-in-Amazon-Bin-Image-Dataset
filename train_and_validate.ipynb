{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "#from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data\n",
    "\n",
    "Before running the code, the data should be downloaded and foldered in the way that is usable for imagefolder function of the PyTorch. The following code assumes that the main directory for the dataset is 'data_dir' and it includes subdirectories for all of the separate classes.\n",
    "\n",
    "For details on how to create those folders, pleaserefer to 'dataset/Folder_images.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 70000, 'val': 15000}\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"kkk=1\\nfor data in dset_loaders['train']:\\n    print(kkk)\\n    kkk+=1\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Macros\n",
    "'''\n",
    "#uniform_sampler=False\n",
    "batch_size=32\n",
    "nclasses=10 #Number of output classes\n",
    "split=200\n",
    "random_seed=1\n",
    "shuffle=True\n",
    "dataset = 'abid'\n",
    "CV = 0\n",
    "train_val = None# (100000, 10000)\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "# Just normalization for validation\n",
    "'''data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.Scale(64),\n",
    "        transforms.RandomCrop(56),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Scale(64),\n",
    "        transforms.CenterCrop(56),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}'''\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "'''Create ImageFolder objects for training and test'''\n",
    "\n",
    "if dataset == 'Hoarding':\n",
    "    data_dir = '../datasets/hoarding/images'\n",
    "elif dataset == 'Hoarding_frames':\n",
    "    data_dir = '../datasets/hoarding/frames/all_inclusive'\n",
    "else:\n",
    "    data_dir = '../datasets/abid/train/balanced'  \n",
    "    \n",
    "\n",
    "if not CV == 0:  \n",
    "    dset_train = datasets.ImageFolder(data_dir+'/train_val', data_transforms['train'])\n",
    "    dset_val = datasets.ImageFolder(data_dir+'/train_val', data_transforms['val'])\n",
    "    \n",
    "    num_train = len(dset_train)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    splits = (num_train*np.linspace(0,1,CV+1)).astype(int)\n",
    "    \n",
    "    val_idx = [indices[splits[k]:splits[k+1]] for k in range(CV)]\n",
    "    train_idx=[np.setdiff1d(indices,val_idx[k]) for k in range(CV)]\n",
    "    '''Sampler functions for validation and training'''\n",
    "    sampler_train = [torch.utils.data.sampler.SubsetRandomSampler(train_idx[k]) for k in range(CV)]\n",
    "    sampler_val = [torch.utils.data.sampler.SubsetRandomSampler(val_idx[k]) for k in range(CV)]\n",
    "\n",
    "    '''Define dataset loaders'''\n",
    "    dset_loaders_arr = [{'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train[k],\n",
    "                                                        num_workers=12),\n",
    "                    'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val[k],\n",
    "                                                        num_workers=12)} for k in range(CV)]\n",
    "    dset_sizes={'train':int(len(dset_train)*(1-1/CV)),'val':int(len(dset_train)*(1/CV))}\n",
    "    \n",
    "    print(dset_sizes)\n",
    "    print('OR')\n",
    "    print('Number of training images '+str(len(val_idx)))\n",
    "    print('Number of validation images '+str(len(train_idx)))\n",
    "\n",
    "elif train_val:\n",
    "    \n",
    "    dset_train = datasets.ImageFolder(data_dir+'/train/0to5', data_transforms['train'])\n",
    "    dset_val = datasets.ImageFolder(data_dir+'/train/0to5', data_transforms['val'])\n",
    "    \n",
    "    num_train = len(dset_train)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_idx = indices[:train_val[0]]\n",
    "    val_idx = indices[-train_val[1]:]\n",
    "    '''Sampler functions for validation and training'''\n",
    "    sampler_train = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "    sampler_val = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "\n",
    "    '''Define dataset loaders'''\n",
    "    dset_loaders = {'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train,\n",
    "                                                        num_workers=12),\n",
    "                    'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val,\n",
    "                                                        num_workers=12)}\n",
    "    dset_sizes={'train':int(len(train_idx)),'val':int(len(val_idx))}\n",
    "    \n",
    "    print(dset_sizes)\n",
    "    print('OR')\n",
    "    print('Number of training images '+str(len(val_idx)))\n",
    "    print('Number of validation images '+str(len(train_idx)))\n",
    "else:\n",
    "    dset_train = datasets.ImageFolder(data_dir+'/train/0to5', data_transforms['train'])\n",
    "    dset_val = datasets.ImageFolder(data_dir+'/val/0to5', data_transforms['val'])\n",
    "\n",
    "    '''Define dataset loaders'''\n",
    "    dset_loaders = {'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,shuffle=True,\n",
    "                                                        num_workers=8),\n",
    "                    'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,\n",
    "                                                        num_workers=8)}\n",
    "\n",
    "    \n",
    "    dset_sizes={'train':len(dset_train),'val':len(dset_val)}\n",
    "    print(dset_sizes)\n",
    "\n",
    "dset_classes = dset_train.classes\n",
    "dset_classes_val = dset_val.classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "print(dset_classes)\n",
    "print(dset_classes_val)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')\n",
    "    \n",
    "'''kkk=1\n",
    "for data in dset_loaders['train']:\n",
    "    print(kkk)\n",
    "    kkk+=1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train.ConcatDataset(dset_val)\n",
    "print(len(dset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../images/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c2a63fdd28c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#data_dir = '/home/mtezcan/Documents/amazon/bin_images/0to5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mdset_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m '''dset_train = datasets.ImageFolder(data_dir+'/0to5', data_transforms['train'])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../images/train'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Macros\n",
    "'''\n",
    "#uniform_sampler=False\n",
    "batch_size=64\n",
    "split=1000\n",
    "random_seed=1\n",
    "shuffle=True\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "'''Create ImageFolder objects for training and test'''\n",
    "data_dir = '../images'\n",
    "#data_dir = '/home/mtezcan/Documents/amazon/bin_images/0to5'\n",
    "dset_train = datasets.ImageFolder(data_dir+'/train', data_transforms['train'])\n",
    "dset_val = datasets.ImageFolder(data_dir+'/val', data_transforms['val'])\n",
    "'''dset_train = datasets.ImageFolder(data_dir+'/0to5', data_transforms['train'])\n",
    "dset_val = datasets.ImageFolder(data_dir+'/0to5', data_transforms['val'])'''\n",
    "\n",
    "\n",
    "'''Validation split'''\n",
    "num_train = len(dset_train)\n",
    "indices = list(range(num_train))\n",
    "val_idx=np.loadtxt('./dataset/validation.txt').astype(np.int)\n",
    "train_idx=np.setdiff1d(indices,val_idx)\n",
    "\n",
    "'''if shuffle == True:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]'''\n",
    "\n",
    "'''Sampler functions for validation and training'''\n",
    "sampler_train = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,shuffle=True,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}\n",
    "'''dset_loaders = {'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val,\n",
    "                                                    num_workers=12)}'''\n",
    "\n",
    "dset_sizes={'train':len(dset_train),'val':len(dset_val)}\n",
    "#dset_sizes={'train':len(dset_train)-1000,'val':1000}\n",
    "dset_classes = dset_train.classes\n",
    "dset_classes_val = dset_val.classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(dset_sizes)\n",
    "print('OR')\n",
    "print('Number of training images '+str(len(val_idx)))\n",
    "print('Number of validation images '+str(len(train_idx)))\n",
    "\n",
    "print(dset_classes)\n",
    "print(dset_classes_val)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs,nrow=8)\n",
    "print('Size of the input tensors in one batch after grid is  '+str(out.size()))\n",
    "plt.figure(figsize=(12,12))\n",
    "ft.imshow(out, title=[dset_classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Log Keeping\n",
    "\n",
    "This section includes the functions defined for the log keeping. Since CNNs require lots of trials, I found it easy to record the properties of the each trial with their performances in an excel file. I also added tnesorboard summaries for every trial and individual text files for showing the details of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code declares the required parameters for the network which will be also used inside log keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coeff(n, metric, lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return [1]\n",
    "    elif metric is 'ccr1':\n",
    "        return [1, 1, 1]\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.arange(1,n)/(n-1)\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros(n-1)\n",
    "        coeff[0] = 2*n-3\n",
    "        for k in range(1, n-1):\n",
    "            coeff[k] = coeff[k-1] + 2*n - (2*(k+1)+1)\n",
    "        coeff = coeff /((n-1)**2)\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "    coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    coeff = coeff * lmbda\n",
    "    coeff[n-2] = 1\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.97777778 0.95555556 0.93333333 0.91111111 0.88888889\n",
      "  0.86666667 0.84444444 0.82222222 0.8       ]\n",
      " [0.97777778 1.         0.97777778 0.95555556 0.93333333 0.91111111\n",
      "  0.88888889 0.86666667 0.84444444 0.82222222]\n",
      " [0.95555556 0.97777778 1.         0.97777778 0.95555556 0.93333333\n",
      "  0.91111111 0.88888889 0.86666667 0.84444444]\n",
      " [0.93333333 0.95555556 0.97777778 1.         0.97777778 0.95555556\n",
      "  0.93333333 0.91111111 0.88888889 0.86666667]\n",
      " [0.91111111 0.93333333 0.95555556 0.97777778 1.         0.97777778\n",
      "  0.95555556 0.93333333 0.91111111 0.88888889]\n",
      " [0.88888889 0.91111111 0.93333333 0.95555556 0.97777778 1.\n",
      "  0.97777778 0.95555556 0.93333333 0.91111111]\n",
      " [0.86666667 0.88888889 0.91111111 0.93333333 0.95555556 0.97777778\n",
      "  1.         0.97777778 0.95555556 0.93333333]\n",
      " [0.84444444 0.86666667 0.88888889 0.91111111 0.93333333 0.95555556\n",
      "  0.97777778 1.         0.97777778 0.95555556]\n",
      " [0.82222222 0.84444444 0.86666667 0.88888889 0.91111111 0.93333333\n",
      "  0.95555556 0.97777778 1.         0.97777778]\n",
      " [0.8        0.82222222 0.84444444 0.86666667 0.88888889 0.91111111\n",
      "  0.93333333 0.95555556 0.97777778 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def make_coeff(n, metric, loss='softmax', lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return np.eye(n)\n",
    "    elif metric is 'ccr1':\n",
    "        coeff = np.zeros((n,n))\n",
    "        for k in range(n):\n",
    "            coeff[k,np.maximum(k-1,0):np.minimum(k+2,n)]=1\n",
    "        if loss is 'softmax':\n",
    "            coeff_sum = np.sum(coeff,axis=1).reshape(-1,1)*np.ones((1,n))\n",
    "            coeff = coeff/coeff_sum\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.zeros((n,n))\n",
    "        for k in range(n):\n",
    "            alpha = 1/(n-1)\n",
    "            row = np.zeros((1,n))\n",
    "            for l in range(n-1):\n",
    "                row_ = np.zeros((1,n))\n",
    "                row_[0, np.maximum(k-l,0):np.minimum(k+l+1,n)] = 1\n",
    "                if loss is 'softmax':\n",
    "                    row_ = row_/np.sum(row_)\n",
    "                row += row_*alpha\n",
    "            coeff[k,:]=row\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros((n,n))\n",
    "        for k in range(n):\n",
    "            row = np.zeros((1,n))\n",
    "            for l in range(n-1):\n",
    "                row_ = np.zeros((1,n))\n",
    "                row_[0, np.maximum(k-l,0):np.minimum(k+l+1,n)] = 1\n",
    "                row += (2*l+1)*row_\n",
    "                \n",
    "            if loss is 'softmax':\n",
    "                row = row / np.sum(row)\n",
    "            elif loss is 'sigmoid':\n",
    "                row = row / ((n**2)-(2*n)+1)\n",
    "            else:\n",
    "                 print('Undefined Loss: ' + str(loss))\n",
    "            coeff[k,:]=row\n",
    "    elif metric is 'test':\n",
    "        coeff = np.ones((n,n))\n",
    "        alpha = 1./45.\n",
    "        for k in range(n):\n",
    "            for l in range(n):\n",
    "                coeff[k,l] = 1 - np.abs(k-l) * alpha\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "        \n",
    "    coeff = np.eye(n)*(1-lmbda) + lmbda*coeff\n",
    "        \n",
    "    #coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    #coeff = coeff * lmbda\n",
    "    #coeff[n-2] = 1\n",
    "    return coeff\n",
    "\n",
    "coeff = make_coeff(10,'test',loss = 'softmax', lmbda=1)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network='resnet18' #Initial network archtiecture.'loaded'forusing a saved network\n",
    "networkName='resnet18_real_sgd_multisoft_August29  19:06:27' #Directory for the saved network\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=19 #Number of the first column in the excel file for writing the results.\n",
    "end_to_end=True #Booolean to decide whether to train the network end-to-end or not.\n",
    "lr=0.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "pretrained=False \n",
    "mse_loss=False #Scalar MSE loss\n",
    "#nclasses=9 #Number of output classes\n",
    "metric = 'ccr'\n",
    "coeff_lmbda =  0\n",
    "multi_coeff = make_coeff(nclasses, metric, loss = 'sigmoid', lmbda = coeff_lmbda)\n",
    "KL = False #KL divergence for porbability measure\n",
    "cheng_lambda = 0\n",
    "\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any\n",
    "\n",
    "algo = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the functions for creating a text file and adding networkproperties to an excel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('../results/tensorboard_runs/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Validation size: '+str(split)+'\\n')\n",
    "    f.write('Random seed: '+str(random_seed)+'\\n')\n",
    "    f.write('Shuffle: '+str(shuffle)+'\\n')\n",
    "    f.write('Validation size: '+str(split)+'\\n')\n",
    "    f.write('Network: '+network+'\\n')\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.write('Network is pretrained: '+str(pretrained)+'\\n')\n",
    "    f.write('Network laoded from: '+networkName+'\\n')\n",
    "    f.write('MSE loss function: '+str(mse_loss)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='../results/logs.xlsx',iter_loc=19):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    multi_coeff = make_coeff(nclasses, metric, loss = 'sigmoid', lmbda = coeff_lmbda)\n",
    "    if network=='loaded':\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'), dataset, networkName,str(split), str(algo), str(metric),\n",
    "               str(coeff_lmbda), str(random_seed),str(shuffle),\n",
    "               optimizer, crt, str(multi_coeff), str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),\n",
    "               str(pretrained), str(batch_size))\n",
    "    else:\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'), dataset, network,str(split),str(algo), str(metric),\n",
    "               str(coeff_lmbda), str(random_seed),str(shuffle),\n",
    "               optimizer, crt, str(multi_coeff),str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),\n",
    "               str(pretrained),str(batch_size))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Training and Validation\n",
    "\n",
    "In this part we will define the functions for training a CNN with different properties and loss functions.\n",
    "\n",
    "The following function takes bunch of properties defined in the beginning of Section-2 as input and creates network using those properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=pretrained)\n",
    "#model_ft.layer1 = nn.Sequential()#model_ft.layer4\n",
    "'''num_ftrs = model_ft.fc.in_features\n",
    "model_ft.conv1 = nn.Conv2d(3, 128, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "\n",
    "model_ft.bn1 = nn.BatchNorm2d(128)\n",
    "model_ft.avgpool = nn.AvgPool2d(2)\n",
    "print(model_ft)\n",
    "model_ft.fc = nn.Linear(num_ftrs, nclasses)'''\n",
    "\n",
    "\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    network=network,\n",
    "                    networkName=networkName,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    end_to_end=end_to_end,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    pretrained=pretrained,\n",
    "                    mse_loss=mse_loss,\n",
    "                    nclasses=nclasses):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    if(network=='resnet18'):\n",
    "        model_ft = models.resnet18(pretrained=pretrained)\n",
    "        '''' model_ft.conv1 = nn.Conv2d(3, 128, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "\n",
    "        model_ft.bn1 = nn.BatchNorm2d(128)\n",
    "        model_ft.layer1 = nn.Sequential()\n",
    "        model_ft.layer2 = nn.Sequential()\n",
    "        model_ft.avgpool = nn.AvgPool2d(4)'''\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features #Change the last layer to adapt new classes\n",
    "        if(mse_loss): #For MSE loss last layer should be a scalar\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet34'):\n",
    "        model_ft = models.resnet34(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet50'):\n",
    "        model_ft = models.resnet50(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='resnet101'):\n",
    "        model_ft = models.resnet101(pretrained=pretrained)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        if(mse_loss):\n",
    "            model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "        else:    \n",
    "            model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    elif(network=='alexnet'):\n",
    "        model_ft = models.alexnet(pretrained=pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].out_features\n",
    "        setattr(model_ft.classifier, '7', nn.ReLU(inplace=True))\n",
    "        setattr(model_ft.classifier, '8', nn.Dropout())\n",
    "        setattr(model_ft.classifier, '9', nn.Linear(num_ftrs,nclasses))\n",
    "\n",
    "    elif(network=='loaded'):#Use the saved network when network='loaded'\n",
    "        model_ft = torch.load('./saved_models/'+networkName)\n",
    "        if not end_to_end:\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False \n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "    else:\n",
    "        raise ValueError('Undefined network '+network)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a simple function to be able to run our training in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_epochs(result_log, logname):\n",
    "    print(len(result_log))\n",
    "\n",
    "    wb_tr = openpyxl.Workbook()\n",
    "    ws_tr = wb_tr.active\n",
    "    wb_val = openpyxl.Workbook()\n",
    "    ws_val = wb_val.active\n",
    "    print(logname)\n",
    "\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, nclasses))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, nclasses))\n",
    "\n",
    "    prev_epoch = 0\n",
    "    for result in result_log:\n",
    "        epoch = result[1]\n",
    "        if not epoch == prev_epoch:\n",
    "            ws_tr.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "            ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "                ws_tr.append(probs)\n",
    "            wb_tr.save('./runs/'+logname + '/train.xlsx')\n",
    "            ws_val.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "            ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_val[1:,:].T.tolist():\n",
    "                ws_val.append(probs)\n",
    "            wb_val.save('./runs/'+logname + '/val.xlsx')\n",
    "\n",
    "            del label_arr_tr, label_arr_val, probs_arr_tr, probs_arr_val\n",
    "            label_arr_tr = np.zeros((1,1))\n",
    "            probs_arr_tr = np.zeros((1, nclasses))\n",
    "            label_arr_val = np.zeros((1,1))\n",
    "            probs_arr_val = np.zeros((1, nclasses))\n",
    "            prev_epoch = epoch\n",
    "\n",
    "        label = np.asarray(result[2]).reshape(-1,1)\n",
    "        scores = np.asarray(result[3])\n",
    "        exp_scores = np.exp(scores - np.max(scores,axis=1).reshape(-1, 1)*np.ones(nclasses))\n",
    "        probs = np.round(exp_scores/(np.sum(exp_scores,axis=1).reshape(-1, 1)*np.ones(nclasses)), decimals=2)\n",
    "        if result[0] == 'train':\n",
    "            label_arr_tr  =np.append(label_arr_tr, label)\n",
    "            probs_arr_tr = np.append(probs_arr_tr, probs, axis=0)\n",
    "        elif result[0] == 'val':\n",
    "            label_arr_val  =np.append(label_arr_val, label)\n",
    "            probs_arr_val = np.append(probs_arr_val, probs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    ws_tr.append(['Epoch ' + str(epoch)])\n",
    "    ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "    ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "        ws_tr.append(probs)\n",
    "    wb_tr.save('./runs/'+logname + '/train.xlsx')\n",
    "    ws_val.append(['Epoch ' + str(epoch)])\n",
    "    ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "    ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_val[1:,:].T.tolist():\n",
    "        ws_val.append(probs)\n",
    "    wb_val.save('./runs/'+logname + '/val.xlsx')\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, nclasses))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, nclasses))\n",
    "    prev_epoch = epoch\n",
    "    print('Finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "\n",
    "def run_network():\n",
    "    print(iter_loc)\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            network=network,\n",
    "                                            networkName=networkName,\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            end_to_end=end_to_end,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            pretrained=pretrained,\n",
    "                                            mse_loss=mse_loss,\n",
    "                                            nclasses=nclasses)\n",
    "    \n",
    "    #model_ft_.fc = nn.Sequential(model_ft.fc, nn.Linear(model_ft.fc.out_features, 1))\n",
    "    #print(len(optimizer_ft.param_groups))\n",
    "    \n",
    "    multi_coeff = make_coeff(nclasses, metric, loss = 'sigmoid', lmbda = coeff_lmbda)\n",
    "    softmax_matrices = get_soft_matrices(metric, nclasses)\n",
    "    print('Multi coeff is ' + str(multi_coeff))\n",
    "    '''Name of the trial'''\n",
    "    if mse_loss:\n",
    "        crt='MSE'\n",
    "    else:\n",
    "        crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname=network+'_'+'_'+optimizer+'_'+crt+'_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('../results/tensorboard_runs/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    best_model, last_model, result_log = ft.train_model(model_ft,optimizer, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=180,batch_size=batch_size,num_log=500,\n",
    "                            lr_decay_epoch=lr_decay_epoch,init_lr=lr, algo = algo,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss,numOut=nclasses,\n",
    "                            multi_coeff = multi_coeff, single_coeff = multi_coeff, KL = KL, write_log = True,\n",
    "                            momentum = momentum, weight_decay = weight_decay,\n",
    "                            logname = '../results/logs.xlsx', cheng_lambda = cheng_lambda, \n",
    "                            softmax_matrices = softmax_matrices)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'../results/saved_models_pytorch/'+logname+'_best')\n",
    "    torch.save(last_model,'../results/saved_models_pytorch/'+logname+'_last')\n",
    "    \n",
    "    print('Writing results')\n",
    "    #write_epochs(result_log, logname)\n",
    "    print('Wrote results')\n",
    "    '''Free up the memory'''\n",
    "    del model_ft, result_log\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, tensor([[ 1.,  1.,  0.,  0.,  0.],\n",
       "          [ 1.,  1.,  1.,  0.,  0.],\n",
       "          [ 0.,  1.,  1.,  1.,  0.],\n",
       "          [ 0.,  0.,  1.,  1.,  1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.]], device='cuda:0'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_soft_matrices(metric, n):\n",
    "    if metric is 'ccr':\n",
    "        softmax_matrices = [(1, torch.from_numpy(np.eye(n)).type(torch.FloatTensor).to(device))]\n",
    "    if metric is 'test':\n",
    "        softmax_matrices = [(1, torch.from_numpy(np.eye(n)).type(torch.FloatTensor).to(device))]\n",
    "    if metric is 'ccr1':\n",
    "        mat = np.eye(n)\n",
    "        for k in range(n-1):\n",
    "            mat[k, k+1] = 1\n",
    "            mat[k+1, k] = 1\n",
    "        softmax_matrices = [(1, torch.from_numpy(mat).type(torch.FloatTensor).to(device))]\n",
    "    if metric is 'mae' or metric is 'mse':\n",
    "        softmax_matrices = [(1, torch.from_numpy(np.eye(n)).type(torch.FloatTensor).to(device))]\n",
    "        for k in range(1, n-1):\n",
    "            mat = np.eye(n)\n",
    "            for l in range(n):\n",
    "                mat[l, max(0,l-k):(k+l+1)] = 1\n",
    "            if metric is 'mae':\n",
    "                softmax_matrices.append((2*k + 1, torch.from_numpy(mat).type(torch.FloatTensor).to(device)))\n",
    "            else:\n",
    "                softmax_matrices.append((2*k + 1, torch.from_numpy(mat).type(torch.FloatTensor).to(device)))\n",
    "            \n",
    "    return softmax_matrices\n",
    "\n",
    "get_soft_matrices('ccr1', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([1,2,3,4])\n",
    "\n",
    "a[2:8] = 2\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function we used in the experiments is the following,\n",
    "\n",
    "$$loss(\\mathbf{y},\\hat{y})=(1-\\lambda )loss_{single}(\\mathbf{y},\\hat{y})+\\lambda loss_{multi}(\\mathbf{y},\\hat{y})$$\n",
    "where $\\mathbf{y}$ is the ground truth and $\\hat{y}$ is the prediction.\n",
    "\n",
    "Now lets test our function for different values of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_ft_ = copy.deepcopy(model_ft)\n",
    "model_ft_.fc = nn.Sequential(model_ft.fc, nn.Softmax(dim=1), nn.Linear(model_ft.fc.out_features, 1, bias = False))\n",
    "\n",
    "print(model_ft_.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Multi coeff is [[1.         0.97777778 0.95555556 0.93333333 0.91111111 0.88888889\n",
      "  0.86666667 0.84444444 0.82222222 0.8       ]\n",
      " [0.97777778 1.         0.97777778 0.95555556 0.93333333 0.91111111\n",
      "  0.88888889 0.86666667 0.84444444 0.82222222]\n",
      " [0.95555556 0.97777778 1.         0.97777778 0.95555556 0.93333333\n",
      "  0.91111111 0.88888889 0.86666667 0.84444444]\n",
      " [0.93333333 0.95555556 0.97777778 1.         0.97777778 0.95555556\n",
      "  0.93333333 0.91111111 0.88888889 0.86666667]\n",
      " [0.91111111 0.93333333 0.95555556 0.97777778 1.         0.97777778\n",
      "  0.95555556 0.93333333 0.91111111 0.88888889]\n",
      " [0.88888889 0.91111111 0.93333333 0.95555556 0.97777778 1.\n",
      "  0.97777778 0.95555556 0.93333333 0.91111111]\n",
      " [0.86666667 0.88888889 0.91111111 0.93333333 0.95555556 0.97777778\n",
      "  1.         0.97777778 0.95555556 0.93333333]\n",
      " [0.84444444 0.86666667 0.88888889 0.91111111 0.93333333 0.95555556\n",
      "  0.97777778 1.         0.97777778 0.95555556]\n",
      " [0.82222222 0.84444444 0.86666667 0.88888889 0.91111111 0.93333333\n",
      "  0.95555556 0.97777778 1.         0.97777778]\n",
      " [0.8        0.82222222 0.84444444 0.86666667 0.88888889 0.91111111\n",
      "  0.93333333 0.95555556 0.97777778 1.        ]]\n",
      "Epoch 0/179\n",
      "----------\n",
      "LR is set to 0.1\n",
      "500/2188, acc: 0.1944, CIR-1: 0.4476, RMSE: 2.5658, MAE: 1.9881\n",
      "1000/2188, acc: 0.2061, CIR-1: 0.4676, RMSE: 2.4526, MAE: 1.8910\n",
      "1500/2188, acc: 0.2124, CIR-1: 0.4761, RMSE: 2.4019, MAE: 1.8459\n",
      "2000/2188, acc: 0.2173, CIR-1: 0.4854, RMSE: 2.3636, MAE: 1.8107\n",
      "train Loss: 8.0084 Acc: 0.2195 CIR-1: 0.4881 RMSE 2.3537 MAE 1.8012\n",
      "val Loss: 7.9225 Acc: 0.2494 CIR-1: 0.5217 RMSE 2.1569 MAE 1.6328\n",
      "\n",
      "Epoch 1/179\n",
      "----------\n",
      "500/2188, acc: 0.2393, CIR-1: 0.5213, RMSE: 2.1960, MAE: 1.6584\n",
      "1000/2188, acc: 0.2374, CIR-1: 0.5226, RMSE: 2.2044, MAE: 1.6637\n",
      "1500/2188, acc: 0.2399, CIR-1: 0.5259, RMSE: 2.1891, MAE: 1.6515\n",
      "2000/2188, acc: 0.2418, CIR-1: 0.5282, RMSE: 2.1828, MAE: 1.6454\n",
      "train Loss: 7.9268 Acc: 0.2428 CIR-1: 0.5288 RMSE 2.1831 MAE 1.6450\n",
      "val Loss: 7.9307 Acc: 0.2543 CIR-1: 0.5475 RMSE 2.2590 MAE 1.6676\n",
      "\n",
      "Epoch 2/179\n",
      "----------\n",
      "500/2188, acc: 0.2455, CIR-1: 0.5407, RMSE: 2.1389, MAE: 1.6046\n",
      "1000/2188, acc: 0.2517, CIR-1: 0.5439, RMSE: 2.1277, MAE: 1.5924\n",
      "1500/2188, acc: 0.2544, CIR-1: 0.5495, RMSE: 2.1165, MAE: 1.5805\n",
      "2000/2188, acc: 0.2540, CIR-1: 0.5492, RMSE: 2.1176, MAE: 1.5813\n",
      "train Loss: 7.9089 Acc: 0.2545 CIR-1: 0.5500 RMSE 2.1151 MAE 1.5798\n",
      "val Loss: 7.8945 Acc: 0.2610 CIR-1: 0.5649 RMSE 2.0428 MAE 1.5215\n",
      "\n",
      "Epoch 3/179\n",
      "----------\n",
      "500/2188, acc: 0.2532, CIR-1: 0.5584, RMSE: 2.0880, MAE: 1.5549\n",
      "1000/2188, acc: 0.2569, CIR-1: 0.5608, RMSE: 2.0786, MAE: 1.5473\n",
      "1500/2188, acc: 0.2572, CIR-1: 0.5608, RMSE: 2.0811, MAE: 1.5485\n",
      "2000/2188, acc: 0.2600, CIR-1: 0.5625, RMSE: 2.0715, MAE: 1.5394\n",
      "train Loss: 7.8983 Acc: 0.2611 CIR-1: 0.5633 RMSE 2.0716 MAE 1.5388\n",
      "val Loss: 7.8900 Acc: 0.2619 CIR-1: 0.5705 RMSE 2.0075 MAE 1.4985\n",
      "\n",
      "Epoch 4/179\n",
      "----------\n",
      "500/2188, acc: 0.2657, CIR-1: 0.5596, RMSE: 2.0623, MAE: 1.5292\n",
      "1000/2188, acc: 0.2672, CIR-1: 0.5660, RMSE: 2.0458, MAE: 1.5163\n",
      "1500/2188, acc: 0.2660, CIR-1: 0.5670, RMSE: 2.0487, MAE: 1.5184\n",
      "2000/2188, acc: 0.2673, CIR-1: 0.5699, RMSE: 2.0420, MAE: 1.5115\n",
      "train Loss: 7.8891 Acc: 0.2676 CIR-1: 0.5702 RMSE 2.0421 MAE 1.5119\n",
      "val Loss: 7.8809 Acc: 0.2681 CIR-1: 0.5762 RMSE 1.9809 MAE 1.4768\n",
      "\n",
      "Epoch 5/179\n",
      "----------\n",
      "500/2188, acc: 0.2760, CIR-1: 0.5783, RMSE: 2.0159, MAE: 1.4789\n",
      "1000/2188, acc: 0.2722, CIR-1: 0.5782, RMSE: 2.0170, MAE: 1.4840\n",
      "1500/2188, acc: 0.2717, CIR-1: 0.5785, RMSE: 2.0235, MAE: 1.4893\n",
      "2000/2188, acc: 0.2719, CIR-1: 0.5790, RMSE: 2.0217, MAE: 1.4882\n",
      "train Loss: 7.8839 Acc: 0.2723 CIR-1: 0.5796 RMSE 2.0210 MAE 1.4881\n",
      "val Loss: 7.8832 Acc: 0.2677 CIR-1: 0.5825 RMSE 1.9863 MAE 1.4751\n",
      "\n",
      "Epoch 6/179\n",
      "----------\n",
      "500/2188, acc: 0.2752, CIR-1: 0.5789, RMSE: 1.9915, MAE: 1.4697\n",
      "1000/2188, acc: 0.2777, CIR-1: 0.5826, RMSE: 1.9994, MAE: 1.4690\n",
      "1500/2188, acc: 0.2781, CIR-1: 0.5835, RMSE: 2.0002, MAE: 1.4690\n",
      "2000/2188, acc: 0.2772, CIR-1: 0.5846, RMSE: 2.0015, MAE: 1.4697\n",
      "train Loss: 7.8801 Acc: 0.2778 CIR-1: 0.5841 RMSE 2.0027 MAE 1.4710\n",
      "val Loss: 7.8742 Acc: 0.2969 CIR-1: 0.6019 RMSE 2.0025 MAE 1.4356\n",
      "\n",
      "Epoch 7/179\n",
      "----------\n",
      "500/2188, acc: 0.2797, CIR-1: 0.5803, RMSE: 1.9887, MAE: 1.4604\n",
      "1000/2188, acc: 0.2796, CIR-1: 0.5826, RMSE: 1.9922, MAE: 1.4626\n",
      "1500/2188, acc: 0.2798, CIR-1: 0.5848, RMSE: 1.9984, MAE: 1.4643\n",
      "2000/2188, acc: 0.2812, CIR-1: 0.5873, RMSE: 1.9907, MAE: 1.4577\n",
      "train Loss: 7.8757 Acc: 0.2812 CIR-1: 0.5876 RMSE 1.9904 MAE 1.4584\n",
      "val Loss: 7.8665 Acc: 0.2864 CIR-1: 0.6049 RMSE 1.9499 MAE 1.4199\n",
      "\n",
      "Epoch 8/179\n",
      "----------\n",
      "500/2188, acc: 0.2837, CIR-1: 0.5922, RMSE: 1.9576, MAE: 1.4322\n",
      "1000/2188, acc: 0.2854, CIR-1: 0.5941, RMSE: 1.9604, MAE: 1.4323\n",
      "1500/2188, acc: 0.2850, CIR-1: 0.5936, RMSE: 1.9721, MAE: 1.4391\n",
      "2000/2188, acc: 0.2859, CIR-1: 0.5931, RMSE: 1.9716, MAE: 1.4386\n",
      "train Loss: 7.8702 Acc: 0.2845 CIR-1: 0.5928 RMSE 1.9736 MAE 1.4423\n",
      "val Loss: 7.8825 Acc: 0.2835 CIR-1: 0.5817 RMSE 1.9208 MAE 1.4263\n",
      "\n",
      "Epoch 9/179\n",
      "----------\n",
      "500/2188, acc: 0.2948, CIR-1: 0.6065, RMSE: 1.9285, MAE: 1.3951\n",
      "1000/2188, acc: 0.2903, CIR-1: 0.6036, RMSE: 1.9465, MAE: 1.4127\n",
      "1500/2188, acc: 0.2890, CIR-1: 0.6020, RMSE: 1.9533, MAE: 1.4191\n",
      "2000/2188, acc: 0.2894, CIR-1: 0.6032, RMSE: 1.9544, MAE: 1.4192\n",
      "train Loss: 7.8656 Acc: 0.2891 CIR-1: 0.6026 RMSE 1.9555 MAE 1.4214\n",
      "val Loss: 7.8710 Acc: 0.2813 CIR-1: 0.6013 RMSE 1.9516 MAE 1.4280\n",
      "\n",
      "Epoch 10/179\n",
      "----------\n",
      "500/2188, acc: 0.2883, CIR-1: 0.6036, RMSE: 1.9384, MAE: 1.4094\n",
      "1000/2188, acc: 0.2881, CIR-1: 0.6009, RMSE: 1.9571, MAE: 1.4218\n",
      "1500/2188, acc: 0.2890, CIR-1: 0.6003, RMSE: 1.9601, MAE: 1.4236\n",
      "2000/2188, acc: 0.2893, CIR-1: 0.6011, RMSE: 1.9526, MAE: 1.4191\n",
      "train Loss: 7.8647 Acc: 0.2897 CIR-1: 0.6018 RMSE 1.9537 MAE 1.4196\n",
      "val Loss: 7.8608 Acc: 0.2929 CIR-1: 0.5941 RMSE 1.9189 MAE 1.4059\n",
      "\n",
      "Epoch 11/179\n",
      "----------\n",
      "500/2188, acc: 0.2914, CIR-1: 0.6127, RMSE: 1.9184, MAE: 1.3892\n",
      "1000/2188, acc: 0.2904, CIR-1: 0.6039, RMSE: 1.9375, MAE: 1.4073\n",
      "1500/2188, acc: 0.2912, CIR-1: 0.6042, RMSE: 1.9331, MAE: 1.4044\n",
      "2000/2188, acc: 0.2939, CIR-1: 0.6049, RMSE: 1.9360, MAE: 1.4033\n",
      "train Loss: 7.8609 Acc: 0.2936 CIR-1: 0.6052 RMSE 1.9402 MAE 1.4062\n",
      "val Loss: 7.8684 Acc: 0.3005 CIR-1: 0.6093 RMSE 1.9841 MAE 1.4219\n",
      "\n",
      "Epoch 12/179\n",
      "----------\n",
      "500/2188, acc: 0.2928, CIR-1: 0.6054, RMSE: 1.9303, MAE: 1.3972\n",
      "1000/2188, acc: 0.2949, CIR-1: 0.6048, RMSE: 1.9369, MAE: 1.4010\n",
      "1500/2188, acc: 0.2939, CIR-1: 0.6080, RMSE: 1.9281, MAE: 1.3959\n",
      "2000/2188, acc: 0.2945, CIR-1: 0.6083, RMSE: 1.9266, MAE: 1.3949\n",
      "train Loss: 7.8578 Acc: 0.2951 CIR-1: 0.6089 RMSE 1.9262 MAE 1.3945\n",
      "val Loss: 7.8548 Acc: 0.3126 CIR-1: 0.6220 RMSE 1.9264 MAE 1.3714\n",
      "\n",
      "Epoch 13/179\n",
      "----------\n",
      "500/2188, acc: 0.3056, CIR-1: 0.6231, RMSE: 1.8970, MAE: 1.3561\n",
      "1000/2188, acc: 0.3023, CIR-1: 0.6164, RMSE: 1.9110, MAE: 1.3733\n",
      "1500/2188, acc: 0.3001, CIR-1: 0.6171, RMSE: 1.9086, MAE: 1.3743\n",
      "2000/2188, acc: 0.2988, CIR-1: 0.6151, RMSE: 1.9169, MAE: 1.3814\n",
      "train Loss: 7.8554 Acc: 0.2985 CIR-1: 0.6146 RMSE 1.9202 MAE 1.3848\n",
      "val Loss: 7.8612 Acc: 0.3054 CIR-1: 0.6143 RMSE 1.9594 MAE 1.4020\n",
      "\n",
      "Epoch 14/179\n",
      "----------\n",
      "500/2188, acc: 0.2952, CIR-1: 0.6166, RMSE: 1.9152, MAE: 1.3799\n",
      "1000/2188, acc: 0.3016, CIR-1: 0.6172, RMSE: 1.9088, MAE: 1.3720\n",
      "1500/2188, acc: 0.3003, CIR-1: 0.6189, RMSE: 1.9084, MAE: 1.3721\n",
      "2000/2188, acc: 0.2998, CIR-1: 0.6178, RMSE: 1.9085, MAE: 1.3740\n",
      "train Loss: 7.8519 Acc: 0.3002 CIR-1: 0.6184 RMSE 1.9080 MAE 1.3738\n",
      "val Loss: 7.8490 Acc: 0.3070 CIR-1: 0.6136 RMSE 1.8710 MAE 1.3549\n",
      "\n",
      "Epoch 15/179\n",
      "----------\n",
      "500/2188, acc: 0.2971, CIR-1: 0.6172, RMSE: 1.8971, MAE: 1.3674\n",
      "1000/2188, acc: 0.3011, CIR-1: 0.6189, RMSE: 1.8999, MAE: 1.3668\n",
      "1500/2188, acc: 0.3016, CIR-1: 0.6191, RMSE: 1.8993, MAE: 1.3665\n",
      "2000/2188, acc: 0.3016, CIR-1: 0.6180, RMSE: 1.9041, MAE: 1.3697\n",
      "train Loss: 7.8509 Acc: 0.3022 CIR-1: 0.6183 RMSE 1.9032 MAE 1.3688\n",
      "val Loss: 7.8482 Acc: 0.3113 CIR-1: 0.6265 RMSE 1.8905 MAE 1.3521\n",
      "\n",
      "Epoch 16/179\n",
      "----------\n",
      "500/2188, acc: 0.3001, CIR-1: 0.6199, RMSE: 1.9045, MAE: 1.3660\n",
      "1000/2188, acc: 0.3025, CIR-1: 0.6219, RMSE: 1.9012, MAE: 1.3633\n",
      "1500/2188, acc: 0.3036, CIR-1: 0.6200, RMSE: 1.8993, MAE: 1.3632\n",
      "2000/2188, acc: 0.3048, CIR-1: 0.6223, RMSE: 1.8952, MAE: 1.3590\n",
      "train Loss: 7.8490 Acc: 0.3042 CIR-1: 0.6220 RMSE 1.8963 MAE 1.3612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 7.8469 Acc: 0.3131 CIR-1: 0.6251 RMSE 1.8810 MAE 1.3443\n",
      "\n",
      "Epoch 17/179\n",
      "----------\n",
      "500/2188, acc: 0.2988, CIR-1: 0.6278, RMSE: 1.8769, MAE: 1.3493\n",
      "1000/2188, acc: 0.3009, CIR-1: 0.6257, RMSE: 1.8782, MAE: 1.3510\n",
      "1500/2188, acc: 0.3029, CIR-1: 0.6246, RMSE: 1.8836, MAE: 1.3532\n",
      "2000/2188, acc: 0.3033, CIR-1: 0.6238, RMSE: 1.8845, MAE: 1.3542\n",
      "train Loss: 7.8469 Acc: 0.3033 CIR-1: 0.6236 RMSE 1.8870 MAE 1.3562\n",
      "val Loss: 7.8458 Acc: 0.3057 CIR-1: 0.6156 RMSE 1.8569 MAE 1.3468\n",
      "\n",
      "Epoch 18/179\n",
      "----------\n",
      "500/2188, acc: 0.3053, CIR-1: 0.6277, RMSE: 1.8610, MAE: 1.3341\n",
      "1000/2188, acc: 0.3047, CIR-1: 0.6250, RMSE: 1.8730, MAE: 1.3446\n",
      "1500/2188, acc: 0.3056, CIR-1: 0.6248, RMSE: 1.8833, MAE: 1.3502\n",
      "2000/2188, acc: 0.3074, CIR-1: 0.6258, RMSE: 1.8797, MAE: 1.3462\n",
      "train Loss: 7.8440 Acc: 0.3082 CIR-1: 0.6267 RMSE 1.8801 MAE 1.3459\n",
      "val Loss: 7.8466 Acc: 0.3202 CIR-1: 0.6343 RMSE 1.8913 MAE 1.3368\n",
      "\n",
      "Epoch 19/179\n",
      "----------\n",
      "500/2188, acc: 0.3141, CIR-1: 0.6263, RMSE: 1.8500, MAE: 1.3217\n",
      "1000/2188, acc: 0.3078, CIR-1: 0.6253, RMSE: 1.8641, MAE: 1.3370\n",
      "1500/2188, acc: 0.3088, CIR-1: 0.6271, RMSE: 1.8637, MAE: 1.3353\n",
      "2000/2188, acc: 0.3093, CIR-1: 0.6277, RMSE: 1.8658, MAE: 1.3359\n",
      "train Loss: 7.8423 Acc: 0.3082 CIR-1: 0.6269 RMSE 1.8695 MAE 1.3401\n",
      "val Loss: 7.8417 Acc: 0.3184 CIR-1: 0.6304 RMSE 1.8578 MAE 1.3235\n",
      "\n",
      "Epoch 20/179\n",
      "----------\n",
      "500/2188, acc: 0.3102, CIR-1: 0.6254, RMSE: 1.8579, MAE: 1.3302\n",
      "1000/2188, acc: 0.3114, CIR-1: 0.6296, RMSE: 1.8564, MAE: 1.3270\n",
      "1500/2188, acc: 0.3121, CIR-1: 0.6326, RMSE: 1.8552, MAE: 1.3248\n",
      "2000/2188, acc: 0.3107, CIR-1: 0.6328, RMSE: 1.8582, MAE: 1.3276\n",
      "train Loss: 7.8400 Acc: 0.3096 CIR-1: 0.6326 RMSE 1.8606 MAE 1.3307\n",
      "val Loss: 7.8463 Acc: 0.3077 CIR-1: 0.6239 RMSE 1.8744 MAE 1.3462\n",
      "\n",
      "Epoch 21/179\n",
      "----------\n",
      "500/2188, acc: 0.3192, CIR-1: 0.6354, RMSE: 1.8466, MAE: 1.3109\n",
      "1000/2188, acc: 0.3170, CIR-1: 0.6355, RMSE: 1.8535, MAE: 1.3169\n",
      "1500/2188, acc: 0.3160, CIR-1: 0.6360, RMSE: 1.8562, MAE: 1.3193\n",
      "2000/2188, acc: 0.3143, CIR-1: 0.6360, RMSE: 1.8533, MAE: 1.3199\n",
      "train Loss: 7.8377 Acc: 0.3134 CIR-1: 0.6348 RMSE 1.8542 MAE 1.3228\n",
      "val Loss: 7.8440 Acc: 0.3197 CIR-1: 0.6363 RMSE 1.8555 MAE 1.3159\n",
      "\n",
      "Epoch 22/179\n",
      "----------\n",
      "500/2188, acc: 0.3097, CIR-1: 0.6299, RMSE: 1.8592, MAE: 1.3272\n",
      "1000/2188, acc: 0.3096, CIR-1: 0.6319, RMSE: 1.8592, MAE: 1.3276\n",
      "1500/2188, acc: 0.3104, CIR-1: 0.6328, RMSE: 1.8528, MAE: 1.3239\n",
      "2000/2188, acc: 0.3121, CIR-1: 0.6332, RMSE: 1.8566, MAE: 1.3245\n",
      "train Loss: 7.8372 Acc: 0.3133 CIR-1: 0.6345 RMSE 1.8546 MAE 1.3223\n",
      "val Loss: 7.8468 Acc: 0.3119 CIR-1: 0.6311 RMSE 1.8863 MAE 1.3439\n",
      "\n",
      "Epoch 23/179\n",
      "----------\n",
      "500/2188, acc: 0.3134, CIR-1: 0.6458, RMSE: 1.8169, MAE: 1.2919\n",
      "1000/2188, acc: 0.3150, CIR-1: 0.6436, RMSE: 1.8300, MAE: 1.3006\n",
      "1500/2188, acc: 0.3151, CIR-1: 0.6419, RMSE: 1.8380, MAE: 1.3065\n",
      "2000/2188, acc: 0.3146, CIR-1: 0.6408, RMSE: 1.8413, MAE: 1.3094\n",
      "train Loss: 7.8343 Acc: 0.3145 CIR-1: 0.6402 RMSE 1.8446 MAE 1.3127\n",
      "val Loss: 7.8416 Acc: 0.3259 CIR-1: 0.6413 RMSE 1.8762 MAE 1.3180\n",
      "\n",
      "Epoch 24/179\n",
      "----------\n",
      "500/2188, acc: 0.3136, CIR-1: 0.6364, RMSE: 1.8392, MAE: 1.3105\n",
      "1000/2188, acc: 0.3148, CIR-1: 0.6392, RMSE: 1.8317, MAE: 1.3050\n",
      "1500/2188, acc: 0.3150, CIR-1: 0.6395, RMSE: 1.8350, MAE: 1.3067\n",
      "2000/2188, acc: 0.3162, CIR-1: 0.6397, RMSE: 1.8347, MAE: 1.3059\n",
      "train Loss: 7.8329 Acc: 0.3166 CIR-1: 0.6397 RMSE 1.8349 MAE 1.3063\n",
      "val Loss: 7.8461 Acc: 0.3281 CIR-1: 0.6355 RMSE 1.8483 MAE 1.3081\n",
      "\n",
      "Epoch 25/179\n",
      "----------\n",
      "500/2188, acc: 0.3231, CIR-1: 0.6516, RMSE: 1.8127, MAE: 1.2789\n",
      "1000/2188, acc: 0.3196, CIR-1: 0.6452, RMSE: 1.8265, MAE: 1.2944\n",
      "1500/2188, acc: 0.3202, CIR-1: 0.6443, RMSE: 1.8244, MAE: 1.2934\n",
      "2000/2188, acc: 0.3185, CIR-1: 0.6428, RMSE: 1.8309, MAE: 1.2993\n",
      "train Loss: 7.8314 Acc: 0.3180 CIR-1: 0.6428 RMSE 1.8312 MAE 1.3005\n",
      "val Loss: 7.8380 Acc: 0.3155 CIR-1: 0.6381 RMSE 1.8401 MAE 1.3125\n",
      "\n",
      "Epoch 26/179\n",
      "----------\n",
      "500/2188, acc: 0.3194, CIR-1: 0.6438, RMSE: 1.8081, MAE: 1.2845\n",
      "1000/2188, acc: 0.3177, CIR-1: 0.6408, RMSE: 1.8244, MAE: 1.2968\n",
      "1500/2188, acc: 0.3178, CIR-1: 0.6432, RMSE: 1.8225, MAE: 1.2948\n",
      "2000/2188, acc: 0.3181, CIR-1: 0.6444, RMSE: 1.8186, MAE: 1.2919\n",
      "train Loss: 7.8287 Acc: 0.3180 CIR-1: 0.6437 RMSE 1.8217 MAE 1.2950\n",
      "val Loss: 7.8364 Acc: 0.3082 CIR-1: 0.6291 RMSE 1.8309 MAE 1.3213\n",
      "\n",
      "Epoch 27/179\n",
      "----------\n",
      "500/2188, acc: 0.3174, CIR-1: 0.6478, RMSE: 1.7922, MAE: 1.2747\n",
      "1000/2188, acc: 0.3197, CIR-1: 0.6460, RMSE: 1.8023, MAE: 1.2810\n",
      "1500/2188, acc: 0.3191, CIR-1: 0.6458, RMSE: 1.8134, MAE: 1.2873\n",
      "2000/2188, acc: 0.3188, CIR-1: 0.6456, RMSE: 1.8155, MAE: 1.2891\n",
      "train Loss: 7.8281 Acc: 0.3193 CIR-1: 0.6462 RMSE 1.8168 MAE 1.2897\n",
      "val Loss: 7.8319 Acc: 0.3257 CIR-1: 0.6388 RMSE 1.8253 MAE 1.2940\n",
      "\n",
      "Epoch 28/179\n",
      "----------\n",
      "500/2188, acc: 0.3202, CIR-1: 0.6422, RMSE: 1.8188, MAE: 1.2907\n",
      "1000/2188, acc: 0.3195, CIR-1: 0.6432, RMSE: 1.8226, MAE: 1.2936\n",
      "1500/2188, acc: 0.3191, CIR-1: 0.6462, RMSE: 1.8198, MAE: 1.2906\n",
      "2000/2188, acc: 0.3200, CIR-1: 0.6480, RMSE: 1.8124, MAE: 1.2851\n",
      "train Loss: 7.8265 Acc: 0.3199 CIR-1: 0.6478 RMSE 1.8160 MAE 1.2880\n",
      "val Loss: 7.8480 Acc: 0.3308 CIR-1: 0.6452 RMSE 1.8861 MAE 1.3142\n",
      "\n",
      "Epoch 29/179\n",
      "----------\n",
      "500/2188, acc: 0.3185, CIR-1: 0.6454, RMSE: 1.8135, MAE: 1.2871\n",
      "1000/2188, acc: 0.3206, CIR-1: 0.6449, RMSE: 1.8144, MAE: 1.2879\n",
      "1500/2188, acc: 0.3214, CIR-1: 0.6448, RMSE: 1.8148, MAE: 1.2877\n",
      "2000/2188, acc: 0.3220, CIR-1: 0.6459, RMSE: 1.8136, MAE: 1.2855\n",
      "train Loss: 7.8265 Acc: 0.3218 CIR-1: 0.6461 RMSE 1.8139 MAE 1.2866\n",
      "val Loss: 7.8362 Acc: 0.3284 CIR-1: 0.6513 RMSE 1.8835 MAE 1.3116\n",
      "\n",
      "Epoch 30/179\n",
      "----------\n",
      "500/2188, acc: 0.3171, CIR-1: 0.6456, RMSE: 1.7998, MAE: 1.2797\n",
      "1000/2188, acc: 0.3192, CIR-1: 0.6487, RMSE: 1.8036, MAE: 1.2786\n",
      "1500/2188, acc: 0.3210, CIR-1: 0.6504, RMSE: 1.8027, MAE: 1.2759\n",
      "2000/2188, acc: 0.3213, CIR-1: 0.6500, RMSE: 1.8036, MAE: 1.2768\n",
      "train Loss: 7.8243 Acc: 0.3221 CIR-1: 0.6501 RMSE 1.8042 MAE 1.2770\n",
      "val Loss: 7.8648 Acc: 0.3113 CIR-1: 0.6167 RMSE 1.8990 MAE 1.3632\n",
      "\n",
      "Epoch 31/179\n",
      "----------\n",
      "500/2188, acc: 0.3221, CIR-1: 0.6521, RMSE: 1.7986, MAE: 1.2707\n",
      "1000/2188, acc: 0.3256, CIR-1: 0.6525, RMSE: 1.7937, MAE: 1.2658\n",
      "1500/2188, acc: 0.3253, CIR-1: 0.6517, RMSE: 1.7988, MAE: 1.2702\n",
      "2000/2188, acc: 0.3247, CIR-1: 0.6519, RMSE: 1.7963, MAE: 1.2697\n",
      "train Loss: 7.8225 Acc: 0.3241 CIR-1: 0.6518 RMSE 1.7955 MAE 1.2706\n",
      "val Loss: 7.8327 Acc: 0.3282 CIR-1: 0.6467 RMSE 1.8357 MAE 1.2914\n",
      "\n",
      "Epoch 32/179\n",
      "----------\n",
      "500/2188, acc: 0.3348, CIR-1: 0.6539, RMSE: 1.7951, MAE: 1.2554\n",
      "1000/2188, acc: 0.3288, CIR-1: 0.6545, RMSE: 1.7954, MAE: 1.2620\n",
      "1500/2188, acc: 0.3272, CIR-1: 0.6549, RMSE: 1.7978, MAE: 1.2649\n",
      "2000/2188, acc: 0.3275, CIR-1: 0.6542, RMSE: 1.7969, MAE: 1.2650\n",
      "train Loss: 7.8217 Acc: 0.3266 CIR-1: 0.6533 RMSE 1.7988 MAE 1.2685\n",
      "val Loss: 7.8384 Acc: 0.3306 CIR-1: 0.6475 RMSE 1.8378 MAE 1.2874\n",
      "\n",
      "Epoch 33/179\n",
      "----------\n",
      "500/2188, acc: 0.3257, CIR-1: 0.6564, RMSE: 1.7610, MAE: 1.2469\n",
      "1000/2188, acc: 0.3262, CIR-1: 0.6569, RMSE: 1.7680, MAE: 1.2509\n",
      "1500/2188, acc: 0.3262, CIR-1: 0.6563, RMSE: 1.7760, MAE: 1.2555\n",
      "2000/2188, acc: 0.3265, CIR-1: 0.6566, RMSE: 1.7788, MAE: 1.2567\n",
      "train Loss: 7.8193 Acc: 0.3269 CIR-1: 0.6564 RMSE 1.7810 MAE 1.2583\n",
      "val Loss: 7.8330 Acc: 0.3261 CIR-1: 0.6459 RMSE 1.8231 MAE 1.2881\n",
      "\n",
      "Epoch 34/179\n",
      "----------\n",
      "500/2188, acc: 0.3232, CIR-1: 0.6561, RMSE: 1.7765, MAE: 1.2562\n",
      "1000/2188, acc: 0.3231, CIR-1: 0.6549, RMSE: 1.7868, MAE: 1.2638\n",
      "1500/2188, acc: 0.3249, CIR-1: 0.6569, RMSE: 1.7829, MAE: 1.2590\n",
      "2000/2188, acc: 0.3254, CIR-1: 0.6578, RMSE: 1.7836, MAE: 1.2588\n",
      "train Loss: 7.8194 Acc: 0.3253 CIR-1: 0.6578 RMSE 1.7841 MAE 1.2599\n",
      "val Loss: 7.8280 Acc: 0.3262 CIR-1: 0.6423 RMSE 1.7904 MAE 1.2745\n",
      "\n",
      "Epoch 35/179\n",
      "----------\n",
      "500/2188, acc: 0.3272, CIR-1: 0.6566, RMSE: 1.7778, MAE: 1.2508\n",
      "1000/2188, acc: 0.3284, CIR-1: 0.6543, RMSE: 1.7892, MAE: 1.2594\n",
      "1500/2188, acc: 0.3302, CIR-1: 0.6576, RMSE: 1.7810, MAE: 1.2527\n",
      "2000/2188, acc: 0.3292, CIR-1: 0.6582, RMSE: 1.7826, MAE: 1.2545\n",
      "train Loss: 7.8174 Acc: 0.3299 CIR-1: 0.6587 RMSE 1.7799 MAE 1.2530\n",
      "val Loss: 7.8302 Acc: 0.3323 CIR-1: 0.6476 RMSE 1.8266 MAE 1.2823\n",
      "\n",
      "Epoch 36/179\n",
      "----------\n",
      "500/2188, acc: 0.3261, CIR-1: 0.6573, RMSE: 1.7610, MAE: 1.2449\n",
      "1000/2188, acc: 0.3273, CIR-1: 0.6588, RMSE: 1.7625, MAE: 1.2451\n",
      "1500/2188, acc: 0.3295, CIR-1: 0.6599, RMSE: 1.7666, MAE: 1.2450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2188, acc: 0.3306, CIR-1: 0.6605, RMSE: 1.7687, MAE: 1.2449\n",
      "train Loss: 7.8159 Acc: 0.3304 CIR-1: 0.6607 RMSE 1.7711 MAE 1.2469\n",
      "val Loss: 7.8318 Acc: 0.3369 CIR-1: 0.6558 RMSE 1.8487 MAE 1.2817\n",
      "\n",
      "Epoch 37/179\n",
      "----------\n",
      "500/2188, acc: 0.3294, CIR-1: 0.6617, RMSE: 1.7689, MAE: 1.2416\n",
      "1000/2188, acc: 0.3308, CIR-1: 0.6632, RMSE: 1.7609, MAE: 1.2374\n",
      "1500/2188, acc: 0.3312, CIR-1: 0.6630, RMSE: 1.7581, MAE: 1.2364\n",
      "2000/2188, acc: 0.3318, CIR-1: 0.6632, RMSE: 1.7603, MAE: 1.2369\n",
      "train Loss: 7.8139 Acc: 0.3317 CIR-1: 0.6635 RMSE 1.7626 MAE 1.2387\n",
      "val Loss: 7.8321 Acc: 0.3381 CIR-1: 0.6577 RMSE 1.8670 MAE 1.2903\n",
      "\n",
      "Epoch 38/179\n",
      "----------\n",
      "500/2188, acc: 0.3255, CIR-1: 0.6573, RMSE: 1.7650, MAE: 1.2466\n",
      "1000/2188, acc: 0.3277, CIR-1: 0.6578, RMSE: 1.7733, MAE: 1.2501\n",
      "1500/2188, acc: 0.3282, CIR-1: 0.6596, RMSE: 1.7711, MAE: 1.2474\n",
      "2000/2188, acc: 0.3308, CIR-1: 0.6607, RMSE: 1.7667, MAE: 1.2426\n",
      "train Loss: 7.8135 Acc: 0.3304 CIR-1: 0.6607 RMSE 1.7676 MAE 1.2443\n",
      "val Loss: 7.8258 Acc: 0.3352 CIR-1: 0.6616 RMSE 1.8106 MAE 1.2628\n",
      "\n",
      "Epoch 39/179\n",
      "----------\n",
      "500/2188, acc: 0.3343, CIR-1: 0.6647, RMSE: 1.7614, MAE: 1.2331\n",
      "1000/2188, acc: 0.3331, CIR-1: 0.6651, RMSE: 1.7589, MAE: 1.2330\n",
      "1500/2188, acc: 0.3336, CIR-1: 0.6654, RMSE: 1.7624, MAE: 1.2355\n",
      "2000/2188, acc: 0.3313, CIR-1: 0.6633, RMSE: 1.7653, MAE: 1.2403\n",
      "train Loss: 7.8135 Acc: 0.3311 CIR-1: 0.6636 RMSE 1.7659 MAE 1.2412\n",
      "val Loss: 7.8301 Acc: 0.3273 CIR-1: 0.6393 RMSE 1.8093 MAE 1.2853\n",
      "\n",
      "Epoch 40/179\n",
      "----------\n",
      "500/2188, acc: 0.3334, CIR-1: 0.6648, RMSE: 1.7661, MAE: 1.2359\n",
      "1000/2188, acc: 0.3341, CIR-1: 0.6646, RMSE: 1.7645, MAE: 1.2359\n",
      "1500/2188, acc: 0.3340, CIR-1: 0.6646, RMSE: 1.7599, MAE: 1.2341\n",
      "2000/2188, acc: 0.3330, CIR-1: 0.6645, RMSE: 1.7599, MAE: 1.2356\n",
      "train Loss: 7.8114 Acc: 0.3326 CIR-1: 0.6644 RMSE 1.7621 MAE 1.2379\n",
      "val Loss: 7.8270 Acc: 0.3346 CIR-1: 0.6489 RMSE 1.8202 MAE 1.2755\n",
      "\n",
      "Epoch 41/179\n",
      "----------\n",
      "500/2188, acc: 0.3344, CIR-1: 0.6672, RMSE: 1.7256, MAE: 1.2127\n",
      "1000/2188, acc: 0.3398, CIR-1: 0.6693, RMSE: 1.7354, MAE: 1.2126\n",
      "1500/2188, acc: 0.3362, CIR-1: 0.6661, RMSE: 1.7464, MAE: 1.2237\n",
      "2000/2188, acc: 0.3356, CIR-1: 0.6663, RMSE: 1.7445, MAE: 1.2239\n",
      "train Loss: 7.8099 Acc: 0.3355 CIR-1: 0.6661 RMSE 1.7487 MAE 1.2272\n",
      "val Loss: 7.8254 Acc: 0.3317 CIR-1: 0.6543 RMSE 1.7976 MAE 1.2657\n",
      "\n",
      "Epoch 42/179\n",
      "----------\n",
      "500/2188, acc: 0.3411, CIR-1: 0.6739, RMSE: 1.7208, MAE: 1.2006\n",
      "1000/2188, acc: 0.3358, CIR-1: 0.6717, RMSE: 1.7344, MAE: 1.2145\n",
      "1500/2188, acc: 0.3362, CIR-1: 0.6709, RMSE: 1.7431, MAE: 1.2196\n",
      "2000/2188, acc: 0.3357, CIR-1: 0.6702, RMSE: 1.7458, MAE: 1.2222\n",
      "train Loss: 7.8086 Acc: 0.3358 CIR-1: 0.6711 RMSE 1.7462 MAE 1.2225\n",
      "val Loss: 7.8264 Acc: 0.3339 CIR-1: 0.6497 RMSE 1.8169 MAE 1.2743\n",
      "\n",
      "Epoch 43/179\n",
      "----------\n",
      "500/2188, acc: 0.3373, CIR-1: 0.6686, RMSE: 1.7374, MAE: 1.2148\n",
      "1000/2188, acc: 0.3360, CIR-1: 0.6695, RMSE: 1.7398, MAE: 1.2179\n",
      "1500/2188, acc: 0.3361, CIR-1: 0.6698, RMSE: 1.7368, MAE: 1.2165\n",
      "2000/2188, acc: 0.3352, CIR-1: 0.6673, RMSE: 1.7429, MAE: 1.2225\n",
      "train Loss: 7.8082 Acc: 0.3350 CIR-1: 0.6670 RMSE 1.7445 MAE 1.2243\n",
      "val Loss: 7.8306 Acc: 0.3369 CIR-1: 0.6523 RMSE 1.8464 MAE 1.2851\n",
      "\n",
      "Epoch 44/179\n",
      "----------\n",
      "500/2188, acc: 0.3372, CIR-1: 0.6647, RMSE: 1.7382, MAE: 1.2182\n",
      "1000/2188, acc: 0.3340, CIR-1: 0.6635, RMSE: 1.7506, MAE: 1.2292\n",
      "1500/2188, acc: 0.3356, CIR-1: 0.6665, RMSE: 1.7430, MAE: 1.2230\n",
      "2000/2188, acc: 0.3366, CIR-1: 0.6676, RMSE: 1.7417, MAE: 1.2209\n",
      "train Loss: 7.8073 Acc: 0.3366 CIR-1: 0.6682 RMSE 1.7411 MAE 1.2208\n",
      "val Loss: 7.8256 Acc: 0.3289 CIR-1: 0.6501 RMSE 1.8225 MAE 1.2823\n",
      "\n",
      "Epoch 45/179\n",
      "----------\n",
      "500/2188, acc: 0.3404, CIR-1: 0.6740, RMSE: 1.7343, MAE: 1.2074\n",
      "1000/2188, acc: 0.3388, CIR-1: 0.6708, RMSE: 1.7417, MAE: 1.2165\n",
      "1500/2188, acc: 0.3385, CIR-1: 0.6718, RMSE: 1.7368, MAE: 1.2138\n",
      "2000/2188, acc: 0.3379, CIR-1: 0.6729, RMSE: 1.7346, MAE: 1.2132\n",
      "train Loss: 7.8054 Acc: 0.3375 CIR-1: 0.6728 RMSE 1.7357 MAE 1.2149\n",
      "val Loss: 7.8308 Acc: 0.3359 CIR-1: 0.6549 RMSE 1.8309 MAE 1.2779\n",
      "\n",
      "Epoch 46/179\n",
      "----------\n",
      "500/2188, acc: 0.3417, CIR-1: 0.6747, RMSE: 1.7232, MAE: 1.2021\n",
      "1000/2188, acc: 0.3407, CIR-1: 0.6712, RMSE: 1.7311, MAE: 1.2098\n",
      "1500/2188, acc: 0.3403, CIR-1: 0.6700, RMSE: 1.7349, MAE: 1.2131\n",
      "2000/2188, acc: 0.3406, CIR-1: 0.6699, RMSE: 1.7324, MAE: 1.2121\n",
      "train Loss: 7.8043 Acc: 0.3406 CIR-1: 0.6716 RMSE 1.7294 MAE 1.2102\n",
      "val Loss: 7.8332 Acc: 0.3405 CIR-1: 0.6603 RMSE 1.8587 MAE 1.2830\n",
      "\n",
      "Epoch 47/179\n",
      "----------\n",
      "500/2188, acc: 0.3376, CIR-1: 0.6696, RMSE: 1.7377, MAE: 1.2126\n",
      "1000/2188, acc: 0.3396, CIR-1: 0.6730, RMSE: 1.7343, MAE: 1.2092\n",
      "1500/2188, acc: 0.3393, CIR-1: 0.6748, RMSE: 1.7293, MAE: 1.2069\n",
      "2000/2188, acc: 0.3407, CIR-1: 0.6754, RMSE: 1.7276, MAE: 1.2047\n",
      "train Loss: 7.8044 Acc: 0.3405 CIR-1: 0.6752 RMSE 1.7307 MAE 1.2074\n",
      "val Loss: 7.8248 Acc: 0.3357 CIR-1: 0.6547 RMSE 1.8036 MAE 1.2631\n",
      "\n",
      "Epoch 48/179\n",
      "----------\n",
      "500/2188, acc: 0.3397, CIR-1: 0.6789, RMSE: 1.7128, MAE: 1.1946\n",
      "1000/2188, acc: 0.3382, CIR-1: 0.6778, RMSE: 1.7250, MAE: 1.2034\n",
      "1500/2188, acc: 0.3381, CIR-1: 0.6759, RMSE: 1.7231, MAE: 1.2044\n",
      "2000/2188, acc: 0.3396, CIR-1: 0.6765, RMSE: 1.7222, MAE: 1.2024\n",
      "train Loss: 7.8023 Acc: 0.3397 CIR-1: 0.6768 RMSE 1.7223 MAE 1.2027\n",
      "val Loss: 7.8309 Acc: 0.3435 CIR-1: 0.6643 RMSE 1.8266 MAE 1.2603\n",
      "\n",
      "Epoch 49/179\n",
      "----------\n",
      "500/2188, acc: 0.3349, CIR-1: 0.6789, RMSE: 1.7113, MAE: 1.1976\n",
      "1000/2188, acc: 0.3353, CIR-1: 0.6783, RMSE: 1.7096, MAE: 1.1988\n",
      "1500/2188, acc: 0.3367, CIR-1: 0.6762, RMSE: 1.7189, MAE: 1.2039\n",
      "2000/2188, acc: 0.3389, CIR-1: 0.6760, RMSE: 1.7203, MAE: 1.2032\n",
      "train Loss: 7.8023 Acc: 0.3394 CIR-1: 0.6765 RMSE 1.7207 MAE 1.2035\n",
      "val Loss: 7.8248 Acc: 0.3396 CIR-1: 0.6607 RMSE 1.8196 MAE 1.2622\n",
      "\n",
      "Epoch 50/179\n",
      "----------\n",
      "500/2188, acc: 0.3424, CIR-1: 0.6735, RMSE: 1.7132, MAE: 1.1951\n",
      "1000/2188, acc: 0.3453, CIR-1: 0.6780, RMSE: 1.7074, MAE: 1.1879\n",
      "1500/2188, acc: 0.3439, CIR-1: 0.6777, RMSE: 1.7099, MAE: 1.1915\n",
      "2000/2188, acc: 0.3433, CIR-1: 0.6782, RMSE: 1.7094, MAE: 1.1915\n",
      "train Loss: 7.7993 Acc: 0.3431 CIR-1: 0.6781 RMSE 1.7108 MAE 1.1932\n",
      "val Loss: 7.8282 Acc: 0.3353 CIR-1: 0.6639 RMSE 1.8461 MAE 1.2799\n",
      "\n",
      "Epoch 51/179\n",
      "----------\n",
      "500/2188, acc: 0.3421, CIR-1: 0.6827, RMSE: 1.6967, MAE: 1.1829\n",
      "1000/2188, acc: 0.3432, CIR-1: 0.6830, RMSE: 1.6985, MAE: 1.1843\n",
      "1500/2188, acc: 0.3442, CIR-1: 0.6838, RMSE: 1.6960, MAE: 1.1816\n",
      "2000/2188, acc: 0.3432, CIR-1: 0.6828, RMSE: 1.7040, MAE: 1.1867\n",
      "train Loss: 7.7984 Acc: 0.3429 CIR-1: 0.6817 RMSE 1.7076 MAE 1.1903\n",
      "val Loss: 7.8262 Acc: 0.3317 CIR-1: 0.6557 RMSE 1.8064 MAE 1.2685\n",
      "\n",
      "Epoch 52/179\n",
      "----------\n",
      "500/2188, acc: 0.3458, CIR-1: 0.6828, RMSE: 1.6971, MAE: 1.1791\n",
      "1000/2188, acc: 0.3438, CIR-1: 0.6842, RMSE: 1.7009, MAE: 1.1837\n",
      "1500/2188, acc: 0.3449, CIR-1: 0.6829, RMSE: 1.6998, MAE: 1.1829\n",
      "2000/2188, acc: 0.3454, CIR-1: 0.6819, RMSE: 1.7033, MAE: 1.1849\n",
      "train Loss: 7.7981 Acc: 0.3453 CIR-1: 0.6820 RMSE 1.7058 MAE 1.1868\n",
      "val Loss: 7.8239 Acc: 0.3434 CIR-1: 0.6665 RMSE 1.7998 MAE 1.2473\n",
      "\n",
      "Epoch 53/179\n",
      "----------\n",
      "500/2188, acc: 0.3476, CIR-1: 0.6820, RMSE: 1.6971, MAE: 1.1772\n",
      "1000/2188, acc: 0.3485, CIR-1: 0.6820, RMSE: 1.6898, MAE: 1.1743\n",
      "1500/2188, acc: 0.3465, CIR-1: 0.6822, RMSE: 1.6934, MAE: 1.1782\n",
      "2000/2188, acc: 0.3469, CIR-1: 0.6821, RMSE: 1.6953, MAE: 1.1792\n",
      "train Loss: 7.7961 Acc: 0.3467 CIR-1: 0.6818 RMSE 1.6984 MAE 1.1821\n",
      "val Loss: 7.8270 Acc: 0.3295 CIR-1: 0.6570 RMSE 1.7946 MAE 1.2643\n",
      "\n",
      "Epoch 54/179\n",
      "----------\n",
      "500/2188, acc: 0.3438, CIR-1: 0.6817, RMSE: 1.6861, MAE: 1.1751\n",
      "1000/2188, acc: 0.3458, CIR-1: 0.6833, RMSE: 1.7037, MAE: 1.1819\n",
      "1500/2188, acc: 0.3434, CIR-1: 0.6835, RMSE: 1.7023, MAE: 1.1842\n",
      "2000/2188, acc: 0.3432, CIR-1: 0.6828, RMSE: 1.7032, MAE: 1.1858\n",
      "train Loss: 7.7973 Acc: 0.3438 CIR-1: 0.6840 RMSE 1.7029 MAE 1.1849\n",
      "val Loss: 7.8341 Acc: 0.3423 CIR-1: 0.6648 RMSE 1.8445 MAE 1.2707\n",
      "\n",
      "Epoch 55/179\n",
      "----------\n",
      "500/2188, acc: 0.3394, CIR-1: 0.6838, RMSE: 1.6892, MAE: 1.1781\n",
      "1000/2188, acc: 0.3448, CIR-1: 0.6866, RMSE: 1.6861, MAE: 1.1723\n",
      "1500/2188, acc: 0.3466, CIR-1: 0.6864, RMSE: 1.6893, MAE: 1.1729\n",
      "2000/2188, acc: 0.3460, CIR-1: 0.6840, RMSE: 1.6948, MAE: 1.1778\n",
      "train Loss: 7.7951 Acc: 0.3467 CIR-1: 0.6848 RMSE 1.6935 MAE 1.1769\n",
      "val Loss: 7.8391 Acc: 0.3265 CIR-1: 0.6481 RMSE 1.7721 MAE 1.2605\n",
      "\n",
      "Epoch 56/179\n",
      "----------\n",
      "500/2188, acc: 0.3442, CIR-1: 0.6882, RMSE: 1.6684, MAE: 1.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/2188, acc: 0.3475, CIR-1: 0.6907, RMSE: 1.6711, MAE: 1.1612\n",
      "1500/2188, acc: 0.3458, CIR-1: 0.6891, RMSE: 1.6810, MAE: 1.1690\n",
      "2000/2188, acc: 0.3467, CIR-1: 0.6881, RMSE: 1.6853, MAE: 1.1709\n",
      "train Loss: 7.7935 Acc: 0.3470 CIR-1: 0.6882 RMSE 1.6876 MAE 1.1723\n",
      "val Loss: 7.8309 Acc: 0.3371 CIR-1: 0.6615 RMSE 1.8337 MAE 1.2721\n",
      "\n",
      "Epoch 57/179\n",
      "----------\n",
      "500/2188, acc: 0.3412, CIR-1: 0.6869, RMSE: 1.6897, MAE: 1.1743\n",
      "1000/2188, acc: 0.3435, CIR-1: 0.6867, RMSE: 1.6895, MAE: 1.1745\n",
      "1500/2188, acc: 0.3449, CIR-1: 0.6853, RMSE: 1.6903, MAE: 1.1755\n",
      "2000/2188, acc: 0.3446, CIR-1: 0.6863, RMSE: 1.6862, MAE: 1.1738\n",
      "train Loss: 7.7944 Acc: 0.3456 CIR-1: 0.6859 RMSE 1.6899 MAE 1.1756\n",
      "val Loss: 7.8284 Acc: 0.3355 CIR-1: 0.6543 RMSE 1.8274 MAE 1.2753\n",
      "\n",
      "Epoch 58/179\n",
      "----------\n",
      "500/2188, acc: 0.3539, CIR-1: 0.6925, RMSE: 1.6710, MAE: 1.1513\n",
      "1000/2188, acc: 0.3514, CIR-1: 0.6924, RMSE: 1.6738, MAE: 1.1567\n",
      "1500/2188, acc: 0.3504, CIR-1: 0.6914, RMSE: 1.6787, MAE: 1.1615\n",
      "2000/2188, acc: 0.3496, CIR-1: 0.6918, RMSE: 1.6777, MAE: 1.1617\n",
      "train Loss: 7.7908 Acc: 0.3499 CIR-1: 0.6925 RMSE 1.6772 MAE 1.1616\n",
      "val Loss: 7.8335 Acc: 0.3341 CIR-1: 0.6531 RMSE 1.7974 MAE 1.2639\n",
      "\n",
      "Epoch 59/179\n",
      "----------\n",
      "500/2188, acc: 0.3439, CIR-1: 0.6949, RMSE: 1.6670, MAE: 1.1557\n",
      "1000/2188, acc: 0.3491, CIR-1: 0.6921, RMSE: 1.6767, MAE: 1.1599\n",
      "1500/2188, acc: 0.3483, CIR-1: 0.6905, RMSE: 1.6790, MAE: 1.1636\n",
      "2000/2188, acc: 0.3480, CIR-1: 0.6904, RMSE: 1.6764, MAE: 1.1632\n",
      "train Loss: 7.7909 Acc: 0.3479 CIR-1: 0.6906 RMSE 1.6782 MAE 1.1647\n",
      "val Loss: 7.8224 Acc: 0.3377 CIR-1: 0.6579 RMSE 1.7838 MAE 1.2469\n",
      "\n",
      "Epoch 60/179\n",
      "----------\n",
      "LR is set to 0.010000000000000002\n",
      "500/2188, acc: 0.3578, CIR-1: 0.6996, RMSE: 1.6156, MAE: 1.1174\n",
      "1000/2188, acc: 0.3621, CIR-1: 0.7033, RMSE: 1.6082, MAE: 1.1086\n",
      "1500/2188, acc: 0.3613, CIR-1: 0.7042, RMSE: 1.6045, MAE: 1.1079\n",
      "2000/2188, acc: 0.3605, CIR-1: 0.7053, RMSE: 1.6066, MAE: 1.1089\n",
      "train Loss: 7.7729 Acc: 0.3612 CIR-1: 0.7067 RMSE 1.6082 MAE 1.1090\n",
      "val Loss: 7.8134 Acc: 0.3427 CIR-1: 0.6761 RMSE 1.7747 MAE 1.2262\n",
      "\n",
      "Epoch 61/179\n",
      "----------\n",
      "500/2188, acc: 0.3658, CIR-1: 0.7121, RMSE: 1.5871, MAE: 1.0887\n",
      "1000/2188, acc: 0.3658, CIR-1: 0.7119, RMSE: 1.5890, MAE: 1.0910\n",
      "1500/2188, acc: 0.3673, CIR-1: 0.7133, RMSE: 1.5921, MAE: 1.0906\n",
      "2000/2188, acc: 0.3654, CIR-1: 0.7127, RMSE: 1.5955, MAE: 1.0947\n",
      "train Loss: 7.7693 Acc: 0.3653 CIR-1: 0.7130 RMSE 1.5950 MAE 1.0952\n",
      "val Loss: 7.8142 Acc: 0.3416 CIR-1: 0.6728 RMSE 1.7788 MAE 1.2325\n",
      "\n",
      "Epoch 62/179\n",
      "----------\n",
      "500/2188, acc: 0.3598, CIR-1: 0.7140, RMSE: 1.5970, MAE: 1.0972\n",
      "1000/2188, acc: 0.3599, CIR-1: 0.7128, RMSE: 1.5979, MAE: 1.1009\n",
      "1500/2188, acc: 0.3628, CIR-1: 0.7136, RMSE: 1.5930, MAE: 1.0956\n",
      "2000/2188, acc: 0.3620, CIR-1: 0.7117, RMSE: 1.5958, MAE: 1.0991\n",
      "train Loss: 7.7688 Acc: 0.3626 CIR-1: 0.7126 RMSE 1.5947 MAE 1.0983\n",
      "val Loss: 7.8149 Acc: 0.3419 CIR-1: 0.6736 RMSE 1.7787 MAE 1.2322\n",
      "\n",
      "Epoch 63/179\n",
      "----------\n",
      "500/2188, acc: 0.3656, CIR-1: 0.7122, RMSE: 1.5896, MAE: 1.0902\n",
      "1000/2188, acc: 0.3635, CIR-1: 0.7153, RMSE: 1.5802, MAE: 1.0880\n",
      "1500/2188, acc: 0.3645, CIR-1: 0.7147, RMSE: 1.5817, MAE: 1.0880\n",
      "2000/2188, acc: 0.3633, CIR-1: 0.7150, RMSE: 1.5877, MAE: 1.0919\n",
      "train Loss: 7.7676 Acc: 0.3642 CIR-1: 0.7160 RMSE 1.5864 MAE 1.0908\n",
      "val Loss: 7.8150 Acc: 0.3427 CIR-1: 0.6734 RMSE 1.7693 MAE 1.2263\n",
      "\n",
      "Epoch 64/179\n",
      "----------\n",
      "500/2188, acc: 0.3638, CIR-1: 0.7232, RMSE: 1.5647, MAE: 1.0740\n",
      "1000/2188, acc: 0.3636, CIR-1: 0.7205, RMSE: 1.5751, MAE: 1.0821\n",
      "1500/2188, acc: 0.3660, CIR-1: 0.7202, RMSE: 1.5768, MAE: 1.0812\n",
      "2000/2188, acc: 0.3643, CIR-1: 0.7174, RMSE: 1.5853, MAE: 1.0887\n",
      "train Loss: 7.7669 Acc: 0.3645 CIR-1: 0.7174 RMSE 1.5837 MAE 1.0885\n",
      "val Loss: 7.8147 Acc: 0.3488 CIR-1: 0.6714 RMSE 1.7836 MAE 1.2281\n",
      "\n",
      "Epoch 65/179\n",
      "----------\n",
      "500/2188, acc: 0.3641, CIR-1: 0.7202, RMSE: 1.5632, MAE: 1.0745\n",
      "1000/2188, acc: 0.3633, CIR-1: 0.7192, RMSE: 1.5699, MAE: 1.0809\n",
      "1500/2188, acc: 0.3625, CIR-1: 0.7174, RMSE: 1.5785, MAE: 1.0871\n",
      "2000/2188, acc: 0.3630, CIR-1: 0.7174, RMSE: 1.5780, MAE: 1.0866\n",
      "train Loss: 7.7656 Acc: 0.3635 CIR-1: 0.7182 RMSE 1.5763 MAE 1.0855\n",
      "val Loss: 7.8167 Acc: 0.3493 CIR-1: 0.6723 RMSE 1.7969 MAE 1.2342\n",
      "\n",
      "Epoch 66/179\n",
      "----------\n",
      "500/2188, acc: 0.3704, CIR-1: 0.7230, RMSE: 1.5667, MAE: 1.0701\n",
      "1000/2188, acc: 0.3670, CIR-1: 0.7203, RMSE: 1.5800, MAE: 1.0814\n",
      "1500/2188, acc: 0.3677, CIR-1: 0.7195, RMSE: 1.5818, MAE: 1.0825\n",
      "2000/2188, acc: 0.3674, CIR-1: 0.7195, RMSE: 1.5777, MAE: 1.0813\n",
      "train Loss: 7.7648 Acc: 0.3673 CIR-1: 0.7203 RMSE 1.5778 MAE 1.0816\n",
      "val Loss: 7.8158 Acc: 0.3433 CIR-1: 0.6717 RMSE 1.7822 MAE 1.2331\n",
      "\n",
      "Epoch 67/179\n",
      "----------\n",
      "500/2188, acc: 0.3576, CIR-1: 0.7076, RMSE: 1.6008, MAE: 1.1059\n",
      "1000/2188, acc: 0.3617, CIR-1: 0.7140, RMSE: 1.5895, MAE: 1.0939\n",
      "1500/2188, acc: 0.3635, CIR-1: 0.7170, RMSE: 1.5770, MAE: 1.0858\n",
      "2000/2188, acc: 0.3648, CIR-1: 0.7170, RMSE: 1.5766, MAE: 1.0847\n",
      "train Loss: 7.7646 Acc: 0.3659 CIR-1: 0.7178 RMSE 1.5747 MAE 1.0832\n",
      "val Loss: 7.8148 Acc: 0.3465 CIR-1: 0.6717 RMSE 1.7882 MAE 1.2322\n",
      "\n",
      "Epoch 68/179\n",
      "----------\n",
      "500/2188, acc: 0.3693, CIR-1: 0.7204, RMSE: 1.5585, MAE: 1.0682\n",
      "1000/2188, acc: 0.3699, CIR-1: 0.7221, RMSE: 1.5636, MAE: 1.0703\n",
      "1500/2188, acc: 0.3682, CIR-1: 0.7214, RMSE: 1.5680, MAE: 1.0745\n",
      "2000/2188, acc: 0.3672, CIR-1: 0.7210, RMSE: 1.5698, MAE: 1.0767\n",
      "train Loss: 7.7635 Acc: 0.3672 CIR-1: 0.7213 RMSE 1.5695 MAE 1.0771\n",
      "val Loss: 7.8164 Acc: 0.3449 CIR-1: 0.6709 RMSE 1.7746 MAE 1.2284\n",
      "\n",
      "Epoch 69/179\n",
      "----------\n",
      "500/2188, acc: 0.3630, CIR-1: 0.7197, RMSE: 1.5819, MAE: 1.0826\n",
      "1000/2188, acc: 0.3649, CIR-1: 0.7220, RMSE: 1.5642, MAE: 1.0744\n",
      "1500/2188, acc: 0.3657, CIR-1: 0.7225, RMSE: 1.5669, MAE: 1.0751\n",
      "2000/2188, acc: 0.3652, CIR-1: 0.7224, RMSE: 1.5717, MAE: 1.0783\n",
      "train Loss: 7.7633 Acc: 0.3660 CIR-1: 0.7228 RMSE 1.5722 MAE 1.0784\n",
      "val Loss: 7.8155 Acc: 0.3479 CIR-1: 0.6770 RMSE 1.7852 MAE 1.2259\n",
      "\n",
      "Epoch 70/179\n",
      "----------\n",
      "500/2188, acc: 0.3666, CIR-1: 0.7173, RMSE: 1.5635, MAE: 1.0751\n",
      "1000/2188, acc: 0.3661, CIR-1: 0.7191, RMSE: 1.5649, MAE: 1.0768\n",
      "1500/2188, acc: 0.3653, CIR-1: 0.7188, RMSE: 1.5691, MAE: 1.0795\n",
      "2000/2188, acc: 0.3665, CIR-1: 0.7194, RMSE: 1.5694, MAE: 1.0785\n",
      "train Loss: 7.7638 Acc: 0.3670 CIR-1: 0.7200 RMSE 1.5693 MAE 1.0785\n",
      "val Loss: 7.8160 Acc: 0.3475 CIR-1: 0.6730 RMSE 1.7796 MAE 1.2268\n",
      "\n",
      "Epoch 71/179\n",
      "----------\n",
      "500/2188, acc: 0.3648, CIR-1: 0.7242, RMSE: 1.5477, MAE: 1.0648\n",
      "1000/2188, acc: 0.3671, CIR-1: 0.7247, RMSE: 1.5532, MAE: 1.0667\n",
      "1500/2188, acc: 0.3687, CIR-1: 0.7250, RMSE: 1.5532, MAE: 1.0653\n",
      "2000/2188, acc: 0.3690, CIR-1: 0.7247, RMSE: 1.5564, MAE: 1.0670\n",
      "train Loss: 7.7624 Acc: 0.3675 CIR-1: 0.7232 RMSE 1.5630 MAE 1.0730\n",
      "val Loss: 7.8143 Acc: 0.3435 CIR-1: 0.6755 RMSE 1.7624 MAE 1.2214\n",
      "\n",
      "Epoch 72/179\n",
      "----------\n",
      "500/2188, acc: 0.3698, CIR-1: 0.7192, RMSE: 1.5601, MAE: 1.0695\n",
      "1000/2188, acc: 0.3709, CIR-1: 0.7214, RMSE: 1.5590, MAE: 1.0677\n",
      "1500/2188, acc: 0.3699, CIR-1: 0.7221, RMSE: 1.5624, MAE: 1.0704\n",
      "2000/2188, acc: 0.3688, CIR-1: 0.7220, RMSE: 1.5650, MAE: 1.0727\n",
      "train Loss: 7.7626 Acc: 0.3695 CIR-1: 0.7221 RMSE 1.5671 MAE 1.0738\n",
      "val Loss: 7.8172 Acc: 0.3493 CIR-1: 0.6710 RMSE 1.7909 MAE 1.2321\n",
      "\n",
      "Epoch 73/179\n",
      "----------\n",
      "500/2188, acc: 0.3758, CIR-1: 0.7264, RMSE: 1.5518, MAE: 1.0540\n",
      "1000/2188, acc: 0.3719, CIR-1: 0.7233, RMSE: 1.5592, MAE: 1.0650\n",
      "1500/2188, acc: 0.3711, CIR-1: 0.7219, RMSE: 1.5650, MAE: 1.0700\n",
      "2000/2188, acc: 0.3690, CIR-1: 0.7221, RMSE: 1.5626, MAE: 1.0711\n",
      "train Loss: 7.7620 Acc: 0.3688 CIR-1: 0.7228 RMSE 1.5627 MAE 1.0716\n",
      "val Loss: 7.8165 Acc: 0.3453 CIR-1: 0.6727 RMSE 1.7661 MAE 1.2239\n",
      "\n",
      "Epoch 74/179\n",
      "----------\n",
      "500/2188, acc: 0.3700, CIR-1: 0.7264, RMSE: 1.5466, MAE: 1.0577\n",
      "1000/2188, acc: 0.3715, CIR-1: 0.7233, RMSE: 1.5574, MAE: 1.0646\n",
      "1500/2188, acc: 0.3725, CIR-1: 0.7238, RMSE: 1.5603, MAE: 1.0657\n",
      "2000/2188, acc: 0.3716, CIR-1: 0.7238, RMSE: 1.5569, MAE: 1.0654\n",
      "train Loss: 7.7604 Acc: 0.3720 CIR-1: 0.7239 RMSE 1.5561 MAE 1.0654\n",
      "val Loss: 7.8167 Acc: 0.3453 CIR-1: 0.6691 RMSE 1.7819 MAE 1.2322\n",
      "\n",
      "Epoch 75/179\n",
      "----------\n",
      "500/2188, acc: 0.3721, CIR-1: 0.7291, RMSE: 1.5446, MAE: 1.0542\n",
      "1000/2188, acc: 0.3686, CIR-1: 0.7276, RMSE: 1.5534, MAE: 1.0634\n",
      "1500/2188, acc: 0.3701, CIR-1: 0.7285, RMSE: 1.5490, MAE: 1.0598\n",
      "2000/2188, acc: 0.3699, CIR-1: 0.7260, RMSE: 1.5527, MAE: 1.0635\n",
      "train Loss: 7.7603 Acc: 0.3697 CIR-1: 0.7258 RMSE 1.5557 MAE 1.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 7.8164 Acc: 0.3489 CIR-1: 0.6713 RMSE 1.7827 MAE 1.2284\n",
      "\n",
      "Epoch 76/179\n",
      "----------\n",
      "500/2188, acc: 0.3729, CIR-1: 0.7256, RMSE: 1.5523, MAE: 1.0572\n",
      "1000/2188, acc: 0.3743, CIR-1: 0.7278, RMSE: 1.5472, MAE: 1.0555\n",
      "1500/2188, acc: 0.3706, CIR-1: 0.7242, RMSE: 1.5537, MAE: 1.0643\n",
      "2000/2188, acc: 0.3702, CIR-1: 0.7249, RMSE: 1.5534, MAE: 1.0640\n",
      "train Loss: 7.7608 Acc: 0.3697 CIR-1: 0.7242 RMSE 1.5583 MAE 1.0680\n",
      "val Loss: 7.8164 Acc: 0.3459 CIR-1: 0.6735 RMSE 1.7817 MAE 1.2288\n",
      "\n",
      "Epoch 77/179\n",
      "----------\n",
      "500/2188, acc: 0.3736, CIR-1: 0.7256, RMSE: 1.5520, MAE: 1.0574\n",
      "1000/2188, acc: 0.3704, CIR-1: 0.7263, RMSE: 1.5511, MAE: 1.0610\n",
      "1500/2188, acc: 0.3723, CIR-1: 0.7271, RMSE: 1.5518, MAE: 1.0597\n",
      "2000/2188, acc: 0.3714, CIR-1: 0.7265, RMSE: 1.5495, MAE: 1.0602\n",
      "train Loss: 7.7597 Acc: 0.3718 CIR-1: 0.7263 RMSE 1.5520 MAE 1.0618\n",
      "val Loss: 7.8172 Acc: 0.3437 CIR-1: 0.6741 RMSE 1.7798 MAE 1.2299\n",
      "\n",
      "Epoch 78/179\n",
      "----------\n",
      "500/2188, acc: 0.3726, CIR-1: 0.7284, RMSE: 1.5532, MAE: 1.0568\n",
      "1000/2188, acc: 0.3702, CIR-1: 0.7258, RMSE: 1.5566, MAE: 1.0639\n",
      "1500/2188, acc: 0.3692, CIR-1: 0.7253, RMSE: 1.5535, MAE: 1.0646\n",
      "2000/2188, acc: 0.3702, CIR-1: 0.7270, RMSE: 1.5501, MAE: 1.0612\n",
      "train Loss: 7.7590 Acc: 0.3707 CIR-1: 0.7278 RMSE 1.5512 MAE 1.0613\n",
      "val Loss: 7.8195 Acc: 0.3485 CIR-1: 0.6737 RMSE 1.8012 MAE 1.2350\n",
      "\n",
      "Epoch 79/179\n",
      "----------\n",
      "500/2188, acc: 0.3673, CIR-1: 0.7262, RMSE: 1.5586, MAE: 1.0654\n",
      "1000/2188, acc: 0.3707, CIR-1: 0.7251, RMSE: 1.5502, MAE: 1.0616\n",
      "1500/2188, acc: 0.3698, CIR-1: 0.7273, RMSE: 1.5517, MAE: 1.0624\n",
      "2000/2188, acc: 0.3708, CIR-1: 0.7276, RMSE: 1.5522, MAE: 1.0616\n",
      "train Loss: 7.7592 Acc: 0.3709 CIR-1: 0.7278 RMSE 1.5527 MAE 1.0624\n",
      "val Loss: 7.8181 Acc: 0.3438 CIR-1: 0.6694 RMSE 1.7767 MAE 1.2316\n",
      "\n",
      "Epoch 80/179\n",
      "----------\n",
      "500/2188, acc: 0.3751, CIR-1: 0.7278, RMSE: 1.5158, MAE: 1.0396\n",
      "1000/2188, acc: 0.3732, CIR-1: 0.7288, RMSE: 1.5276, MAE: 1.0471\n",
      "1500/2188, acc: 0.3724, CIR-1: 0.7282, RMSE: 1.5373, MAE: 1.0533\n",
      "2000/2188, acc: 0.3705, CIR-1: 0.7263, RMSE: 1.5444, MAE: 1.0597\n",
      "train Loss: 7.7581 Acc: 0.3707 CIR-1: 0.7270 RMSE 1.5435 MAE 1.0595\n",
      "val Loss: 7.8189 Acc: 0.3463 CIR-1: 0.6717 RMSE 1.7953 MAE 1.2365\n",
      "\n",
      "Epoch 81/179\n",
      "----------\n",
      "500/2188, acc: 0.3727, CIR-1: 0.7256, RMSE: 1.5392, MAE: 1.0528\n",
      "1000/2188, acc: 0.3731, CIR-1: 0.7260, RMSE: 1.5465, MAE: 1.0563\n",
      "1500/2188, acc: 0.3745, CIR-1: 0.7276, RMSE: 1.5431, MAE: 1.0539\n",
      "2000/2188, acc: 0.3743, CIR-1: 0.7269, RMSE: 1.5438, MAE: 1.0555\n",
      "train Loss: 7.7575 Acc: 0.3750 CIR-1: 0.7279 RMSE 1.5425 MAE 1.0543\n",
      "val Loss: 7.8181 Acc: 0.3473 CIR-1: 0.6701 RMSE 1.7896 MAE 1.2331\n",
      "\n",
      "Epoch 82/179\n",
      "----------\n",
      "500/2188, acc: 0.3699, CIR-1: 0.7228, RMSE: 1.5481, MAE: 1.0603\n",
      "1000/2188, acc: 0.3696, CIR-1: 0.7244, RMSE: 1.5502, MAE: 1.0625\n",
      "1500/2188, acc: 0.3702, CIR-1: 0.7250, RMSE: 1.5531, MAE: 1.0634\n",
      "2000/2188, acc: 0.3694, CIR-1: 0.7264, RMSE: 1.5482, MAE: 1.0614\n",
      "train Loss: 7.7587 Acc: 0.3696 CIR-1: 0.7266 RMSE 1.5487 MAE 1.0619\n",
      "val Loss: 7.8186 Acc: 0.3501 CIR-1: 0.6731 RMSE 1.7872 MAE 1.2289\n",
      "\n",
      "Epoch 83/179\n",
      "----------\n",
      "500/2188, acc: 0.3675, CIR-1: 0.7270, RMSE: 1.5520, MAE: 1.0620\n",
      "1000/2188, acc: 0.3684, CIR-1: 0.7302, RMSE: 1.5469, MAE: 1.0582\n",
      "1500/2188, acc: 0.3679, CIR-1: 0.7298, RMSE: 1.5466, MAE: 1.0596\n",
      "2000/2188, acc: 0.3697, CIR-1: 0.7303, RMSE: 1.5442, MAE: 1.0573\n",
      "train Loss: 7.7567 Acc: 0.3709 CIR-1: 0.7313 RMSE 1.5411 MAE 1.0549\n",
      "val Loss: 7.8210 Acc: 0.3510 CIR-1: 0.6698 RMSE 1.8113 MAE 1.2397\n",
      "\n",
      "Epoch 84/179\n",
      "----------\n",
      "500/2188, acc: 0.3802, CIR-1: 0.7304, RMSE: 1.5160, MAE: 1.0338\n",
      "1000/2188, acc: 0.3743, CIR-1: 0.7294, RMSE: 1.5325, MAE: 1.0482\n",
      "1500/2188, acc: 0.3729, CIR-1: 0.7292, RMSE: 1.5373, MAE: 1.0522\n",
      "2000/2188, acc: 0.3755, CIR-1: 0.7305, RMSE: 1.5351, MAE: 1.0486\n",
      "train Loss: 7.7564 Acc: 0.3758 CIR-1: 0.7305 RMSE 1.5370 MAE 1.0496\n",
      "val Loss: 7.8176 Acc: 0.3512 CIR-1: 0.6731 RMSE 1.7914 MAE 1.2289\n",
      "\n",
      "Epoch 85/179\n",
      "----------\n",
      "500/2188, acc: 0.3720, CIR-1: 0.7251, RMSE: 1.5324, MAE: 1.0509\n",
      "1000/2188, acc: 0.3743, CIR-1: 0.7298, RMSE: 1.5324, MAE: 1.0471\n",
      "1500/2188, acc: 0.3744, CIR-1: 0.7295, RMSE: 1.5372, MAE: 1.0498\n",
      "2000/2188, acc: 0.3734, CIR-1: 0.7297, RMSE: 1.5369, MAE: 1.0508\n",
      "train Loss: 7.7567 Acc: 0.3729 CIR-1: 0.7291 RMSE 1.5390 MAE 1.0534\n",
      "val Loss: 7.8171 Acc: 0.3444 CIR-1: 0.6749 RMSE 1.7775 MAE 1.2275\n",
      "\n",
      "Epoch 86/179\n",
      "----------\n",
      "500/2188, acc: 0.3738, CIR-1: 0.7279, RMSE: 1.5382, MAE: 1.0493\n",
      "1000/2188, acc: 0.3746, CIR-1: 0.7294, RMSE: 1.5419, MAE: 1.0510\n",
      "1500/2188, acc: 0.3747, CIR-1: 0.7295, RMSE: 1.5391, MAE: 1.0500\n",
      "2000/2188, acc: 0.3736, CIR-1: 0.7288, RMSE: 1.5382, MAE: 1.0512\n",
      "train Loss: 7.7559 Acc: 0.3745 CIR-1: 0.7293 RMSE 1.5373 MAE 1.0507\n",
      "val Loss: 7.8182 Acc: 0.3463 CIR-1: 0.6725 RMSE 1.7847 MAE 1.2315\n",
      "\n",
      "Epoch 87/179\n",
      "----------\n",
      "500/2188, acc: 0.3749, CIR-1: 0.7271, RMSE: 1.5383, MAE: 1.0484\n",
      "1000/2188, acc: 0.3719, CIR-1: 0.7288, RMSE: 1.5388, MAE: 1.0523\n",
      "1500/2188, acc: 0.3730, CIR-1: 0.7294, RMSE: 1.5365, MAE: 1.0499\n",
      "2000/2188, acc: 0.3728, CIR-1: 0.7290, RMSE: 1.5343, MAE: 1.0501\n",
      "train Loss: 7.7550 Acc: 0.3731 CIR-1: 0.7299 RMSE 1.5327 MAE 1.0494\n",
      "val Loss: 7.8206 Acc: 0.3448 CIR-1: 0.6666 RMSE 1.7944 MAE 1.2407\n",
      "\n",
      "Epoch 88/179\n",
      "----------\n",
      "500/2188, acc: 0.3796, CIR-1: 0.7303, RMSE: 1.5301, MAE: 1.0405\n",
      "1000/2188, acc: 0.3777, CIR-1: 0.7288, RMSE: 1.5385, MAE: 1.0481\n",
      "1500/2188, acc: 0.3775, CIR-1: 0.7298, RMSE: 1.5389, MAE: 1.0477\n",
      "2000/2188, acc: 0.3766, CIR-1: 0.7304, RMSE: 1.5336, MAE: 1.0460\n",
      "train Loss: 7.7558 Acc: 0.3762 CIR-1: 0.7304 RMSE 1.5362 MAE 1.0480\n",
      "val Loss: 7.8175 Acc: 0.3482 CIR-1: 0.6713 RMSE 1.7767 MAE 1.2255\n",
      "\n",
      "Epoch 89/179\n",
      "----------\n",
      "500/2188, acc: 0.3701, CIR-1: 0.7264, RMSE: 1.5478, MAE: 1.0579\n",
      "1000/2188, acc: 0.3734, CIR-1: 0.7315, RMSE: 1.5413, MAE: 1.0506\n",
      "1500/2188, acc: 0.3742, CIR-1: 0.7322, RMSE: 1.5389, MAE: 1.0491\n",
      "2000/2188, acc: 0.3749, CIR-1: 0.7326, RMSE: 1.5351, MAE: 1.0467\n",
      "train Loss: 7.7551 Acc: 0.3751 CIR-1: 0.7326 RMSE 1.5364 MAE 1.0479\n",
      "val Loss: 7.8184 Acc: 0.3469 CIR-1: 0.6721 RMSE 1.7873 MAE 1.2321\n",
      "\n",
      "Epoch 90/179\n",
      "----------\n",
      "500/2188, acc: 0.3779, CIR-1: 0.7326, RMSE: 1.5289, MAE: 1.0391\n",
      "1000/2188, acc: 0.3779, CIR-1: 0.7326, RMSE: 1.5279, MAE: 1.0405\n",
      "1500/2188, acc: 0.3767, CIR-1: 0.7317, RMSE: 1.5354, MAE: 1.0455\n",
      "2000/2188, acc: 0.3760, CIR-1: 0.7310, RMSE: 1.5364, MAE: 1.0474\n",
      "train Loss: 7.7558 Acc: 0.3758 CIR-1: 0.7307 RMSE 1.5368 MAE 1.0489\n",
      "val Loss: 7.8187 Acc: 0.3491 CIR-1: 0.6767 RMSE 1.7931 MAE 1.2288\n",
      "\n",
      "Epoch 91/179\n",
      "----------\n",
      "500/2188, acc: 0.3732, CIR-1: 0.7328, RMSE: 1.5222, MAE: 1.0399\n",
      "1000/2188, acc: 0.3751, CIR-1: 0.7318, RMSE: 1.5260, MAE: 1.0423\n",
      "1500/2188, acc: 0.3747, CIR-1: 0.7325, RMSE: 1.5256, MAE: 1.0424\n",
      "2000/2188, acc: 0.3758, CIR-1: 0.7334, RMSE: 1.5271, MAE: 1.0419\n",
      "train Loss: 7.7541 Acc: 0.3759 CIR-1: 0.7333 RMSE 1.5286 MAE 1.0433\n",
      "val Loss: 7.8184 Acc: 0.3503 CIR-1: 0.6719 RMSE 1.7868 MAE 1.2283\n",
      "\n",
      "Epoch 92/179\n",
      "----------\n",
      "500/2188, acc: 0.3683, CIR-1: 0.7283, RMSE: 1.5231, MAE: 1.0479\n",
      "1000/2188, acc: 0.3733, CIR-1: 0.7307, RMSE: 1.5220, MAE: 1.0418\n",
      "1500/2188, acc: 0.3725, CIR-1: 0.7332, RMSE: 1.5243, MAE: 1.0424\n",
      "2000/2188, acc: 0.3711, CIR-1: 0.7330, RMSE: 1.5246, MAE: 1.0447\n",
      "train Loss: 7.7532 Acc: 0.3713 CIR-1: 0.7328 RMSE 1.5274 MAE 1.0470\n",
      "val Loss: 7.8190 Acc: 0.3485 CIR-1: 0.6722 RMSE 1.8002 MAE 1.2356\n",
      "\n",
      "Epoch 93/179\n",
      "----------\n",
      "500/2188, acc: 0.3797, CIR-1: 0.7333, RMSE: 1.5143, MAE: 1.0303\n",
      "1000/2188, acc: 0.3767, CIR-1: 0.7328, RMSE: 1.5190, MAE: 1.0376\n",
      "1500/2188, acc: 0.3766, CIR-1: 0.7349, RMSE: 1.5175, MAE: 1.0360\n",
      "2000/2188, acc: 0.3753, CIR-1: 0.7340, RMSE: 1.5205, MAE: 1.0393\n",
      "train Loss: 7.7522 Acc: 0.3756 CIR-1: 0.7346 RMSE 1.5209 MAE 1.0394\n",
      "val Loss: 7.8191 Acc: 0.3475 CIR-1: 0.6736 RMSE 1.7890 MAE 1.2315\n",
      "\n",
      "Epoch 94/179\n",
      "----------\n",
      "500/2188, acc: 0.3794, CIR-1: 0.7331, RMSE: 1.5085, MAE: 1.0291\n",
      "1000/2188, acc: 0.3766, CIR-1: 0.7342, RMSE: 1.5166, MAE: 1.0355\n",
      "1500/2188, acc: 0.3776, CIR-1: 0.7337, RMSE: 1.5212, MAE: 1.0376\n",
      "2000/2188, acc: 0.3763, CIR-1: 0.7341, RMSE: 1.5236, MAE: 1.0399\n",
      "train Loss: 7.7530 Acc: 0.3770 CIR-1: 0.7342 RMSE 1.5240 MAE 1.0401\n",
      "val Loss: 7.8182 Acc: 0.3458 CIR-1: 0.6748 RMSE 1.7883 MAE 1.2310\n",
      "\n",
      "Epoch 95/179\n",
      "----------\n",
      "500/2188, acc: 0.3778, CIR-1: 0.7382, RMSE: 1.5053, MAE: 1.0248\n",
      "1000/2188, acc: 0.3783, CIR-1: 0.7361, RMSE: 1.5163, MAE: 1.0322\n",
      "1500/2188, acc: 0.3763, CIR-1: 0.7335, RMSE: 1.5170, MAE: 1.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2188, acc: 0.3769, CIR-1: 0.7342, RMSE: 1.5171, MAE: 1.0357\n",
      "train Loss: 7.7519 Acc: 0.3765 CIR-1: 0.7345 RMSE 1.5183 MAE 1.0371\n",
      "val Loss: 7.8210 Acc: 0.3459 CIR-1: 0.6728 RMSE 1.7899 MAE 1.2341\n",
      "\n",
      "Epoch 96/179\n",
      "----------\n",
      "500/2188, acc: 0.3763, CIR-1: 0.7411, RMSE: 1.5136, MAE: 1.0279\n",
      "1000/2188, acc: 0.3768, CIR-1: 0.7385, RMSE: 1.5165, MAE: 1.0319\n",
      "1500/2188, acc: 0.3774, CIR-1: 0.7387, RMSE: 1.5118, MAE: 1.0303\n",
      "2000/2188, acc: 0.3777, CIR-1: 0.7371, RMSE: 1.5157, MAE: 1.0327\n",
      "train Loss: 7.7522 Acc: 0.3775 CIR-1: 0.7371 RMSE 1.5167 MAE 1.0342\n",
      "val Loss: 7.8219 Acc: 0.3519 CIR-1: 0.6717 RMSE 1.8043 MAE 1.2351\n",
      "\n",
      "Epoch 97/179\n",
      "----------\n",
      "500/2188, acc: 0.3772, CIR-1: 0.7409, RMSE: 1.4866, MAE: 1.0158\n",
      "1000/2188, acc: 0.3818, CIR-1: 0.7397, RMSE: 1.4974, MAE: 1.0188\n",
      "1500/2188, acc: 0.3790, CIR-1: 0.7387, RMSE: 1.5052, MAE: 1.0259\n",
      "2000/2188, acc: 0.3780, CIR-1: 0.7368, RMSE: 1.5125, MAE: 1.0317\n",
      "train Loss: 7.7511 Acc: 0.3779 CIR-1: 0.7363 RMSE 1.5146 MAE 1.0338\n",
      "val Loss: 7.8188 Acc: 0.3439 CIR-1: 0.6689 RMSE 1.7758 MAE 1.2312\n",
      "\n",
      "Epoch 98/179\n",
      "----------\n",
      "500/2188, acc: 0.3743, CIR-1: 0.7371, RMSE: 1.4973, MAE: 1.0241\n",
      "1000/2188, acc: 0.3727, CIR-1: 0.7357, RMSE: 1.5168, MAE: 1.0372\n",
      "1500/2188, acc: 0.3741, CIR-1: 0.7348, RMSE: 1.5162, MAE: 1.0374\n",
      "2000/2188, acc: 0.3756, CIR-1: 0.7363, RMSE: 1.5123, MAE: 1.0338\n",
      "train Loss: 7.7507 Acc: 0.3755 CIR-1: 0.7365 RMSE 1.5142 MAE 1.0354\n",
      "val Loss: 7.8205 Acc: 0.3441 CIR-1: 0.6723 RMSE 1.7887 MAE 1.2349\n",
      "\n",
      "Epoch 99/179\n",
      "----------\n",
      "500/2188, acc: 0.3736, CIR-1: 0.7338, RMSE: 1.5347, MAE: 1.0438\n",
      "1000/2188, acc: 0.3797, CIR-1: 0.7380, RMSE: 1.5195, MAE: 1.0308\n",
      "1500/2188, acc: 0.3775, CIR-1: 0.7367, RMSE: 1.5167, MAE: 1.0330\n",
      "2000/2188, acc: 0.3773, CIR-1: 0.7370, RMSE: 1.5155, MAE: 1.0330\n",
      "train Loss: 7.7504 Acc: 0.3778 CIR-1: 0.7370 RMSE 1.5155 MAE 1.0333\n",
      "val Loss: 7.8198 Acc: 0.3446 CIR-1: 0.6712 RMSE 1.7963 MAE 1.2381\n",
      "\n",
      "Epoch 100/179\n",
      "----------\n",
      "500/2188, acc: 0.3836, CIR-1: 0.7428, RMSE: 1.4842, MAE: 1.0077\n",
      "1000/2188, acc: 0.3824, CIR-1: 0.7405, RMSE: 1.4939, MAE: 1.0164\n",
      "1500/2188, acc: 0.3805, CIR-1: 0.7376, RMSE: 1.5078, MAE: 1.0264\n",
      "2000/2188, acc: 0.3802, CIR-1: 0.7371, RMSE: 1.5131, MAE: 1.0295\n",
      "train Loss: 7.7514 Acc: 0.3792 CIR-1: 0.7369 RMSE 1.5183 MAE 1.0336\n",
      "val Loss: 7.8209 Acc: 0.3408 CIR-1: 0.6654 RMSE 1.7988 MAE 1.2478\n",
      "\n",
      "Epoch 101/179\n",
      "----------\n",
      "500/2188, acc: 0.3760, CIR-1: 0.7358, RMSE: 1.5064, MAE: 1.0282\n",
      "1000/2188, acc: 0.3800, CIR-1: 0.7393, RMSE: 1.5040, MAE: 1.0230\n",
      "1500/2188, acc: 0.3810, CIR-1: 0.7384, RMSE: 1.5027, MAE: 1.0228\n",
      "2000/2188, acc: 0.3798, CIR-1: 0.7374, RMSE: 1.5083, MAE: 1.0274\n",
      "train Loss: 7.7503 Acc: 0.3800 CIR-1: 0.7374 RMSE 1.5111 MAE 1.0291\n",
      "val Loss: 7.8206 Acc: 0.3437 CIR-1: 0.6705 RMSE 1.7920 MAE 1.2371\n",
      "\n",
      "Epoch 102/179\n",
      "----------\n",
      "500/2188, acc: 0.3781, CIR-1: 0.7341, RMSE: 1.5153, MAE: 1.0321\n",
      "1000/2188, acc: 0.3796, CIR-1: 0.7372, RMSE: 1.5082, MAE: 1.0268\n",
      "1500/2188, acc: 0.3790, CIR-1: 0.7396, RMSE: 1.5021, MAE: 1.0240\n",
      "2000/2188, acc: 0.3776, CIR-1: 0.7386, RMSE: 1.5076, MAE: 1.0285\n",
      "train Loss: 7.7493 Acc: 0.3786 CIR-1: 0.7396 RMSE 1.5064 MAE 1.0272\n",
      "val Loss: 7.8218 Acc: 0.3501 CIR-1: 0.6692 RMSE 1.8142 MAE 1.2434\n",
      "\n",
      "Epoch 103/179\n",
      "----------\n",
      "500/2188, acc: 0.3763, CIR-1: 0.7382, RMSE: 1.5000, MAE: 1.0237\n",
      "1000/2188, acc: 0.3770, CIR-1: 0.7392, RMSE: 1.5075, MAE: 1.0272\n",
      "1500/2188, acc: 0.3773, CIR-1: 0.7394, RMSE: 1.5079, MAE: 1.0280\n",
      "2000/2188, acc: 0.3773, CIR-1: 0.7389, RMSE: 1.5076, MAE: 1.0281\n",
      "train Loss: 7.7497 Acc: 0.3771 CIR-1: 0.7394 RMSE 1.5093 MAE 1.0295\n",
      "val Loss: 7.8238 Acc: 0.3485 CIR-1: 0.6734 RMSE 1.8144 MAE 1.2433\n",
      "\n",
      "Epoch 104/179\n",
      "----------\n",
      "500/2188, acc: 0.3806, CIR-1: 0.7396, RMSE: 1.5045, MAE: 1.0208\n",
      "1000/2188, acc: 0.3788, CIR-1: 0.7392, RMSE: 1.5051, MAE: 1.0252\n",
      "1500/2188, acc: 0.3811, CIR-1: 0.7408, RMSE: 1.5021, MAE: 1.0216\n",
      "2000/2188, acc: 0.3823, CIR-1: 0.7410, RMSE: 1.5028, MAE: 1.0210\n",
      "train Loss: 7.7482 Acc: 0.3828 CIR-1: 0.7410 RMSE 1.5032 MAE 1.0216\n",
      "val Loss: 7.8207 Acc: 0.3500 CIR-1: 0.6707 RMSE 1.8104 MAE 1.2408\n",
      "\n",
      "Epoch 105/179\n",
      "----------\n",
      "500/2188, acc: 0.3797, CIR-1: 0.7379, RMSE: 1.5079, MAE: 1.0243\n",
      "1000/2188, acc: 0.3798, CIR-1: 0.7375, RMSE: 1.5017, MAE: 1.0237\n",
      "1500/2188, acc: 0.3787, CIR-1: 0.7377, RMSE: 1.5063, MAE: 1.0269\n",
      "2000/2188, acc: 0.3790, CIR-1: 0.7392, RMSE: 1.5073, MAE: 1.0267\n",
      "train Loss: 7.7492 Acc: 0.3791 CIR-1: 0.7400 RMSE 1.5056 MAE 1.0262\n",
      "val Loss: 7.8225 Acc: 0.3481 CIR-1: 0.6717 RMSE 1.8086 MAE 1.2420\n",
      "\n",
      "Epoch 106/179\n",
      "----------\n",
      "500/2188, acc: 0.3859, CIR-1: 0.7410, RMSE: 1.4858, MAE: 1.0088\n",
      "1000/2188, acc: 0.3816, CIR-1: 0.7398, RMSE: 1.4924, MAE: 1.0173\n",
      "1500/2188, acc: 0.3810, CIR-1: 0.7388, RMSE: 1.5006, MAE: 1.0223\n",
      "2000/2188, acc: 0.3796, CIR-1: 0.7394, RMSE: 1.5014, MAE: 1.0237\n",
      "train Loss: 7.7482 Acc: 0.3804 CIR-1: 0.7398 RMSE 1.5000 MAE 1.0229\n",
      "val Loss: 7.8219 Acc: 0.3497 CIR-1: 0.6723 RMSE 1.8031 MAE 1.2363\n",
      "\n",
      "Epoch 107/179\n",
      "----------\n",
      "500/2188, acc: 0.3851, CIR-1: 0.7403, RMSE: 1.5013, MAE: 1.0157\n",
      "1000/2188, acc: 0.3821, CIR-1: 0.7436, RMSE: 1.4947, MAE: 1.0142\n",
      "1500/2188, acc: 0.3828, CIR-1: 0.7449, RMSE: 1.4945, MAE: 1.0134\n",
      "2000/2188, acc: 0.3817, CIR-1: 0.7431, RMSE: 1.4998, MAE: 1.0182\n",
      "train Loss: 7.7484 Acc: 0.3805 CIR-1: 0.7427 RMSE 1.5025 MAE 1.0214\n",
      "val Loss: 7.8235 Acc: 0.3505 CIR-1: 0.6662 RMSE 1.8044 MAE 1.2408\n",
      "\n",
      "Epoch 108/179\n",
      "----------\n",
      "500/2188, acc: 0.3837, CIR-1: 0.7438, RMSE: 1.4957, MAE: 1.0114\n",
      "1000/2188, acc: 0.3871, CIR-1: 0.7442, RMSE: 1.4921, MAE: 1.0087\n",
      "1500/2188, acc: 0.3862, CIR-1: 0.7451, RMSE: 1.4911, MAE: 1.0090\n",
      "2000/2188, acc: 0.3837, CIR-1: 0.7433, RMSE: 1.5004, MAE: 1.0166\n",
      "train Loss: 7.7471 Acc: 0.3837 CIR-1: 0.7442 RMSE 1.4995 MAE 1.0163\n",
      "val Loss: 7.8245 Acc: 0.3471 CIR-1: 0.6688 RMSE 1.8138 MAE 1.2458\n",
      "\n",
      "Epoch 109/179\n",
      "----------\n",
      "500/2188, acc: 0.3746, CIR-1: 0.7397, RMSE: 1.5006, MAE: 1.0255\n",
      "1000/2188, acc: 0.3781, CIR-1: 0.7421, RMSE: 1.4988, MAE: 1.0210\n",
      "1500/2188, acc: 0.3794, CIR-1: 0.7425, RMSE: 1.4965, MAE: 1.0190\n",
      "2000/2188, acc: 0.3804, CIR-1: 0.7431, RMSE: 1.4971, MAE: 1.0181\n",
      "train Loss: 7.7472 Acc: 0.3818 CIR-1: 0.7434 RMSE 1.4960 MAE 1.0173\n",
      "val Loss: 7.8248 Acc: 0.3486 CIR-1: 0.6715 RMSE 1.8173 MAE 1.2442\n",
      "\n",
      "Epoch 110/179\n",
      "----------\n",
      "500/2188, acc: 0.3862, CIR-1: 0.7425, RMSE: 1.5032, MAE: 1.0122\n",
      "1000/2188, acc: 0.3852, CIR-1: 0.7407, RMSE: 1.5034, MAE: 1.0172\n",
      "1500/2188, acc: 0.3828, CIR-1: 0.7417, RMSE: 1.4988, MAE: 1.0171\n",
      "2000/2188, acc: 0.3835, CIR-1: 0.7431, RMSE: 1.4954, MAE: 1.0148\n",
      "train Loss: 7.7463 Acc: 0.3842 CIR-1: 0.7435 RMSE 1.4959 MAE 1.0148\n",
      "val Loss: 7.8229 Acc: 0.3467 CIR-1: 0.6696 RMSE 1.8000 MAE 1.2395\n",
      "\n",
      "Epoch 111/179\n",
      "----------\n",
      "500/2188, acc: 0.3803, CIR-1: 0.7428, RMSE: 1.4935, MAE: 1.0135\n",
      "1000/2188, acc: 0.3810, CIR-1: 0.7456, RMSE: 1.4920, MAE: 1.0129\n",
      "1500/2188, acc: 0.3812, CIR-1: 0.7452, RMSE: 1.4936, MAE: 1.0136\n",
      "2000/2188, acc: 0.3820, CIR-1: 0.7440, RMSE: 1.4937, MAE: 1.0141\n",
      "train Loss: 7.7454 Acc: 0.3826 CIR-1: 0.7445 RMSE 1.4930 MAE 1.0139\n",
      "val Loss: 7.8265 Acc: 0.3469 CIR-1: 0.6658 RMSE 1.8023 MAE 1.2435\n",
      "\n",
      "Epoch 112/179\n",
      "----------\n",
      "500/2188, acc: 0.3827, CIR-1: 0.7428, RMSE: 1.4932, MAE: 1.0129\n",
      "1000/2188, acc: 0.3829, CIR-1: 0.7450, RMSE: 1.4925, MAE: 1.0126\n",
      "1500/2188, acc: 0.3828, CIR-1: 0.7443, RMSE: 1.4971, MAE: 1.0158\n",
      "2000/2188, acc: 0.3807, CIR-1: 0.7436, RMSE: 1.4987, MAE: 1.0186\n",
      "train Loss: 7.7470 Acc: 0.3805 CIR-1: 0.7435 RMSE 1.4993 MAE 1.0198\n",
      "val Loss: 7.8230 Acc: 0.3450 CIR-1: 0.6709 RMSE 1.7995 MAE 1.2391\n",
      "\n",
      "Epoch 113/179\n",
      "----------\n",
      "500/2188, acc: 0.3839, CIR-1: 0.7414, RMSE: 1.4859, MAE: 1.0099\n",
      "1000/2188, acc: 0.3847, CIR-1: 0.7424, RMSE: 1.4915, MAE: 1.0123\n",
      "1500/2188, acc: 0.3842, CIR-1: 0.7425, RMSE: 1.4945, MAE: 1.0144\n",
      "2000/2188, acc: 0.3828, CIR-1: 0.7434, RMSE: 1.4914, MAE: 1.0138\n",
      "train Loss: 7.7453 Acc: 0.3828 CIR-1: 0.7435 RMSE 1.4916 MAE 1.0147\n",
      "val Loss: 7.8224 Acc: 0.3485 CIR-1: 0.6695 RMSE 1.8007 MAE 1.2388\n",
      "\n",
      "Epoch 114/179\n",
      "----------\n",
      "500/2188, acc: 0.3824, CIR-1: 0.7413, RMSE: 1.4782, MAE: 1.0083\n",
      "1000/2188, acc: 0.3807, CIR-1: 0.7439, RMSE: 1.4832, MAE: 1.0108\n",
      "1500/2188, acc: 0.3799, CIR-1: 0.7430, RMSE: 1.4861, MAE: 1.0136\n",
      "2000/2188, acc: 0.3813, CIR-1: 0.7437, RMSE: 1.4880, MAE: 1.0128\n",
      "train Loss: 7.7451 Acc: 0.3821 CIR-1: 0.7446 RMSE 1.4890 MAE 1.0126\n",
      "val Loss: 7.8236 Acc: 0.3449 CIR-1: 0.6693 RMSE 1.7960 MAE 1.2410\n",
      "\n",
      "Epoch 115/179\n",
      "----------\n",
      "500/2188, acc: 0.3793, CIR-1: 0.7381, RMSE: 1.4976, MAE: 1.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/2188, acc: 0.3839, CIR-1: 0.7441, RMSE: 1.4861, MAE: 1.0093\n",
      "1500/2188, acc: 0.3834, CIR-1: 0.7457, RMSE: 1.4860, MAE: 1.0094\n",
      "2000/2188, acc: 0.3833, CIR-1: 0.7470, RMSE: 1.4830, MAE: 1.0077\n",
      "train Loss: 7.7434 Acc: 0.3835 CIR-1: 0.7474 RMSE 1.4825 MAE 1.0078\n",
      "val Loss: 7.8239 Acc: 0.3536 CIR-1: 0.6670 RMSE 1.8118 MAE 1.2403\n",
      "\n",
      "Epoch 116/179\n",
      "----------\n",
      "500/2188, acc: 0.3931, CIR-1: 0.7549, RMSE: 1.4521, MAE: 0.9788\n",
      "1000/2188, acc: 0.3870, CIR-1: 0.7498, RMSE: 1.4675, MAE: 0.9960\n",
      "1500/2188, acc: 0.3846, CIR-1: 0.7491, RMSE: 1.4742, MAE: 1.0012\n",
      "2000/2188, acc: 0.3844, CIR-1: 0.7483, RMSE: 1.4783, MAE: 1.0035\n",
      "train Loss: 7.7434 Acc: 0.3839 CIR-1: 0.7476 RMSE 1.4821 MAE 1.0067\n",
      "val Loss: 7.8268 Acc: 0.3462 CIR-1: 0.6677 RMSE 1.8229 MAE 1.2523\n",
      "\n",
      "Epoch 117/179\n",
      "----------\n",
      "500/2188, acc: 0.3774, CIR-1: 0.7424, RMSE: 1.4986, MAE: 1.0194\n",
      "1000/2188, acc: 0.3763, CIR-1: 0.7435, RMSE: 1.4920, MAE: 1.0177\n",
      "1500/2188, acc: 0.3802, CIR-1: 0.7453, RMSE: 1.4895, MAE: 1.0132\n",
      "2000/2188, acc: 0.3823, CIR-1: 0.7474, RMSE: 1.4827, MAE: 1.0074\n",
      "train Loss: 7.7443 Acc: 0.3825 CIR-1: 0.7471 RMSE 1.4864 MAE 1.0097\n",
      "val Loss: 7.8263 Acc: 0.3418 CIR-1: 0.6669 RMSE 1.8069 MAE 1.2503\n",
      "\n",
      "Epoch 118/179\n",
      "----------\n",
      "500/2188, acc: 0.3770, CIR-1: 0.7443, RMSE: 1.4753, MAE: 1.0085\n",
      "1000/2188, acc: 0.3800, CIR-1: 0.7466, RMSE: 1.4779, MAE: 1.0068\n",
      "1500/2188, acc: 0.3822, CIR-1: 0.7466, RMSE: 1.4851, MAE: 1.0089\n",
      "2000/2188, acc: 0.3830, CIR-1: 0.7465, RMSE: 1.4868, MAE: 1.0092\n",
      "train Loss: 7.7441 Acc: 0.3847 CIR-1: 0.7470 RMSE 1.4858 MAE 1.0079\n",
      "val Loss: 7.8238 Acc: 0.3457 CIR-1: 0.6668 RMSE 1.8000 MAE 1.2425\n",
      "\n",
      "Epoch 119/179\n",
      "----------\n",
      "500/2188, acc: 0.3874, CIR-1: 0.7509, RMSE: 1.4719, MAE: 0.9939\n",
      "1000/2188, acc: 0.3839, CIR-1: 0.7482, RMSE: 1.4762, MAE: 1.0017\n",
      "1500/2188, acc: 0.3842, CIR-1: 0.7479, RMSE: 1.4735, MAE: 1.0016\n",
      "2000/2188, acc: 0.3837, CIR-1: 0.7482, RMSE: 1.4766, MAE: 1.0035\n",
      "train Loss: 7.7440 Acc: 0.3826 CIR-1: 0.7473 RMSE 1.4816 MAE 1.0078\n",
      "val Loss: 7.8239 Acc: 0.3457 CIR-1: 0.6687 RMSE 1.7998 MAE 1.2409\n",
      "\n",
      "Epoch 120/179\n",
      "----------\n",
      "LR is set to 0.0010000000000000002\n",
      "500/2188, acc: 0.3831, CIR-1: 0.7519, RMSE: 1.4745, MAE: 0.9972\n",
      "1000/2188, acc: 0.3871, CIR-1: 0.7525, RMSE: 1.4662, MAE: 0.9925\n",
      "1500/2188, acc: 0.3862, CIR-1: 0.7516, RMSE: 1.4701, MAE: 0.9955\n",
      "2000/2188, acc: 0.3865, CIR-1: 0.7516, RMSE: 1.4667, MAE: 0.9943\n",
      "train Loss: 7.7398 Acc: 0.3860 CIR-1: 0.7525 RMSE 1.4661 MAE 0.9946\n",
      "val Loss: 7.8237 Acc: 0.3493 CIR-1: 0.6667 RMSE 1.8055 MAE 1.2417\n",
      "\n",
      "Epoch 121/179\n",
      "----------\n",
      "500/2188, acc: 0.3906, CIR-1: 0.7569, RMSE: 1.4541, MAE: 0.9804\n",
      "1000/2188, acc: 0.3901, CIR-1: 0.7557, RMSE: 1.4488, MAE: 0.9803\n",
      "1500/2188, acc: 0.3888, CIR-1: 0.7541, RMSE: 1.4554, MAE: 0.9854\n",
      "2000/2188, acc: 0.3866, CIR-1: 0.7547, RMSE: 1.4553, MAE: 0.9871\n",
      "train Loss: 7.7377 Acc: 0.3866 CIR-1: 0.7550 RMSE 1.4549 MAE 0.9877\n",
      "val Loss: 7.8237 Acc: 0.3477 CIR-1: 0.6683 RMSE 1.8010 MAE 1.2405\n",
      "\n",
      "Epoch 122/179\n",
      "----------\n",
      "500/2188, acc: 0.3899, CIR-1: 0.7591, RMSE: 1.4326, MAE: 0.9701\n",
      "1000/2188, acc: 0.3888, CIR-1: 0.7564, RMSE: 1.4443, MAE: 0.9785\n",
      "1500/2188, acc: 0.3882, CIR-1: 0.7555, RMSE: 1.4559, MAE: 0.9850\n",
      "2000/2188, acc: 0.3876, CIR-1: 0.7546, RMSE: 1.4585, MAE: 0.9875\n",
      "train Loss: 7.7385 Acc: 0.3879 CIR-1: 0.7546 RMSE 1.4594 MAE 0.9884\n",
      "val Loss: 7.8242 Acc: 0.3500 CIR-1: 0.6685 RMSE 1.8098 MAE 1.2420\n",
      "\n",
      "Epoch 123/179\n",
      "----------\n",
      "500/2188, acc: 0.3850, CIR-1: 0.7545, RMSE: 1.4354, MAE: 0.9781\n",
      "1000/2188, acc: 0.3863, CIR-1: 0.7552, RMSE: 1.4464, MAE: 0.9818\n",
      "1500/2188, acc: 0.3858, CIR-1: 0.7538, RMSE: 1.4504, MAE: 0.9857\n",
      "2000/2188, acc: 0.3856, CIR-1: 0.7539, RMSE: 1.4538, MAE: 0.9875\n",
      "train Loss: 7.7371 Acc: 0.3858 CIR-1: 0.7543 RMSE 1.4566 MAE 0.9890\n",
      "val Loss: 7.8242 Acc: 0.3475 CIR-1: 0.6675 RMSE 1.8121 MAE 1.2461\n",
      "\n",
      "Epoch 124/179\n",
      "----------\n",
      "500/2188, acc: 0.3891, CIR-1: 0.7527, RMSE: 1.4574, MAE: 0.9844\n",
      "1000/2188, acc: 0.3890, CIR-1: 0.7553, RMSE: 1.4485, MAE: 0.9810\n",
      "1500/2188, acc: 0.3898, CIR-1: 0.7551, RMSE: 1.4545, MAE: 0.9839\n",
      "2000/2188, acc: 0.3892, CIR-1: 0.7541, RMSE: 1.4562, MAE: 0.9861\n",
      "train Loss: 7.7376 Acc: 0.3886 CIR-1: 0.7549 RMSE 1.4555 MAE 0.9866\n",
      "val Loss: 7.8251 Acc: 0.3467 CIR-1: 0.6671 RMSE 1.8100 MAE 1.2467\n",
      "\n",
      "Epoch 125/179\n",
      "----------\n",
      "500/2188, acc: 0.3907, CIR-1: 0.7494, RMSE: 1.4605, MAE: 0.9868\n",
      "1000/2188, acc: 0.3878, CIR-1: 0.7533, RMSE: 1.4554, MAE: 0.9859\n",
      "1500/2188, acc: 0.3882, CIR-1: 0.7531, RMSE: 1.4518, MAE: 0.9849\n",
      "2000/2188, acc: 0.3887, CIR-1: 0.7538, RMSE: 1.4509, MAE: 0.9842\n",
      "train Loss: 7.7371 Acc: 0.3893 CIR-1: 0.7541 RMSE 1.4545 MAE 0.9857\n",
      "val Loss: 7.8243 Acc: 0.3473 CIR-1: 0.6651 RMSE 1.8001 MAE 1.2415\n",
      "\n",
      "Epoch 126/179\n",
      "----------\n",
      "500/2188, acc: 0.3831, CIR-1: 0.7521, RMSE: 1.4539, MAE: 0.9891\n",
      "1000/2188, acc: 0.3855, CIR-1: 0.7543, RMSE: 1.4580, MAE: 0.9888\n",
      "1500/2188, acc: 0.3877, CIR-1: 0.7559, RMSE: 1.4526, MAE: 0.9843\n",
      "2000/2188, acc: 0.3878, CIR-1: 0.7553, RMSE: 1.4536, MAE: 0.9854\n",
      "train Loss: 7.7379 Acc: 0.3875 CIR-1: 0.7551 RMSE 1.4555 MAE 0.9873\n",
      "val Loss: 7.8234 Acc: 0.3471 CIR-1: 0.6682 RMSE 1.8039 MAE 1.2423\n",
      "\n",
      "Epoch 127/179\n",
      "----------\n",
      "500/2188, acc: 0.3887, CIR-1: 0.7601, RMSE: 1.4408, MAE: 0.9736\n",
      "1000/2188, acc: 0.3872, CIR-1: 0.7556, RMSE: 1.4483, MAE: 0.9825\n",
      "1500/2188, acc: 0.3884, CIR-1: 0.7559, RMSE: 1.4496, MAE: 0.9823\n",
      "2000/2188, acc: 0.3872, CIR-1: 0.7555, RMSE: 1.4521, MAE: 0.9850\n",
      "train Loss: 7.7368 Acc: 0.3876 CIR-1: 0.7556 RMSE 1.4519 MAE 0.9853\n",
      "val Loss: 7.8252 Acc: 0.3481 CIR-1: 0.6696 RMSE 1.8078 MAE 1.2417\n",
      "\n",
      "Epoch 128/179\n",
      "----------\n",
      "500/2188, acc: 0.3890, CIR-1: 0.7548, RMSE: 1.4502, MAE: 0.9802\n",
      "1000/2188, acc: 0.3869, CIR-1: 0.7554, RMSE: 1.4515, MAE: 0.9837\n",
      "1500/2188, acc: 0.3884, CIR-1: 0.7543, RMSE: 1.4520, MAE: 0.9839\n",
      "2000/2188, acc: 0.3880, CIR-1: 0.7542, RMSE: 1.4553, MAE: 0.9861\n",
      "train Loss: 7.7377 Acc: 0.3878 CIR-1: 0.7537 RMSE 1.4583 MAE 0.9886\n",
      "val Loss: 7.8247 Acc: 0.3467 CIR-1: 0.6681 RMSE 1.7999 MAE 1.2404\n",
      "\n",
      "Epoch 129/179\n",
      "----------\n",
      "500/2188, acc: 0.3944, CIR-1: 0.7547, RMSE: 1.4517, MAE: 0.9766\n",
      "1000/2188, acc: 0.3905, CIR-1: 0.7559, RMSE: 1.4538, MAE: 0.9813\n",
      "1500/2188, acc: 0.3901, CIR-1: 0.7559, RMSE: 1.4570, MAE: 0.9836\n",
      "2000/2188, acc: 0.3893, CIR-1: 0.7560, RMSE: 1.4553, MAE: 0.9840\n",
      "train Loss: 7.7372 Acc: 0.3899 CIR-1: 0.7561 RMSE 1.4549 MAE 0.9839\n",
      "val Loss: 7.8242 Acc: 0.3477 CIR-1: 0.6691 RMSE 1.8149 MAE 1.2457\n",
      "\n",
      "Epoch 130/179\n",
      "----------\n",
      "500/2188, acc: 0.3864, CIR-1: 0.7569, RMSE: 1.4462, MAE: 0.9795\n",
      "1000/2188, acc: 0.3877, CIR-1: 0.7583, RMSE: 1.4432, MAE: 0.9786\n",
      "1500/2188, acc: 0.3876, CIR-1: 0.7556, RMSE: 1.4466, MAE: 0.9822\n",
      "2000/2188, acc: 0.3896, CIR-1: 0.7562, RMSE: 1.4477, MAE: 0.9811\n",
      "train Loss: 7.7367 Acc: 0.3894 CIR-1: 0.7560 RMSE 1.4509 MAE 0.9834\n",
      "val Loss: 7.8242 Acc: 0.3494 CIR-1: 0.6693 RMSE 1.8098 MAE 1.2416\n",
      "\n",
      "Epoch 131/179\n",
      "----------\n",
      "500/2188, acc: 0.3934, CIR-1: 0.7568, RMSE: 1.4386, MAE: 0.9711\n",
      "1000/2188, acc: 0.3890, CIR-1: 0.7555, RMSE: 1.4459, MAE: 0.9803\n",
      "1500/2188, acc: 0.3891, CIR-1: 0.7553, RMSE: 1.4513, MAE: 0.9828\n",
      "2000/2188, acc: 0.3877, CIR-1: 0.7545, RMSE: 1.4509, MAE: 0.9847\n",
      "train Loss: 7.7373 Acc: 0.3878 CIR-1: 0.7546 RMSE 1.4525 MAE 0.9859\n",
      "val Loss: 7.8261 Acc: 0.3501 CIR-1: 0.6670 RMSE 1.8134 MAE 1.2441\n",
      "\n",
      "Epoch 132/179\n",
      "----------\n",
      "500/2188, acc: 0.3841, CIR-1: 0.7508, RMSE: 1.4613, MAE: 0.9925\n",
      "1000/2188, acc: 0.3883, CIR-1: 0.7554, RMSE: 1.4522, MAE: 0.9829\n",
      "1500/2188, acc: 0.3874, CIR-1: 0.7551, RMSE: 1.4526, MAE: 0.9848\n",
      "2000/2188, acc: 0.3878, CIR-1: 0.7550, RMSE: 1.4515, MAE: 0.9846\n",
      "train Loss: 7.7369 Acc: 0.3877 CIR-1: 0.7551 RMSE 1.4530 MAE 0.9861\n",
      "val Loss: 7.8247 Acc: 0.3501 CIR-1: 0.6705 RMSE 1.8184 MAE 1.2445\n",
      "\n",
      "Epoch 133/179\n",
      "----------\n",
      "500/2188, acc: 0.3899, CIR-1: 0.7607, RMSE: 1.4468, MAE: 0.9741\n",
      "1000/2188, acc: 0.3883, CIR-1: 0.7585, RMSE: 1.4508, MAE: 0.9808\n",
      "1500/2188, acc: 0.3878, CIR-1: 0.7556, RMSE: 1.4581, MAE: 0.9868\n",
      "2000/2188, acc: 0.3882, CIR-1: 0.7549, RMSE: 1.4589, MAE: 0.9873\n",
      "train Loss: 7.7372 Acc: 0.3885 CIR-1: 0.7553 RMSE 1.4563 MAE 0.9865\n",
      "val Loss: 7.8258 Acc: 0.3485 CIR-1: 0.6692 RMSE 1.8168 MAE 1.2461\n",
      "\n",
      "Epoch 134/179\n",
      "----------\n",
      "500/2188, acc: 0.3845, CIR-1: 0.7522, RMSE: 1.4639, MAE: 0.9917\n",
      "1000/2188, acc: 0.3867, CIR-1: 0.7538, RMSE: 1.4589, MAE: 0.9880\n",
      "1500/2188, acc: 0.3907, CIR-1: 0.7562, RMSE: 1.4475, MAE: 0.9785\n",
      "2000/2188, acc: 0.3896, CIR-1: 0.7545, RMSE: 1.4499, MAE: 0.9821\n",
      "train Loss: 7.7367 Acc: 0.3898 CIR-1: 0.7549 RMSE 1.4517 MAE 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 7.8247 Acc: 0.3501 CIR-1: 0.6695 RMSE 1.8140 MAE 1.2431\n",
      "\n",
      "Epoch 135/179\n",
      "----------\n",
      "500/2188, acc: 0.3868, CIR-1: 0.7509, RMSE: 1.4560, MAE: 0.9884\n",
      "1000/2188, acc: 0.3898, CIR-1: 0.7537, RMSE: 1.4572, MAE: 0.9857\n",
      "1500/2188, acc: 0.3876, CIR-1: 0.7529, RMSE: 1.4590, MAE: 0.9889\n",
      "2000/2188, acc: 0.3888, CIR-1: 0.7543, RMSE: 1.4567, MAE: 0.9862\n",
      "train Loss: 7.7366 Acc: 0.3888 CIR-1: 0.7554 RMSE 1.4542 MAE 0.9852\n",
      "val Loss: 7.8243 Acc: 0.3478 CIR-1: 0.6675 RMSE 1.8007 MAE 1.2405\n",
      "\n",
      "Epoch 136/179\n",
      "----------\n",
      "500/2188, acc: 0.3817, CIR-1: 0.7529, RMSE: 1.4465, MAE: 0.9864\n",
      "1000/2188, acc: 0.3890, CIR-1: 0.7571, RMSE: 1.4420, MAE: 0.9768\n",
      "1500/2188, acc: 0.3896, CIR-1: 0.7582, RMSE: 1.4415, MAE: 0.9759\n",
      "2000/2188, acc: 0.3893, CIR-1: 0.7578, RMSE: 1.4465, MAE: 0.9790\n",
      "train Loss: 7.7356 Acc: 0.3893 CIR-1: 0.7581 RMSE 1.4480 MAE 0.9801\n",
      "val Loss: 7.8251 Acc: 0.3470 CIR-1: 0.6671 RMSE 1.8045 MAE 1.2435\n",
      "\n",
      "Epoch 137/179\n",
      "----------\n",
      "500/2188, acc: 0.3928, CIR-1: 0.7566, RMSE: 1.4590, MAE: 0.9795\n",
      "1000/2188, acc: 0.3895, CIR-1: 0.7573, RMSE: 1.4502, MAE: 0.9800\n",
      "1500/2188, acc: 0.3910, CIR-1: 0.7580, RMSE: 1.4471, MAE: 0.9777\n",
      "2000/2188, acc: 0.3912, CIR-1: 0.7573, RMSE: 1.4456, MAE: 0.9775\n",
      "train Loss: 7.7355 Acc: 0.3916 CIR-1: 0.7578 RMSE 1.4447 MAE 0.9773\n",
      "val Loss: 7.8247 Acc: 0.3451 CIR-1: 0.6683 RMSE 1.8042 MAE 1.2437\n",
      "\n",
      "Epoch 138/179\n",
      "----------\n",
      "500/2188, acc: 0.3784, CIR-1: 0.7453, RMSE: 1.4725, MAE: 1.0049\n",
      "1000/2188, acc: 0.3814, CIR-1: 0.7500, RMSE: 1.4616, MAE: 0.9963\n",
      "1500/2188, acc: 0.3850, CIR-1: 0.7539, RMSE: 1.4486, MAE: 0.9854\n",
      "2000/2188, acc: 0.3869, CIR-1: 0.7548, RMSE: 1.4482, MAE: 0.9834\n",
      "train Loss: 7.7362 Acc: 0.3882 CIR-1: 0.7557 RMSE 1.4477 MAE 0.9823\n",
      "val Loss: 7.8261 Acc: 0.3505 CIR-1: 0.6683 RMSE 1.8115 MAE 1.2424\n",
      "\n",
      "Epoch 139/179\n",
      "----------\n",
      "500/2188, acc: 0.3847, CIR-1: 0.7528, RMSE: 1.4445, MAE: 0.9840\n",
      "1000/2188, acc: 0.3871, CIR-1: 0.7554, RMSE: 1.4409, MAE: 0.9802\n",
      "1500/2188, acc: 0.3898, CIR-1: 0.7586, RMSE: 1.4379, MAE: 0.9751\n",
      "2000/2188, acc: 0.3877, CIR-1: 0.7572, RMSE: 1.4441, MAE: 0.9807\n",
      "train Loss: 7.7358 Acc: 0.3888 CIR-1: 0.7579 RMSE 1.4467 MAE 0.9811\n",
      "val Loss: 7.8254 Acc: 0.3480 CIR-1: 0.6693 RMSE 1.8124 MAE 1.2450\n",
      "\n",
      "Epoch 140/179\n",
      "----------\n",
      "500/2188, acc: 0.3887, CIR-1: 0.7546, RMSE: 1.4467, MAE: 0.9802\n",
      "1000/2188, acc: 0.3872, CIR-1: 0.7533, RMSE: 1.4501, MAE: 0.9853\n",
      "1500/2188, acc: 0.3867, CIR-1: 0.7531, RMSE: 1.4532, MAE: 0.9876\n",
      "2000/2188, acc: 0.3872, CIR-1: 0.7536, RMSE: 1.4530, MAE: 0.9870\n",
      "train Loss: 7.7370 Acc: 0.3879 CIR-1: 0.7542 RMSE 1.4527 MAE 0.9867\n",
      "val Loss: 7.8252 Acc: 0.3469 CIR-1: 0.6686 RMSE 1.8028 MAE 1.2413\n",
      "\n",
      "Epoch 141/179\n",
      "----------\n",
      "500/2188, acc: 0.3828, CIR-1: 0.7509, RMSE: 1.4468, MAE: 0.9862\n",
      "1000/2188, acc: 0.3872, CIR-1: 0.7559, RMSE: 1.4431, MAE: 0.9797\n",
      "1500/2188, acc: 0.3886, CIR-1: 0.7556, RMSE: 1.4465, MAE: 0.9810\n",
      "2000/2188, acc: 0.3895, CIR-1: 0.7572, RMSE: 1.4438, MAE: 0.9784\n",
      "train Loss: 7.7357 Acc: 0.3891 CIR-1: 0.7571 RMSE 1.4446 MAE 0.9799\n",
      "val Loss: 7.8263 Acc: 0.3493 CIR-1: 0.6713 RMSE 1.8254 MAE 1.2481\n",
      "\n",
      "Epoch 142/179\n",
      "----------\n",
      "500/2188, acc: 0.3874, CIR-1: 0.7519, RMSE: 1.4509, MAE: 0.9848\n",
      "1000/2188, acc: 0.3893, CIR-1: 0.7518, RMSE: 1.4563, MAE: 0.9870\n",
      "1500/2188, acc: 0.3892, CIR-1: 0.7532, RMSE: 1.4528, MAE: 0.9850\n",
      "2000/2188, acc: 0.3898, CIR-1: 0.7555, RMSE: 1.4483, MAE: 0.9813\n",
      "train Loss: 7.7361 Acc: 0.3895 CIR-1: 0.7558 RMSE 1.4482 MAE 0.9820\n",
      "val Loss: 7.8255 Acc: 0.3467 CIR-1: 0.6681 RMSE 1.8038 MAE 1.2427\n",
      "\n",
      "Epoch 143/179\n",
      "----------\n",
      "500/2188, acc: 0.3935, CIR-1: 0.7560, RMSE: 1.4397, MAE: 0.9718\n",
      "1000/2188, acc: 0.3926, CIR-1: 0.7556, RMSE: 1.4505, MAE: 0.9790\n",
      "1500/2188, acc: 0.3912, CIR-1: 0.7560, RMSE: 1.4505, MAE: 0.9806\n",
      "2000/2188, acc: 0.3902, CIR-1: 0.7561, RMSE: 1.4503, MAE: 0.9812\n",
      "train Loss: 7.7365 Acc: 0.3906 CIR-1: 0.7571 RMSE 1.4491 MAE 0.9806\n",
      "val Loss: 7.8257 Acc: 0.3499 CIR-1: 0.6695 RMSE 1.8112 MAE 1.2422\n",
      "\n",
      "Epoch 144/179\n",
      "----------\n",
      "500/2188, acc: 0.3869, CIR-1: 0.7544, RMSE: 1.4526, MAE: 0.9857\n",
      "1000/2188, acc: 0.3856, CIR-1: 0.7548, RMSE: 1.4521, MAE: 0.9867\n",
      "1500/2188, acc: 0.3896, CIR-1: 0.7560, RMSE: 1.4512, MAE: 0.9821\n",
      "2000/2188, acc: 0.3897, CIR-1: 0.7559, RMSE: 1.4485, MAE: 0.9812\n",
      "train Loss: 7.7364 Acc: 0.3894 CIR-1: 0.7562 RMSE 1.4507 MAE 0.9829\n"
     ]
    }
   ],
   "source": [
    "lr=0.01 #Initial learning rate\n",
    "optimizer='sgd'\n",
    "lr_scheduler = ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch= 60 #Number of epoch for learning rate decay\n",
    "single_loss=0.0\n",
    "multi_loss=1.0\n",
    "coeff_lmbda = 1\n",
    "KL = False\n",
    "\n",
    "algo = None\n",
    "metric = 'test'\n",
    "lr=0.1 #Initial learning rate\n",
    "run_network()\n",
    "\n",
    "metric = 'ccr1'\n",
    "lr=0.1 #Initial learning rate\n",
    "run_network()\n",
    "lr=0.01 #Initial learning rate\n",
    "run_network()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Multi coeff is [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.05\n",
      "train Loss: 1.9876 Acc: 0.9108 CIR-1: 0.9609 RMSE 0.6152 MAE 0.1566\n",
      "val Loss: 21.2750 Acc: 0.3513 CIR-1: 0.5818 RMSE 1.9639 MAE 1.4071\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3123 Acc: 0.9910 CIR-1: 0.9992 RMSE 0.1114 MAE 0.0100\n",
      "val Loss: 25.8120 Acc: 0.2491 CIR-1: 0.5056 RMSE 1.9458 MAE 1.5558\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9950 CIR-1: 0.9996 RMSE 0.0828 MAE 0.0055\n",
      "val Loss: 23.1010 Acc: 0.3959 CIR-1: 0.6245 RMSE 1.9771 MAE 1.3662\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9960 CIR-1: 1.0000 RMSE 0.0634 MAE 0.0040\n",
      "val Loss: 22.9920 Acc: 0.3680 CIR-1: 0.6097 RMSE 2.1625 MAE 1.4907\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1225 Acc: 0.9962 CIR-1: 0.9999 RMSE 0.0643 MAE 0.0039\n",
      "val Loss: 20.8725 Acc: 0.4238 CIR-1: 0.5595 RMSE 1.9324 MAE 1.3810\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9960 CIR-1: 0.9997 RMSE 0.0707 MAE 0.0044\n",
      "val Loss: 26.0750 Acc: 0.4294 CIR-1: 0.6115 RMSE 2.5864 MAE 1.6710\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1053 Acc: 0.9972 CIR-1: 0.9999 RMSE 0.0562 MAE 0.0029\n",
      "val Loss: 27.4968 Acc: 0.3178 CIR-1: 0.6970 RMSE 2.0134 MAE 1.3885\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.1084 Acc: 0.9968 CIR-1: 0.9998 RMSE 0.0617 MAE 0.0034\n",
      "val Loss: 26.9135 Acc: 0.2770 CIR-1: 0.6115 RMSE 2.5735 MAE 1.7788\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9965 CIR-1: 0.9996 RMSE 0.0730 MAE 0.0040\n",
      "val Loss: 23.4159 Acc: 0.4015 CIR-1: 0.7119 RMSE 2.4957 MAE 1.5409\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0978 Acc: 0.9966 CIR-1: 0.9996 RMSE 0.0684 MAE 0.0038\n",
      "val Loss: 25.6522 Acc: 0.3643 CIR-1: 0.5335 RMSE 2.7619 MAE 1.8996\n",
      "\n",
      "Training complete in 13m 57s\n",
      "Best val RMSE: 1.932408\n",
      "Writing results\n",
      "Wrote results\n",
      "19\n",
      "Multi coeff is [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.05\n",
      "train Loss: 1.8336 Acc: 0.9161 CIR-1: 0.9587 RMSE 0.6102 MAE 0.1525\n",
      "val Loss: 20.9688 Acc: 0.3420 CIR-1: 0.5558 RMSE 1.9710 MAE 1.4461\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.2967 Acc: 0.9915 CIR-1: 0.9985 RMSE 0.1282 MAE 0.0106\n",
      "val Loss: 19.1929 Acc: 0.2416 CIR-1: 0.4796 RMSE 2.4804 MAE 1.8216\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2321 Acc: 0.9926 CIR-1: 0.9989 RMSE 0.1119 MAE 0.0088\n",
      "val Loss: 25.6426 Acc: 0.2491 CIR-1: 0.5390 RMSE 2.3177 MAE 1.7286\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9955 CIR-1: 1.0000 RMSE 0.0668 MAE 0.0045\n",
      "val Loss: 19.9350 Acc: 0.3420 CIR-1: 0.4851 RMSE 2.6482 MAE 1.8383\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9964 CIR-1: 0.9997 RMSE 0.0676 MAE 0.0039\n",
      "val Loss: 21.8150 Acc: 0.3104 CIR-1: 0.5316 RMSE 2.9314 MAE 2.0428\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9961 CIR-1: 0.9997 RMSE 0.0738 MAE 0.0044\n",
      "val Loss: 22.7065 Acc: 0.2472 CIR-1: 0.5130 RMSE 2.8060 MAE 2.0112\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1038 Acc: 0.9968 CIR-1: 1.0000 RMSE 0.0562 MAE 0.0032\n",
      "val Loss: 22.9431 Acc: 0.2584 CIR-1: 0.5446 RMSE 2.2842 MAE 1.7007\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.9972 CIR-1: 1.0000 RMSE 0.0532 MAE 0.0028\n",
      "val Loss: 24.0490 Acc: 0.3104 CIR-1: 0.5892 RMSE 2.8911 MAE 1.9647\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1146:\n",
      "Process Process-1148:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "Process Process-1149:\n",
      "Process Process-1147:\n",
      "Process Process-1152:\n",
      "Process Process-1151:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1150:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 81, in to_tensor\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-1145:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 81, in to_tensor\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f6bf0b39978>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 324, in _shutdown_workers\n",
      "    q.put(None)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 21722) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6b570b0c61c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m \u001b[0;31m#Initial learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bfb74a744eaa>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                             \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                             \u001b[0mlogname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../results/logs.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheng_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheng_lambda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                             softmax_matrices = softmax_matrices)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m'''Save the models'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mtezcan/lindrv/Projects/ordinal_regression/codes/functions/fine_tune.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optim_str, lr_scheduler, dset_loaders, dset_sizes, writer, use_gpu, num_epochs, batch_size, num_log, init_lr, lr_decay_epoch, regression, learn_a, cross_loss, multi_loss, write_log, numOut, logname, iter_loc, multi_coeff, single_coeff, KL, poisson, binomial, cheng, algo, mae_loss, weighted_softmax, test, momentum, weight_decay, fix_a, cheng_lambda, weighted_softmax_2, softmax_matrices)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearn_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfix_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpoisson\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbinomial\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.1 #Initial learning rate\n",
    "optimizer='sgd'\n",
    "lr_scheduler = ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "single_loss=0.0\n",
    "multi_loss=1.0\n",
    "coeff_lmbda = 1\n",
    "KL = False\n",
    "\n",
    "algo = None\n",
    "\n",
    "metric = 'ccr'\n",
    "\n",
    "lr=0.05 #Initial learning rate\n",
    "run_network()\n",
    "run_network()\n",
    "run_network()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001 #Initial learning rate\n",
    "weight_decay = 0\n",
    "optimizer='sgd'\n",
    "lr_scheduler = ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch= 30 #Number of epoch for learning rate decay\n",
    "single_loss=0.0\n",
    "multi_loss=1.0\n",
    "coeff_lmbda = 1\n",
    "KL = True\n",
    "\n",
    "algo = 'weighted_softmax_2'\n",
    "\n",
    "\n",
    "'''metric = 'ccr'\n",
    "run_network()\n",
    "metric = 'ccr1'\n",
    "run_network()'''\n",
    "metric = 'mae'\n",
    "\n",
    "lr = 0.001\n",
    "run_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr=0.01 #Initial learning rate\n",
    "optimizer='sgd'\n",
    "lr_scheduler = ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=20 #Number of epoch for learning rate decay\n",
    "single_loss=0.0\n",
    "multi_loss=1.0\n",
    "coeff_lmbda = 1\n",
    "KL = True\n",
    "algo = 'cheng'\n",
    "\n",
    "cheng_lambda = 0.01\n",
    "run_network()\n",
    "cheng_lambda = 0.04\n",
    "run_network()\n",
    "cheng_lambda = 0.7\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr=0.03 # Initial learning rate\n",
    "optimizer='sgd'\n",
    "lr_scheduler = ft.exp_lr_scheduler # Learning rate scheduler\n",
    "lr_decay_epoch=20 # Number of epoch for learning rate decay\n",
    "single_loss=1.0\n",
    "multi_loss=0.0\n",
    "coeff_lmbda = 1\n",
    "KL = True\n",
    "    \n",
    "algo = 'binomial'\n",
    "lr=0.03\n",
    "run_network()\n",
    "\n",
    "lr=0.01 # Initial learning rate\n",
    "run_network()\n",
    "\n",
    "lr=0.001 # Initial learning rate\n",
    "run_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    metric = 'ccr'\n",
    "    KL = True\n",
    "    single_loss=1.\n",
    "    multi_loss=0.\n",
    "    run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KL = True\n",
    "\n",
    "metric = 'ccr'\n",
    "single_loss= 1.0\n",
    "multi_loss = 0.0\n",
    "run_network()\n",
    "\n",
    "metric = 'ccr1'\n",
    "run_network()\n",
    "\n",
    "metric = 'mae'\n",
    "run_network()\n",
    "\n",
    "metric = 'mse'\n",
    "run_network()\n",
    "\n",
    "metric = 'ccr1'\n",
    "for lmbda in [.2, .4, .6, .8, .9]:\n",
    "    single_loss= round(1.-lmbda, 1)\n",
    "    multi_loss = lmbda\n",
    "    print('Single loss = '+str(single_loss)+', Multi loss = '+str(multi_loss))\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mae'\n",
    "for lmbda in [.2, .4, .6, .8, .9]:\n",
    "    single_loss= round(1.-lmbda, 1)\n",
    "    multi_loss = lmbda\n",
    "    print('Single loss = '+str(single_loss)+', Multi loss = '+str(multi_loss))\n",
    "    run_network()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr=0.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "single_loss= 1.0\n",
    "multi_loss = 0.0\n",
    "metric = 'ccr'\n",
    "run_network()\n",
    "metric = 'ccr1'\n",
    "run_network()\n",
    "metric = 'mae'\n",
    "run_network()\n",
    "metric = 'mse'\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_loss=0.\n",
    "multi_loss=1.\n",
    "\n",
    "for k in range(len(dset_loaders_arr)):\n",
    "    dset_loaders = dset_loaders_arr[k]\n",
    "    run_network()\n",
    "    \n",
    "single_loss=.1\n",
    "multi_loss=.9\n",
    "\n",
    "for k in range(len(dset_loaders_arr)):\n",
    "    dset_loaders = dset_loaders_arr[k]\n",
    "    run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_coeff = (1/5) * [1, 2, 3, 4, 5, 4, 3, 2, 1]\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_coeff = np.asarray([1])\n",
    "print(multi_coeff)\n",
    "run_network()\n",
    "\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "run_network()\n",
    "\n",
    "single_loss = 0.1\n",
    "multi_loss = 0.9\n",
    "multi_coeff = [1, 1, 1]\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''multi_coeff = (1/5) * np.asarray([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "print(multi_coeff)\n",
    "run_network()'''\n",
    "\n",
    "multi_coeff = (1/25) * np.asarray([9, 16, 21, 24, 25, 24, 21, 16, 9])\n",
    "print(multi_coeff)\n",
    "run_network()\n",
    "\n",
    "multi_coeff = np.asarray([1])\n",
    "print(multi_coeff)\n",
    "run_network()\n",
    "\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_loss = 0.1\n",
    "multi_loss = 0.9\n",
    "multi_coeff = (1/5) * np.asarray([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "print(multi_coeff)\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_loss = 0.0\n",
    "multi_loss = 1.0\n",
    "multi_coeff =  np.asarray([.9, 1, .9])\n",
    "print(multi_coeff)\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_coeff = (1/25) * np.asarray([9, 16, 21, 24, 25, 24, 21, 16, 9])\n",
    "extend = int((len(multi_coeff) - 1) / 2)\n",
    "label_multi = np.zeros(numOut + 2 * extend)\n",
    "label_multi[label:label + 2 * extend + 1] = multi_coeff\n",
    "\n",
    "if extend is not 0:\n",
    "    label_multi = label_multi[extend:-extend]\n",
    "\n",
    "print(label_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss=False\n",
    "for lmbda in [1., 1., 1., 1., 1.]:\n",
    "    single_loss= round(1.-lmbda, 1)\n",
    "    multi_loss = lmbda\n",
    "    print('Single loss = '+str(single_loss)+', Multi loss = '+str(multi_loss))\n",
    "    run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
