{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5\n",
    "\n",
    "\n",
    "#from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f0a2e905b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAD8CAYAAAAylrwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAjYAQMGDMiIgYAdMGDAgIz43zi9YYgE0yNZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0aa41cf5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "dim = 2\n",
    "\n",
    "def generateLinearData(num_samples = 10000, num_classes = num_classes, dim = dim, bound = 5, sigma_noise = .1,rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    label = np.dot((np.random.rand(1,dim)*bound*2-bound).reshape(1,-1),fvec)\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateLinearData(rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCircularData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    \n",
    "    fvec_l = np.sum(fvec**2, axis = 0).reshape(1,-1)\n",
    "    print(fvec_l.shape)\n",
    "    label = fvec_l\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateCircularData(num_classes =5, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Greys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = 9, dim = 2,\n",
    "                         bound = 1, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "    sample_per_class = int(num_samples/num_classes)\n",
    "    num_samples = sample_per_class*num_classes\n",
    "    fvec = np.zeros((dim, sample_per_class*num_classes))\n",
    "    label = np.zeros((1, sample_per_class*num_classes))\n",
    "    \n",
    "    t = np.linspace(0, 10, sample_per_class)\n",
    "    x = t * np.cos(t)\n",
    "    y = t * np.sin(t)\n",
    "    x = x.reshape(1, -1)\n",
    "    y = y.reshape(1, -1)\n",
    "\n",
    "    cons = .7\n",
    "    for k in range(0, num_classes):\n",
    "        r = np.linspace(0.05, 1, sample_per_class)\n",
    "        t = np.linspace(k*cons, (k+6)*cons, sample_per_class)\n",
    "        x = np.cos(t)\n",
    "        y = np.sin(t)\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        label[0, k*sample_per_class:(k+1)*sample_per_class] = rand_classes[k]\n",
    "        fvec[0, k*sample_per_class:(k+1)*sample_per_class] = bound * x * r\n",
    "        fvec[1, k*sample_per_class:(k+1)*sample_per_class] = bound * y * r\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "X, y = generateSpiralData(num_classes = 9, sigma_noise = 0.01, rand_label = False)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "\n",
    "    cons = 4\n",
    "    N = num_samples # number of points per class\n",
    "    D = dim # dimensionality\n",
    "    K = num_classes # number of classes\n",
    "\n",
    "    X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "    y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "    for j in range(K):\n",
    "      ix = range(N*j,N*(j+1))\n",
    "      r = np.linspace(0.0,1,N) # radius\n",
    "      t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*sigma_noise # theta\n",
    "      X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "      y[ix] = j\n",
    "    \n",
    "    label = y.astype(np.int)\n",
    "    fvec = X\n",
    "    \n",
    "    return fvec, label\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "fvec, label = generateCircularData(num_classes =9, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "fvec, label = generateSpiralData(num_classes = 3, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "#plt.savefig('circular_vs_spiral.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Regression Benchmark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_bins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "housing\n",
      "results.csv\n",
      "stock\n",
      "stocksdomain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 0)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-35211db07a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feat\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/housing\", sep=',', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"./dataset/regression/housing\", sep='\\s+', header=None)\n",
    "train_df = pd.read_csv(\"./dataset/regression/cpu_act.data\", sep=',', header=None)\n",
    "#train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "      <th>feat18</th>\n",
       "      <th>feat19</th>\n",
       "      <th>feat20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1036</td>\n",
       "      <td>103</td>\n",
       "      <td>114</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>172076</td>\n",
       "      <td>355965</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>73.60</td>\n",
       "      <td>89.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6527</td>\n",
       "      <td>1851864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2165</td>\n",
       "      <td>205</td>\n",
       "      <td>101</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.20</td>\n",
       "      <td>43107</td>\n",
       "      <td>44139</td>\n",
       "      <td>4.80</td>\n",
       "      <td>42.20</td>\n",
       "      <td>75.80</td>\n",
       "      <td>181.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>85.40</td>\n",
       "      <td>88.20</td>\n",
       "      <td>19.40</td>\n",
       "      <td>161.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130</td>\n",
       "      <td>1131931</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>77</td>\n",
       "      <td>3806</td>\n",
       "      <td>258</td>\n",
       "      <td>166</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>492142</td>\n",
       "      <td>268706</td>\n",
       "      <td>4.80</td>\n",
       "      <td>19.40</td>\n",
       "      <td>44.00</td>\n",
       "      <td>79.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>7.60</td>\n",
       "      <td>12.20</td>\n",
       "      <td>68.00</td>\n",
       "      <td>218.80</td>\n",
       "      <td>5.2</td>\n",
       "      <td>256</td>\n",
       "      <td>1314590</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4721</td>\n",
       "      <td>256</td>\n",
       "      <td>177</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.58</td>\n",
       "      <td>524787</td>\n",
       "      <td>174964</td>\n",
       "      <td>14.51</td>\n",
       "      <td>51.49</td>\n",
       "      <td>88.47</td>\n",
       "      <td>189.86</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.17</td>\n",
       "      <td>24.85</td>\n",
       "      <td>95.63</td>\n",
       "      <td>248.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233</td>\n",
       "      <td>972606</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>3949</td>\n",
       "      <td>249</td>\n",
       "      <td>244</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.60</td>\n",
       "      <td>197289</td>\n",
       "      <td>529200</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>219.60</td>\n",
       "      <td>297.20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>331</td>\n",
       "      <td>1013805</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat0  feat1  feat2  feat3  feat4  feat5  feat6   feat7   feat8  feat9  \\\n",
       "0      6      2   1036    103    114   1.00   1.00  172076  355965   0.00   \n",
       "1      1      0   2165    205    101   0.40   1.20   43107   44139   4.80   \n",
       "2     62     77   3806    258    166   1.40   1.40  492142  268706   4.80   \n",
       "3      5      0   4721    256    177   0.99   2.58  524787  174964  14.51   \n",
       "4     42     55   3949    249    244   2.60   4.60  197289  529200   4.20   \n",
       "\n",
       "   feat10  feat11  feat12  feat13  feat14  feat15  feat16  feat17  feat18  \\\n",
       "0    0.00    0.00    0.00    0.00    2.00    4.00   73.60   89.00     2.0   \n",
       "1   42.20   75.80  181.40    0.20   85.40   88.20   19.40  161.80     3.0   \n",
       "2   19.40   44.00   79.20    2.20    7.60   12.20   68.00  218.80     5.2   \n",
       "3   51.49   88.47  189.86    1.99    4.17   24.85   95.63  248.91     1.0   \n",
       "4    6.80    6.60    0.00    1.40    1.80    2.20  219.60  297.20     3.4   \n",
       "\n",
       "   feat19   feat20  label  \n",
       "0    6527  1851864     90  \n",
       "1     130  1131931     88  \n",
       "2     256  1314590     85  \n",
       "3     233   972606     81  \n",
       "4     331  1013805     79  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples per class is 819.2\n",
      "[0.0, 72.000100000000003, 79.000200000000007, 83.000299999999996, 87.000399999999999, 89.000500000000002, 91.000600000000006, 93.000699999999995, 95.000799999999998, 97.000900000000001, 99.001000000000005]\n",
      "[0.0, 72.000100000000003, 79.000200000000007, 83.000299999999996, 87.000399999999999, 89.000500000000002, 91.000600000000006, 93.000699999999995, 95.000799999999998, 97.000900000000001, 100.001]\n",
      "99\n",
      "Unique labels are [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEFCAYAAAAYKqc0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJekAv1/V0EIg3SB63wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1db02588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_bins\n",
    "print('Number of Samples per class is ' + str(num_samples_per_class))\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_bins+1)]\n",
    "bins.insert(0,0.0)\n",
    "print(bins)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "k = 10\n",
    "\n",
    "print(label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]])\n",
    "for k in range(num_bins):\n",
    "    #print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print('Unique labels are ' + str(np.unique(label_ord)))\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "#print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.xlabel('Original Label')\n",
    "plt.ylabel('Ordinal Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>label</th>\n",
       "      <th>label_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat0  feat1  feat2  feat3  feat4  feat5  feat6   feat7  feat8  feat9  \\\n",
       "0  0.00632   18.0   2.31      0  0.538  6.575   65.2  4.0900      1  296.0   \n",
       "1  0.02731    0.0   7.07      0  0.469  6.421   78.9  4.9671      2  242.0   \n",
       "2  0.02729    0.0   7.07      0  0.469  7.185   61.1  4.9671      2  242.0   \n",
       "3  0.03237    0.0   2.18      0  0.458  6.998   45.8  6.0622      3  222.0   \n",
       "4  0.06905    0.0   2.18      0  0.458  7.147   54.2  6.0622      3  222.0   \n",
       "\n",
       "   feat10  feat11  feat12  label  label_ord  \n",
       "0    15.3  396.90    4.98   24.0        6.0  \n",
       "1    17.8  396.90    9.14   21.6        5.0  \n",
       "2    17.8  392.83    4.03   34.7        8.0  \n",
       "3    18.7  394.63    2.94   33.4        8.0  \n",
       "4    18.7  396.90    5.33   36.2        9.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAF2CAYAAADjiqiVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRiYkiRlYGBKkpTB/wercK9yh2rrnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d963978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,\n",
    "            c=np.sort(label_ord[sorted_idx]), cmap = plt.get_cmap('tab10'))\n",
    "plt.colorbar()\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Label', fontsize=12)\n",
    "\n",
    "plt.savefig('cpu_act.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7ff6ebf1bb70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHmCAYAAACWBYNaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIwlhgEAGEsMAwAw1v8DmfV3DxEQlpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6b4043668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coeff(n, metric, lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return [1]\n",
    "    elif metric is 'ccr1':\n",
    "        return [1, 1, 1]\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.arange(1,n)/(n-1)\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros(n-1)\n",
    "        coeff[0] = 2*n-3\n",
    "        for k in range(1, n-1):\n",
    "            coeff[k] = coeff[k-1] + 2*n - (2*(k+1)+1)\n",
    "        coeff = coeff /((n-1)**2)\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "    coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    coeff = coeff * lmbda\n",
    "    coeff[n-2] = 1\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type = 'boston_housing'\n",
    "num_samples = 10000\n",
    "num_classes = 9\n",
    "nclasses = num_classes\n",
    "dim = 2\n",
    "\n",
    "sigma_noise = 0.01\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=10 #Number of the first column in the excel file for writing the results.\n",
    "lr=.5 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "batch_size = 256\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "rand_label = False\n",
    "\n",
    "metric = 'ccr'\n",
    "coeff_lmbda =  1\n",
    "multi_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "KL = False #KL divergence for porbability measure\n",
    "\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any\n",
    "\n",
    "algo = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9189118  -0.77272727 -0.21724497 -0.86166008 -0.30166642  0.04373803\n",
      "  0.35272711 -0.51523744 -0.25657329 -0.15558338  0.24585821  0.79713567\n",
      " -0.39718194]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "(506, 13)\n",
      "[3 7 7 1 1 9 9 3 0 4 3 3 0 2 1 2 4 1 4 7 0 2 6 2 3 7 1 6 9 4 9 0 3 0 0 6 8\n",
      " 4 1 0 4 8 6 7 9 8 4 3 7 6 5 5 2 0 6 7 5 8 0 0 2 1 6 1 2 4 7 8 6 5 4 8 9 1\n",
      " 6 7 7 0 7 1 5 4 0 4 3 4 6 2 2 1 4 4 0 5 7 2 2 9 1 2 6 6 1 0 9 2 6 7 5 6 3\n",
      " 6 9 1 0 5 1 3 5 6 7 8 0 5 9 3 2 6 5 9 8 2 6 7 5 6 1 7 2 1 8 8 8 7 8 1 4 9\n",
      " 4 3 7 0 1 8 5 7 3 4 4 3 8 9 9 2 2 2 9 8 2 3 4 5 1 6 7 5 4 0 7 8 9 8 7 9 6\n",
      " 3 0 5 6 7 0 9 2 7 3 4 3 6 9 0 4 4 6 8 9 4 4 3 1 4 5 2 1 3 2 8 2 0 1 3 2 6\n",
      " 8 0 5 0 2 4 2 7 4 7 4 8 5 4 5 4 5 4 8 8 7 6 6 2 5 6 5 7 7 4 8 9 5 9 1 1 5\n",
      " 3 6 4 2 8 5 2 4 9 3 0 1 9 3 1 9 4 9 3 8 0 2 3 2 1 7 1 0 5 2 3 1 6 5 9 5 5\n",
      " 2 9 1 4 5 6 3 4 5 8 3 8 0 6 3 2 4 4 6 3 4 7 6 8 3 8 9 9 2 2 5 6 5 0 1 6 4\n",
      " 5 9 0 7 1 3 3 1 8 6 6 8 9 4 2 0 8 2 1 8 2 6 9 2 0 5 8 8 4 0 8 1 0 3 0 2 8\n",
      " 1 6 9 4 9 7 3 9 7 4 9 6 8 1 6 1 9 0 0 5 5 1 8 3 9 9 2 2 7 7 5 1 6 2 0 0 7\n",
      " 4 4 3 2 0 5 4 4 0 8 3 4 7 1 8 8 5 9 6 7 1 1 5 1 6 8 0 9 7 1 7 6 2 8 0 3 5\n",
      " 7 9 1 1 9 0 2 9 3 0 0 1 9 8 9 7 0 3 7 3 8 7 2 6 7 8 5 3 8 7 0 0 0 9 9 3 7\n",
      " 5 6 5 8 7 5 6 3 0 2 3 6 2 9 3 4 7 4 1 3 9 7 5 2 3]\n",
      "{'train': 404, 'val': 101}\n",
      "OR\n",
      "Number of training images 5\n",
      "Number of validation images 5\n",
      "{'train': 404, 'val': 101}\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inputs, classes = next(iter(dset_loaders['train']))\\nprint(inputs.shape)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = 5\n",
    "random_seed = 1\n",
    "\n",
    "if data_type == 'circular':\n",
    "    fvec, label = generateCircularData(num_samples = num_samples, \n",
    "                                       num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'linear':\n",
    "    fvec, label = generateLinearData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'spiral':\n",
    "    fvec, label = generateSpiralData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "else:\n",
    "    num_classes = num_bins\n",
    "    nclasses = num_classes\n",
    "    \n",
    "    feat=train_df.values[:,:-2]\n",
    "    #Normalize the features\n",
    "\n",
    "    feat_max = np.amax(feat,axis=0)\n",
    "    feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "    feat=feat*2-1\n",
    "\n",
    "    '''feat_mean = np.mean(feat,axis=0)\n",
    "    feat_std = np.std(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_mean)/feat_std\n",
    "    '''\n",
    "    label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "    rand_idx = np.random.permutation(len(label_ord))\n",
    "    feat = feat[rand_idx, :]\n",
    "    label = label_ord[rand_idx]\n",
    "\n",
    "\n",
    "    print(np.mean(feat,axis=0))\n",
    "    print(np.min(feat,axis=0))\n",
    "    print(feat.shape)\n",
    "    print(label)\n",
    "\n",
    "    fvec=feat.copy()\n",
    "    dim = feat.shape[1]\n",
    "    \n",
    "    if not CV == 0: \n",
    "        dset_train= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "        dset_val= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "\n",
    "        '''Define dataset loaders''''''\n",
    "        dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                            num_workers=12)}\n",
    "\n",
    "\n",
    "        dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        print(dset_sizes)\n",
    "\n",
    "        if use_gpu:\n",
    "            print('GPU is available')\n",
    "        else:\n",
    "            print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "        inputs, classes = next(iter(dset_loaders['train']))\n",
    "        print(inputs.shape)'''\n",
    "        '''dset_train = datasets.ImageFolder(data_dir+'/train_val', data_transforms['train'])\n",
    "        dset_val = datasets.ImageFolder(data_dir+'/train_val', data_transforms['val'])'''\n",
    "\n",
    "        num_train = len(dset_train)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        splits = (num_train*np.linspace(0,1,CV+1)).astype(int)\n",
    "\n",
    "        val_idx = [indices[splits[k]:splits[k+1]] for k in range(CV)]\n",
    "        train_idx=[np.setdiff1d(indices,val_idx[k]) for k in range(CV)]\n",
    "        '''Sampler functions for validation and training'''\n",
    "        sampler_train = [torch.utils.data.sampler.SubsetRandomSampler(train_idx[k]) for k in range(CV)]\n",
    "        sampler_val = [torch.utils.data.sampler.SubsetRandomSampler(val_idx[k]) for k in range(CV)]\n",
    "\n",
    "        '''Define dataset loaders'''\n",
    "        dset_loaders_arr = [{'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train[k],\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val[k],\n",
    "                                                            num_workers=12)} for k in range(CV)]\n",
    "        dset_sizes={'train':int(len(dset_train)*(1-1/CV)),'val':int(len(dset_train)*(1/CV))}\n",
    "\n",
    "        print(dset_sizes)\n",
    "        print('OR')\n",
    "        print('Number of training images '+str(len(val_idx)))\n",
    "        print('Number of validation images '+str(len(train_idx)))\n",
    "    \n",
    "\n",
    "\n",
    "'''rand_idx = np.random.permutation(len(label))\n",
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "''''''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}\n",
    "\n",
    "\n",
    "dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "'''\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(dset_sizes)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "'''inputs, classes = next(iter(dset_loaders['train']))\n",
    "print(inputs.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(feat.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('runs_regression/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Feature Length: '+str(dim)+'\\n')\n",
    "    f.write('Number of classes: '+str(num_classes)+'\\n')\n",
    "    f.write('Data type: '+data_type+'\\n')\n",
    "    f.write('Random Noise: '+str(sigma_noise)+'\\n')\n",
    "    \n",
    "    f.write('Hidden sizes: '+ str(hidden_sizes)+'\\n')\n",
    "    f.write('Dropouts: '+str(dropouts)+'\\n')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Number of samples: '+str(num_samples)+'\\n')\n",
    "    \n",
    "    f.write('Optimizer: ' + optimizer + '\\n')\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_regression.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='logs_regression.xlsx',iter_loc=10):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    \n",
    "    print(logname)\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    specs=(datetime.now().strftime('%B%d  %H:%M:%S'),data_type,str(hidden_sizes),str(dim),str(num_classes),\n",
    "           crt, str(lr), str(m_coeff), str(algo))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)\n",
    "writeLog_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc0): Linear (2 -> 50)\n",
      "  (relu0): ReLU ()\n",
      "  (drop0): Dropout (p = 0)\n",
      "  (fc1): Linear (50 -> 50)\n",
      "  (relu1): ReLU ()\n",
      "  (drop1): Dropout (p = 0)\n",
      "  (fc2): Linear (50 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropouts, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.numHidden=len(hidden_sizes)\n",
    "        setattr(self, 'fc0', nn.Linear(input_size, hidden_sizes[0]))\n",
    "        setattr(self, 'relu0', nn.ReLU())\n",
    "        setattr(self, 'drop0', nn.Dropout(p=dropouts[0]))\n",
    "        for k in range(len(hidden_sizes)-1):\n",
    "            setattr(self, 'fc'+str(k+1), nn.Linear(hidden_sizes[k], hidden_sizes[k+1]))\n",
    "            setattr(self, 'relu'+str(k+1), nn.ReLU())\n",
    "            setattr(self, 'drop'+str(k+1), nn.Dropout(p=dropouts[k+1]))\n",
    "        setattr(self, 'fc'+str(len(hidden_sizes)), nn.Linear(hidden_sizes[-1], num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.fc0(x)\n",
    "        out = self.relu0(out)\n",
    "        out = self.drop0(out)\n",
    "        for k in range(self.numHidden-1):\n",
    "            fc = getattr(self,'fc'+str(k+1))\n",
    "            relu = getattr(self,'relu'+str(k+1))\n",
    "            drop = getattr(self,'drop'+str(k+1))\n",
    "            out = fc(out)\n",
    "            out = relu(out)\n",
    "            out = drop(out)\n",
    "        fc = getattr(self,'fc'+str(self.numHidden))\n",
    "        out = fc(out)\n",
    "        return out\n",
    "    \n",
    "model=Net(2, [50, 50], [0, 0], 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    nclasses=num_classes,\n",
    "                    hidden_sizes = hidden_sizes,\n",
    "                    dropouts = dropouts):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    model_ft = Net(dim, hidden_sizes , dropouts, num_classes)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end_to_end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6fc291b403a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                             \u001b[0mlr_decay_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_decay_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                             nclasses=num_classes)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0ma_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-c06a19410825>\u001b[0m in \u001b[0;36mnetwork_loader\u001b[0;34m(comment, optimizer, iter_loc, lr, momentum, weight_decay, lr_scheduler, lr_decay_epoch, nclasses, hidden_sizes, dropouts)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_to_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end_to_end' is not defined"
     ]
    }
   ],
   "source": [
    "model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "a_vec = Variable(torch.randn(10, 1), requires_grad=True)\n",
    "params = optimizer_ft.param_groups\n",
    "params[0]['params'].append(a_vec)\n",
    "optimizer_ft.param_groups = params\n",
    "print(optimizer_ft.param_groups)\n",
    "#optimizer_ft.add_param_group({'params': a_vec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_epochs(result_log, logname):\n",
    "    print(len(result_log))\n",
    "\n",
    "    wb_tr = openpyxl.Workbook()\n",
    "    ws_tr = wb_tr.active\n",
    "    wb_val = openpyxl.Workbook()\n",
    "    ws_val = wb_val.active\n",
    "    print(logname)\n",
    "\n",
    "    label_arr_tr = np.zeros((100000,1))\n",
    "    probs_arr_tr = np.zeros((100000, num_classes))\n",
    "    label_arr_val = np.zeros((100000,1))\n",
    "    probs_arr_val = np.zeros((100000, num_classes))\n",
    "\n",
    "    prev_epoch = 0\n",
    "    \n",
    "    count_tr = count_val = 0\n",
    "    for result in result_log:\n",
    "        epoch = result[1]\n",
    "        if not epoch == prev_epoch:\n",
    "            label_arr_tr = label_arr_tr[:count_tr]\n",
    "            probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "            label_arr_val = label_arr_val[:count_val]\n",
    "            probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            ws_tr.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "            ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "                ws_tr.append(probs)\n",
    "            #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "            ws_val.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "            ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_val[1:,:].T.tolist():\n",
    "                ws_val.append(probs)\n",
    "    \n",
    "\n",
    "            label_arr_tr = np.zeros((100000,1))\n",
    "            probs_arr_tr = np.zeros((100000, num_classes))\n",
    "            label_arr_val = np.zeros((100000,1))\n",
    "            probs_arr_val = np.zeros((100000, num_classes)) \n",
    "            count_tr = count_val = 0\n",
    "            prev_epoch = epoch\n",
    "\n",
    "        label = np.asarray(result[2]).reshape(-1,1)\n",
    "        scores = np.asarray(result[3])\n",
    "        exp_scores = np.exp(scores - np.max(scores,axis=1).reshape(-1, 1)*np.ones(num_classes))\n",
    "        probs = np.round(exp_scores/(np.sum(exp_scores,axis=1).reshape(-1, 1)*np.ones(num_classes)), decimals=2)\n",
    "        if result[0] == 'train':\n",
    "            label_arr_tr[count_tr:count_tr + len(label)]  = label\n",
    "            probs_arr_tr[count_tr:count_tr + len(label), :] = probs\n",
    "            count_tr += len(label)\n",
    "        elif result[0] == 'val':\n",
    "            label_arr_val[count_val:count_val + len(label)]  = label\n",
    "            probs_arr_val[count_val:count_val + len(label), :] = probs\n",
    "            count_val += len(label)\n",
    "\n",
    "\n",
    "    \n",
    "    label_arr_tr = label_arr_tr[:count_tr]\n",
    "    probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "    label_arr_val = label_arr_val[:count_val]\n",
    "    probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            \n",
    "    ws_tr.append(['Epoch ' + str(epoch)])\n",
    "    ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "    ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "        ws_tr.append(probs)\n",
    "    #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "    ws_val.append(['Epoch ' + str(epoch)])\n",
    "    ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "    ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_val[1:,:].T.tolist():\n",
    "        ws_val.append(probs)\n",
    "    wb_val.save('./runs_regression/'+logname + '/val.xlsx')\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, num_classes))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, num_classes))\n",
    "    prev_epoch = epoch\n",
    "    print('Finito')\n",
    "    \n",
    "    del label_arr_tr, probs_arr_tr, label_arr_val, probs_arr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "    \n",
    "def run_network():\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "    \n",
    "    \n",
    "    '''Name of the trial'''\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname='Ordinal_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('runs_regression/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    best_model, last_model, result_log = ft.train_model(model_ft,optimizer_ft, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=100,batch_size=batch_size,num_log=250,\n",
    "                            lr_decay_epoch=lr_decay_epoch,init_lr=lr,regression=False,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss,numOut=num_classes,\n",
    "                            logname='logs_regression.xlsx',\n",
    "                            multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL, algo = algo)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'./saved_models/ord/'+logname+'_best')\n",
    "    torch.save(last_model,'./saved_models/ord/'+logname+'_last')\n",
    "    \n",
    "    '''print('Writing results')\n",
    "    write_epochs(result_log, logname)\n",
    "    print('Wrote results')'''\n",
    "    '''Free up the memory'''\n",
    "    del model_ft, result_log\n",
    "    \n",
    "    writer.close\n",
    "    del writer\n",
    "    return last_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22784, 16)\n"
     ]
    }
   ],
   "source": [
    "'''hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "end_to_end = True\n",
    "run_network()'''\n",
    "print(fvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=1 #Initial learning rate\n",
    "momentum=0.5\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=15 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]\n",
    "dropouts = [0, 0, 0, 0, 0, .5, .5, .5, 0, 0, 0]\n",
    "\n",
    "'''hidden_size = [64, 64, 128, 64, 32]\n",
    "dropouts = [0, 0, 0, 0, 0]'''\n",
    "\n",
    "single_loss=0.\n",
    "multi_loss =1.\n",
    "\n",
    "metric = 'mae'\n",
    "algo = 'cheng'\n",
    "for dset_loaders in dset_loaders_arr:\n",
    "    run_network()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72625953  0.235544    0.03819638]\n",
      " [ 0.17899252  0.39192492  0.4290826 ]\n",
      " [ 0.68682605  0.26286978  0.05030423]\n",
      " [ 0.69291276  0.25876865  0.04831864]\n",
      " [ 0.50891167  0.36219808  0.12889017]]\n",
      "(5, 1)\n",
      "(5, 1)\n",
      "(5, 1)\n",
      "[[ 0.72625959  0.23554402  0.03819639]\n",
      " [ 0.17899252  0.3919249   0.42908258]\n",
      " [ 0.68682599  0.26286977  0.05030424]\n",
      " [ 0.69291273  0.25876863  0.04831864]\n",
      " [ 0.50891171  0.3621981   0.12889019]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n"
     ]
    }
   ],
   "source": [
    "numOut = 3\n",
    "numIns = 5\n",
    "\n",
    "log_j_fact = np.log(np.asarray([math.factorial(j) for j in range(numOut)]))\n",
    "ones_vec = Variable(torch.ones(numOut).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "j_vec = Variable(torch.range(0, numOut-1).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "log_j_fact = Variable(torch.from_numpy(log_j_fact).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "\n",
    "\n",
    "preds = Variable(torch.randn(numIns,1).cuda())\n",
    "softplus_step = torch.nn.Softplus()\n",
    "preds = softplus_step(preds)\n",
    "outputs = torch.mm(preds, ones_vec)\n",
    "outputs = j_vec * torch.log(outputs) - outputs - log_j_fact\n",
    "softmax_step = torch.nn.Softmax(dim=1)\n",
    "outputs_softmax = softmax_step(outputs)\n",
    "print(outputs_softmax.data.cpu().numpy())\n",
    "\n",
    "f = preds.data.cpu().numpy()\n",
    "pos_f = np.zeros((numIns,numOut))\n",
    "\n",
    "log_j = np.asarray([(np.log(math.factorial(k))) for k in range(numOut)]).reshape(numOut,1)\n",
    "for k in range(numOut):\n",
    "    print((k*np.log(f) -f - np.log(math.factorial(k))).shape)\n",
    "    pos_f[:, k] = (k*np.log(f) -f - np.log(math.factorial(k))).reshape(numIns)\n",
    "    \n",
    "soft_pos = np.exp(pos_f)\n",
    "soft_pos = soft_pos/(np.sum(soft_pos, axis=1).reshape(-1,1)*np.ones((1, numOut)))\n",
    "print(soft_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1 1 0 1 1 1]\n",
      " [1 1 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 0 1 0 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n",
      "[ 1  1 -1  9  3]\n"
     ]
    }
   ],
   "source": [
    "preds = (np.random.randint(0,5, size = (5,10))>0).astype(np.int)\n",
    "print(preds)\n",
    "print(np.sum(np.cumprod(preds,axis = 1), axis=1)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 34s\n",
      "Best val RMSE: 1.582704\n",
      "logs_regression.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.147533\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 33s\n",
      "Best val RMSE: 1.177344\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.090009\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.410709\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.353397\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.080887\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.156129\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.185724\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.364326\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.694487\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.304979\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.304979\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.338686\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.566986\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.573292\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.320066\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.262561\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 1.214598\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.554298\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.342379\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 27s\n",
      "Best val RMSE: 1.029274\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 27s\n",
      "Best val RMSE: 1.112485\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 26s\n",
      "Best val RMSE: 1.108027\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.353397\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 1.342379\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.134517\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 30s\n",
      "Best val RMSE: 1.085457\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 50s\n",
      "Best val RMSE: 1.094541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 1.414214\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 4s\n",
      "Best val RMSE: 2.897592\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 5s\n",
      "Best val RMSE: 2.976808\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 2.877017\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 4s\n",
      "Best val RMSE: 3.947678\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 5s\n",
      "Best val RMSE: 2.906122\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:119: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  a_vec = Variable(torch.range(0, numOut - 1).cuda().view(numOut, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 5s\n",
      "Best val RMSE: 3.402096\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 5s\n",
      "Best val RMSE: 3.177894\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 4s\n",
      "Best val RMSE: 2.671818\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 57s\n",
      "Best val RMSE: 2.861489\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 26s\n",
      "Best val RMSE: 3.604178\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.357050\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 28s\n",
      "Best val RMSE: 0.995037\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.029274\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 51s\n",
      "Best val RMSE: 1.138872\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.357050\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:127: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  j_vec = Variable(torch.range(0, numOut-1).type(torch.FloatTensor).cuda().view(1, numOut))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE: 1.774405\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.289716\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.285871\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.214598\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 11s\n",
      "Best val RMSE: 1.499175\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:139: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  j_vec = Variable(torch.range(0, numOut-1).type(torch.FloatTensor).cuda().view(1, numOut))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.320066\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.112485\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:414: RuntimeWarning: invalid value encountered in less\n",
      "  labels_numpy=labels.data.cpu().numpy().reshape(-1, 1)\n",
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:415: RuntimeWarning: invalid value encountered in greater\n",
      "  \n",
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:420: RuntimeWarning: invalid value encountered in less_equal\n",
      "  running_mae += np.sum(np.abs(preds_numpy - labels_numpy))\n",
      "/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py:424: RuntimeWarning: invalid value encountered in less\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.465781\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 2.356789\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.285871\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.479229\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 1.121350\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.177344\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE: 1.210515\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.459011\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE: 1.407195\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.034073\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.198183\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.168904\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 1.459011\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 1.676866\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.234809\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.334982\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 1.353397\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 1.582704\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 11s\n",
      "Best val RMSE: 1.595166\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.334982\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.316310\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.181541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 1.566986\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.301180\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.067059\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.116926\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 1.134517\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.323811\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.393052\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 1.181541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.143211\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.062409\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.428147\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 11s\n",
      "Best val RMSE: 2.998349\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 2.322938\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 29s\n",
      "Best val RMSE: 2.682913\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 35s\n",
      "Best val RMSE: 2.408730\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 2.590921\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE: 4.014824\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 3.628818\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 3.196533\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 10s\n",
      "Best val RMSE: 4.584736\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 3.358158\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.367950\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 0.974933\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.112485\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.014743\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.304979\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 1.631982\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.274269\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 1.289716\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 34s\n",
      "Best val RMSE: 1.297370\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 33s\n",
      "Best val RMSE: 1.479229\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 33s\n",
      "Best val RMSE: 1.353397\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.048337\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.151839\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 31s\n",
      "Best val RMSE: 1.357050\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 32s\n",
      "Best val RMSE: 1.375169\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 35s\n",
      "Best val RMSE: 1.472521\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 35s\n",
      "Best val RMSE: 1.143211\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.143211\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 35s\n",
      "Best val RMSE: 1.130145\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 34s\n",
      "Best val RMSE: 1.371564\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 35s\n",
      "Best val RMSE: 1.431609\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.090009\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.202308\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.181541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.407195\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.818497\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.289716\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.403673\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.181541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.407195\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.601361\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.382350\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.338686\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.210515\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.462400\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.312544\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.076297\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.156129\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.125756\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.353397\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.403673\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.130145\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.164661\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 40s\n",
      "Best val RMSE: 1.057739\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.435063\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 2.985112\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 2.594740\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 2.838909\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 2.363082\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 2.936624\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 3.171657\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 4.313231\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 3.816328\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 5.382406\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 4.767879\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 1.360693\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 0.995037\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 41s\n",
      "Best val RMSE: 1.076297\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 1.108027\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 42s\n",
      "Best val RMSE: 1.312544\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 1.541505\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 41s\n",
      "Best val RMSE: 1.389494\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 1.234809\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 1.270378\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 41s\n",
      "Best val RMSE: 1.445375\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 1.459011\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 41s\n",
      "Best val RMSE: 1.662040\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 1.151839\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 45s\n",
      "Best val RMSE: 1.147533\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 1.0\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "Training complete in 2m 42s\n",
      "Best val RMSE: 2.515300\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 2.973480\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 45s\n",
      "Best val RMSE: 2.770066\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 2.573667\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 46s\n",
      "Best val RMSE: 1.815772\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 43s\n",
      "Best val RMSE: 2.530996\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 2.671818\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 45s\n",
      "Best val RMSE: 2.840653\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 48s\n",
      "Best val RMSE: 2.360987\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 47s\n",
      "Best val RMSE: 2.632621\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 45s\n",
      "Best val RMSE: 2.675522\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 48s\n",
      "Best val RMSE: 2.544651\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 51s\n",
      "Best val RMSE: 2.383940\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 44s\n",
      "Best val RMSE: 2.325068\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 49s\n",
      "Best val RMSE: 2.594740\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 50s\n",
      "Best val RMSE: 2.264666\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 47s\n",
      "Best val RMSE: 2.668110\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 2.159483\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 49s\n",
      "Best val RMSE: 2.562100\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 47s\n",
      "Best val RMSE: 2.725022\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 48s\n",
      "Best val RMSE: 2.589010\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 48s\n",
      "Best val RMSE: 2.297222\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 49s\n",
      "Best val RMSE: 1.924310\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 2.103745\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 50s\n",
      "Best val RMSE: 1.613679\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 2.106097\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 2s\n",
      "Best val RMSE: 1.921736\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 57s\n",
      "Best val RMSE: 1.832058\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 57s\n",
      "Best val RMSE: 1.829354\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 1.656072\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 54s\n",
      "Best val RMSE: 1.906217\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 51s\n",
      "Best val RMSE: 1.274269\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 51s\n",
      "Best val RMSE: 0.990050\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 1.019610\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 1.112485\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 49s\n",
      "Best val RMSE: 1.638038\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 1.455614\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 1.338686\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 1.378764\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 52s\n",
      "Best val RMSE: 1.238811\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 1.505765\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 58s\n",
      "Best val RMSE: 1.757586\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 60s\n",
      "Best val RMSE: 1.495869\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 0s\n",
      "Best val RMSE: 1.448796\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 59s\n",
      "Best val RMSE: 1.282016\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 60s\n",
      "Best val RMSE: 1.850876\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 57s\n",
      "Best val RMSE: 1.802089\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 53s\n",
      "Best val RMSE: 1.435063\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 55s\n",
      "Best val RMSE: 1.342379\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 55s\n",
      "Best val RMSE: 1.509049\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 59s\n",
      "Best val RMSE: 1.679816\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 58s\n",
      "Best val RMSE: 1.378764\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 2m 59s\n",
      "Best val RMSE: 1.143211\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 2s\n",
      "Best val RMSE: 1.000000\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 13s\n",
      "Best val RMSE: 1.181541\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 16s\n",
      "Best val RMSE: 1.396601\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 14s\n",
      "Best val RMSE: 3.016457\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.613749\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.459574\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.170915\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.810870\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.686600\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 17s\n",
      "Best val RMSE: 2.277744\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.958458\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.491570\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 2.859758\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.515300\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.784327\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.383940\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 2.266851\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 19s\n",
      "Best val RMSE: 2.554360\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 24s\n",
      "Best val RMSE: 2.684757\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 23s\n",
      "Best val RMSE: 2.513331\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 18s\n",
      "Best val RMSE: 2.437333\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 17s\n",
      "Best val RMSE: 1.959996\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 15s\n",
      "Best val RMSE: 2.335690\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 2.423074\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 21s\n",
      "Best val RMSE: 1.997523\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 21s\n",
      "Best val RMSE: 1.995043\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 30s\n",
      "Best val RMSE: 1.737758\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 19s\n",
      "Best val RMSE: 2.166349\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 1.949867\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 1.688634\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 27s\n",
      "Best val RMSE: 1.729190\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 24s\n",
      "Best val RMSE: 1.595166\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 1.877432\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 22s\n",
      "Best val RMSE: 1.289716\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 21s\n",
      "Best val RMSE: 1.057739\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 23s\n",
      "Best val RMSE: 1.014743\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 21s\n",
      "Best val RMSE: 1.053048\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 1.218667\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 1.435063\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 20s\n",
      "Best val RMSE: 1.250742\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 1s\n",
      "Best val RMSE: 1.185724\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 1s\n",
      "Best val RMSE: 1.459011\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 3s\n",
      "Best val RMSE: 1.746283\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 8s\n",
      "Best val RMSE: 1.749116\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.438509\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE: 1.538290\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.316310\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 7s\n",
      "Best val RMSE: 1.700320\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 1.911404\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 5s\n",
      "Best val RMSE: 1.522114\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 9s\n",
      "Best val RMSE: 1.622857\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 1.522114\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 7s\n",
      "Best val RMSE: 1.766016\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 4s\n",
      "Best val RMSE: 1.489235\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 17s\n",
      "Best val RMSE: 1.125756\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 26s\n",
      "Best val RMSE: 1.164661\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 1.138872\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 1.320066\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 24s\n",
      "Best val RMSE: 2.628857\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 27s\n",
      "Best val RMSE: 2.350479\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 36s\n",
      "Best val RMSE: 2.649491\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 1.723455\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 3.727075\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 24s\n",
      "Best val RMSE: 2.381862\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 29s\n",
      "Best val RMSE: 2.337808\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 22s\n",
      "Best val RMSE: 3.009885\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 2.068146\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 25s\n",
      "Best val RMSE: 3.027923\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 27s\n",
      "Best val RMSE: 2.686600\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 2.124818\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 30s\n",
      "Best val RMSE: 2.461586\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 2.728653\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 31s\n",
      "Best val RMSE: 2.666254\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 26s\n",
      "Best val RMSE: 2.986770\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 26s\n",
      "Best val RMSE: 2.113137\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 29s\n",
      "Best val RMSE: 2.297222\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 2.166349\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 29s\n",
      "Best val RMSE: 2.560167\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 30s\n",
      "Best val RMSE: 2.065751\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 30s\n",
      "Best val RMSE: 2.240491\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 37s\n",
      "Best val RMSE: 1.949867\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 31s\n",
      "Best val RMSE: 1.667986\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 2.360987\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 30s\n",
      "Best val RMSE: 2.046489\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 34s\n",
      "Best val RMSE: 1.890571\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 35s\n",
      "Best val RMSE: 1.777193\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 34s\n",
      "Best val RMSE: 1.570142\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 36s\n",
      "Best val RMSE: 2.122487\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 40s\n",
      "Best val RMSE: 1.375169\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 29s\n",
      "Best val RMSE: 1.053048\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 32s\n",
      "Best val RMSE: 1.062409\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 45s\n",
      "Best val RMSE: 1.076297\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 42s\n",
      "Best val RMSE: 1.246778\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 38s\n",
      "Best val RMSE: 1.438509\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 2s\n",
      "Best val RMSE: 1.659059\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 7s\n",
      "Best val RMSE: 1.278148\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 9s\n",
      "Best val RMSE: 1.206418\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 9s\n",
      "Best val RMSE: 1.222722\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.717701\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 1.304979\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 15s\n",
      "Best val RMSE: 1.448796\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 14s\n",
      "Best val RMSE: 1.258634\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 2s\n",
      "Best val RMSE: 1.694487\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 3m 53s\n",
      "Best val RMSE: 1.895800\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.585828\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.289716\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 14s\n",
      "Best val RMSE: 1.475879\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 14s\n",
      "Best val RMSE: 1.635013\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.389494\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.067059\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 1.057739\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 1.246778\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.1\n",
      "LR is set to 0.010000000000000002\n",
      "LR is set to 0.0010000000000000002\n",
      "Training complete in 4m 14s\n",
      "Best val RMSE: 1.270378\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 9s\n",
      "Best val RMSE: 4.418682\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 8s\n",
      "Best val RMSE: 2.320806\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 9s\n",
      "Best val RMSE: 2.656954\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 3.853762\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 10s\n",
      "Best val RMSE: 2.764700\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 11s\n",
      "Best val RMSE: 4.382684\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 2.986770\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 20s\n",
      "Best val RMSE: 3.551600\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 3.725747\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 4.219239\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 19s\n",
      "Best val RMSE: 4.135095\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 16s\n",
      "Best val RMSE: 3.415167\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 12s\n",
      "Best val RMSE: 3.816328\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 16s\n",
      "Best val RMSE: 4.196887\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 15s\n",
      "Best val RMSE: 3.318117\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 3.444036\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 16s\n",
      "Best val RMSE: 2.837165\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 10s\n",
      "Best val RMSE: 3.658707\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 11s\n",
      "Best val RMSE: 3.564123\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 2.560167\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 16s\n",
      "Best val RMSE: 4.046756\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 19s\n",
      "Best val RMSE: 3.018097\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 19s\n",
      "Best val RMSE: 2.826676\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 17s\n",
      "Best val RMSE: 2.902713\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 16s\n",
      "Best val RMSE: 2.640132\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 20s\n",
      "Best val RMSE: 2.619425\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 19s\n",
      "Best val RMSE: 2.985112\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 15s\n",
      "Best val RMSE: 2.463596\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 3.122895\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 17s\n",
      "Best val RMSE: 2.912928\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 20s\n",
      "Best val RMSE: 1.438509\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 1.099054\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 1.189891\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 1.301180\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 1.364326\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 1.367950\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 1.090009\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 1.062409\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 1.202308\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 19s\n",
      "Best val RMSE: 1.396601\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 29s\n",
      "Best val RMSE: 3.032824\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 3.361105\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 29s\n",
      "Best val RMSE: 3.207355\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 3.231957\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 3.394813\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 2.134117\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 2.134117\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 29s\n",
      "Best val RMSE: 1.929449\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 30s\n",
      "Best val RMSE: 1.901016\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 25s\n",
      "Best val RMSE: 2.007412\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 47s\n",
      "Best val RMSE: 1.880067\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 13s\n",
      "Best val RMSE: 1.459011\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 30s\n",
      "Best val RMSE: 1.723455\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 1.576435\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 1.619803\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 3.752227\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 3.946423\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 3.328544\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 2.451510\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 3.646509\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 3.955195\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 3.476940\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 3.506712\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 3.435401\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 3.628818\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 25s\n",
      "Best val RMSE: 3.813732\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 2.826676\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 21s\n",
      "Best val RMSE: 4.101437\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 24s\n",
      "Best val RMSE: 3.364050\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 29s\n",
      "Best val RMSE: 2.840653\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 24s\n",
      "Best val RMSE: 3.846047\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 3.374335\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 3.624723\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 3.091028\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 24s\n",
      "Best val RMSE: 4.036958\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 3.327057\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 30s\n",
      "Best val RMSE: 2.656954\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 2.519233\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 25s\n",
      "Best val RMSE: 2.739516\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1, 1, 1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 22s\n",
      "Best val RMSE: 2.821417\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 3.241134\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 23s\n",
      "Best val RMSE: 2.571743\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 31s\n",
      "Best val RMSE: 2.463596\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 2.697634\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 28s\n",
      "Best val RMSE: 2.453528\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 1.455614\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 1.160403\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 30s\n",
      "Best val RMSE: 1.160403\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 1.293548\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 1.393052\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 29s\n",
      "Best val RMSE: 1.410709\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 27s\n",
      "Best val RMSE: 1.125756\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 24s\n",
      "Best val RMSE: 1.160403\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 24s\n",
      "Best val RMSE: 1.226764\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 26s\n",
      "Best val RMSE: 1.396601\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 4m 31s\n",
      "Best val RMSE: 3.381663\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [1]\n",
      "LR is set to 0.01\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "received 0 items of ancdata",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9cfcd5fb3db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cheng'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdset_loaders\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_loaders_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'poisson'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-1d854c7fac37>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0miter_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_loc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumOut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0mlogname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs_regression.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                             multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL, algo = algo)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m'''Save the models'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, lr_scheduler, dset_loaders, dset_sizes, writer, use_gpu, num_epochs, batch_size, num_log, init_lr, lr_decay_epoch, regression, learn_a, cross_loss, multi_loss, write_log, numOut, logname, iter_loc, multi_coeff, single_coeff, KL, poisson, binomial, cheng, algo)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mrunning_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 raise RuntimeError('received %d items of ancdata' %\n\u001b[0;32m--> 161\u001b[0;31m                                    len(ancdata))\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mcmsg_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmsg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmsg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             if (cmsg_level == socket.SOL_SOCKET and\n",
      "\u001b[0;31mRuntimeError\u001b[0m: received 0 items of ancdata"
     ]
    }
   ],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=40 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = [0, 0, .5, .5, .5, .5, .5, .5, .5, 0, 0]#.5, .5, .5]\n",
    "\n",
    "for lr_now in [1, 0.1, 0.01]:\n",
    "    lr = lr_now\n",
    "    for kk in range(3):\n",
    "\n",
    "        algo = 'None'\n",
    "        single_loss=1.\n",
    "        multi_loss =0.\n",
    "        KL = True\n",
    "        metric = 'ccr'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'ccr1'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        single_loss=0.\n",
    "        multi_loss =1.\n",
    "        metric = 'ccr'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'ccr1'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'learn_a'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'fix_a'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'cheng'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'poisson'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'binomial'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm is learn_a\n",
      "Multi_coef is [ 0.  1.  0.]\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR is set to 0.05\n",
      "Variable containing:\n",
      "-2.0074\n",
      "-0.1140\n",
      "-0.1974\n",
      " 0.3888\n",
      "-0.6736\n",
      " 0.2404\n",
      "-1.6391\n",
      " 0.1642\n",
      "-0.1674\n",
      " 0.6457\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.1025  0.0933  0.0941  ...   0.0983  0.0927  0.1111\n",
      " 0.1047  0.0948  0.0944  ...   0.1025  0.0950  0.1072\n",
      " 0.1021  0.0927  0.0965  ...   0.1045  0.0949  0.1064\n",
      "          ...                          ...          \n",
      " 0.1040  0.0948  0.0939  ...   0.1008  0.0922  0.1090\n",
      " 0.0991  0.0941  0.0972  ...   0.1027  0.0940  0.1044\n",
      " 0.1043  0.0955  0.0946  ...   0.1007  0.0952  0.1086\n",
      "[torch.cuda.FloatTensor of size 256x10 (GPU 0)]\n",
      "\n",
      "Preds is Variable containing:\n",
      "-0.3485\n",
      "-0.3582\n",
      "-0.3581\n",
      "-0.3557\n",
      "-0.3569\n",
      "-0.3565\n",
      "-0.3537\n",
      "-0.3562\n",
      "-0.3538\n",
      "-0.3593\n",
      "-0.3631\n",
      "-0.3548\n",
      "-0.3626\n",
      "-0.3539\n",
      "-0.3641\n",
      "-0.3569\n",
      "-0.3429\n",
      "-0.3500\n",
      "-0.3584\n",
      "-0.3521\n",
      "-0.3549\n",
      "-0.3500\n",
      "-0.3553\n",
      "-0.3625\n",
      "-0.3547\n",
      "-0.3440\n",
      "-0.3671\n",
      "-0.3595\n",
      "-0.3572\n",
      "-0.3566\n",
      "-0.3550\n",
      "-0.3568\n",
      "-0.3552\n",
      "-0.3466\n",
      "-0.3515\n",
      "-0.3580\n",
      "-0.3507\n",
      "-0.3622\n",
      "-0.3522\n",
      "-0.3573\n",
      "-0.3533\n",
      "-0.3606\n",
      "-0.3545\n",
      "-0.3552\n",
      "-0.3532\n",
      "-0.3560\n",
      "-0.3558\n",
      "-0.3596\n",
      "-0.3607\n",
      "-0.3568\n",
      "-0.3500\n",
      "-0.3619\n",
      "-0.3456\n",
      "-0.3521\n",
      "-0.3497\n",
      "-0.3502\n",
      "-0.3576\n",
      "-0.3547\n",
      "-0.3538\n",
      "-0.3626\n",
      "-0.3592\n",
      "-0.3575\n",
      "-0.3506\n",
      "-0.3596\n",
      "-0.3520\n",
      "-0.3583\n",
      "-0.3605\n",
      "-0.3510\n",
      "-0.3510\n",
      "-0.3536\n",
      "-0.3537\n",
      "-0.3552\n",
      "-0.3535\n",
      "-0.3489\n",
      "-0.3636\n",
      "-0.3608\n",
      "-0.3519\n",
      "-0.3540\n",
      "-0.3575\n",
      "-0.3590\n",
      "-0.3533\n",
      "-0.3562\n",
      "-0.3479\n",
      "-0.3565\n",
      "-0.3520\n",
      "-0.3475\n",
      "-0.3591\n",
      "-0.3483\n",
      "-0.3597\n",
      "-0.3521\n",
      "-0.3544\n",
      "-0.3516\n",
      "-0.3426\n",
      "-0.3565\n",
      "-0.3523\n",
      "-0.3527\n",
      "-0.3632\n",
      "-0.3593\n",
      "-0.3567\n",
      "-0.3530\n",
      "-0.3582\n",
      "-0.3545\n",
      "-0.3480\n",
      "-0.3613\n",
      "-0.3507\n",
      "-0.3571\n",
      "-0.3498\n",
      "-0.3582\n",
      "-0.3532\n",
      "-0.3574\n",
      "-0.3580\n",
      "-0.3658\n",
      "-0.3562\n",
      "-0.3550\n",
      "-0.3553\n",
      "-0.3565\n",
      "-0.3539\n",
      "-0.3554\n",
      "-0.3443\n",
      "-0.3432\n",
      "-0.3557\n",
      "-0.3527\n",
      "-0.3523\n",
      "-0.3609\n",
      "-0.3617\n",
      "-0.3550\n",
      "-0.3551\n",
      "-0.3572\n",
      "-0.3582\n",
      "-0.3643\n",
      "-0.3462\n",
      "-0.3582\n",
      "-0.3487\n",
      "-0.3535\n",
      "-0.3621\n",
      "-0.3536\n",
      "-0.3597\n",
      "-0.3553\n",
      "-0.3498\n",
      "-0.3624\n",
      "-0.3547\n",
      "-0.3630\n",
      "-0.3564\n",
      "-0.3522\n",
      "-0.3460\n",
      "-0.3576\n",
      "-0.3596\n",
      "-0.3566\n",
      "-0.3567\n",
      "-0.3543\n",
      "-0.3546\n",
      "-0.3643\n",
      "-0.3516\n",
      "-0.3510\n",
      "-0.3547\n",
      "-0.3558\n",
      "-0.3575\n",
      "-0.3450\n",
      "-0.3524\n",
      "-0.3457\n",
      "-0.3568\n",
      "-0.3531\n",
      "-0.3567\n",
      "-0.3608\n",
      "-0.3522\n",
      "-0.3484\n",
      "-0.3672\n",
      "-0.3596\n",
      "-0.3602\n",
      "-0.3528\n",
      "-0.3526\n",
      "-0.3599\n",
      "-0.3584\n",
      "-0.3516\n",
      "-0.3520\n",
      "-0.3522\n",
      "-0.3599\n",
      "-0.3585\n",
      "-0.3533\n",
      "-0.3580\n",
      "-0.3579\n",
      "-0.3564\n",
      "-0.3524\n",
      "-0.3535\n",
      "-0.3665\n",
      "-0.3569\n",
      "-0.3565\n",
      "-0.3593\n",
      "-0.3604\n",
      "-0.3484\n",
      "-0.3562\n",
      "-0.3601\n",
      "-0.3568\n",
      "-0.3592\n",
      "-0.3587\n",
      "-0.3563\n",
      "-0.3555\n",
      "-0.3611\n",
      "-0.3581\n",
      "-0.3522\n",
      "-0.3583\n",
      "-0.3568\n",
      "-0.3759\n",
      "-0.3512\n",
      "-0.3576\n",
      "-0.3538\n",
      "-0.3520\n",
      "-0.3598\n",
      "-0.3633\n",
      "-0.3543\n",
      "-0.3587\n",
      "-0.3593\n",
      "-0.3570\n",
      "-0.3562\n",
      "-0.3649\n",
      "-0.3607\n",
      "-0.3645\n",
      "-0.3560\n",
      "-0.3551\n",
      "-0.3641\n",
      "-0.3504\n",
      "-0.3484\n",
      "-0.3557\n",
      "-0.3465\n",
      "-0.3590\n",
      "-0.3532\n",
      "-0.3570\n",
      "-0.3538\n",
      "-0.3473\n",
      "-0.3618\n",
      "-0.3533\n",
      "-0.3521\n",
      "-0.3554\n",
      "-0.3630\n",
      "-0.3565\n",
      "-0.3499\n",
      "-0.3602\n",
      "-0.3556\n",
      "-0.3522\n",
      "-0.3576\n",
      "-0.3543\n",
      "-0.3543\n",
      "-0.3561\n",
      "-0.3528\n",
      "-0.3560\n",
      "-0.3582\n",
      "-0.3500\n",
      "-0.3585\n",
      "-0.3539\n",
      "-0.3585\n",
      "-0.3560\n",
      "-0.3517\n",
      "-0.3571\n",
      "-0.3544\n",
      "-0.3531\n",
      "-0.3544\n",
      "[torch.cuda.FloatTensor of size 256x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 8\n",
      " 0\n",
      " 6\n",
      " 0\n",
      " 9\n",
      " 0\n",
      " 7\n",
      " 5\n",
      " 9\n",
      " 4\n",
      " 3\n",
      " 6\n",
      " 0\n",
      " 8\n",
      " 6\n",
      " 2\n",
      " 7\n",
      " 8\n",
      " 2\n",
      " 6\n",
      " 2\n",
      " 7\n",
      " 5\n",
      " 5\n",
      " 5\n",
      " 9\n",
      " 0\n",
      " 6\n",
      " 5\n",
      " 7\n",
      " 9\n",
      " 6\n",
      " 6\n",
      " 0\n",
      " 8\n",
      " 0\n",
      " 2\n",
      " 8\n",
      " 6\n",
      " 3\n",
      " 6\n",
      " 1\n",
      " 4\n",
      " 2\n",
      " 7\n",
      " 6\n",
      " 0\n",
      " 2\n",
      " 3\n",
      " 8\n",
      " 9\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 9\n",
      " 8\n",
      " 7\n",
      " 9\n",
      " 1\n",
      " 7\n",
      " 1\n",
      " 6\n",
      " 8\n",
      " 6\n",
      " 9\n",
      " 2\n",
      " 0\n",
      " 7\n",
      " 9\n",
      " 5\n",
      " 5\n",
      " 5\n",
      " 9\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 7\n",
      " 9\n",
      " 2\n",
      " 0\n",
      " 3\n",
      " 2\n",
      " 5\n",
      " 2\n",
      " 3\n",
      " 8\n",
      " 2\n",
      " 3\n",
      " 6\n",
      " 6\n",
      " 4\n",
      " 7\n",
      " 6\n",
      " 5\n",
      " 8\n",
      " 8\n",
      " 4\n",
      " 4\n",
      " 7\n",
      " 6\n",
      " 4\n",
      " 5\n",
      " 2\n",
      " 5\n",
      " 9\n",
      " 0\n",
      " 0\n",
      " 5\n",
      " 8\n",
      " 5\n",
      " 5\n",
      " 4\n",
      " 2\n",
      " 8\n",
      " 9\n",
      " 8\n",
      " 5\n",
      " 0\n",
      " 9\n",
      " 5\n",
      " 5\n",
      " 9\n",
      " 4\n",
      " 3\n",
      " 0\n",
      " 0\n",
      " 8\n",
      " 5\n",
      " 4\n",
      " 1\n",
      " 9\n",
      " 2\n",
      " 5\n",
      " 8\n",
      " 3\n",
      " 8\n",
      " 6\n",
      " 3\n",
      " 7\n",
      " 2\n",
      " 8\n",
      " 1\n",
      " 1\n",
      " 8\n",
      " 8\n",
      " 3\n",
      " 2\n",
      " 0\n",
      " 6\n",
      " 7\n",
      " 5\n",
      " 1\n",
      " 9\n",
      " 4\n",
      " 8\n",
      " 7\n",
      " 0\n",
      " 8\n",
      " 9\n",
      " 0\n",
      " 3\n",
      " 0\n",
      " 5\n",
      " 1\n",
      " 8\n",
      " 7\n",
      " 3\n",
      " 0\n",
      " 4\n",
      " 5\n",
      " 9\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 6\n",
      " 2\n",
      " 0\n",
      " 3\n",
      " 5\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 3\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 2\n",
      " 6\n",
      " 2\n",
      " 1\n",
      " 6\n",
      " 4\n",
      " 0\n",
      " 4\n",
      " 6\n",
      " 4\n",
      " 6\n",
      " 6\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 0\n",
      " 8\n",
      " 5\n",
      " 3\n",
      " 2\n",
      " 7\n",
      " 5\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 4\n",
      " 2\n",
      " 5\n",
      " 3\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 8\n",
      " 6\n",
      " 9\n",
      " 6\n",
      " 2\n",
      " 6\n",
      " 9\n",
      " 7\n",
      " 8\n",
      " 6\n",
      " 8\n",
      " 8\n",
      " 0\n",
      " 8\n",
      " 0\n",
      " 4\n",
      " 1\n",
      " 7\n",
      " 0\n",
      " 3\n",
      " 5\n",
      " 4\n",
      " 7\n",
      " 4\n",
      " 3\n",
      " 1\n",
      " 4\n",
      " 8\n",
      " 3\n",
      " 2\n",
      " 6\n",
      " 6\n",
      " 7\n",
      " 4\n",
      " 2\n",
      "[torch.cuda.FloatTensor of size 256 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5a1e68e99e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmulti_coeff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_coeff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlmbda_mae\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-1d854c7fac37>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0miter_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_loc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumOut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0mlogname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs_regression.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                             multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL, algo = algo)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m'''Save the models'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, lr_scheduler, dset_loaders, dset_sizes, writer, use_gpu, num_epochs, batch_size, num_log, init_lr, lr_decay_epoch, regression, learn_a, cross_loss, multi_loss, numOut, logname, iter_loc, multi_coeff, single_coeff, KL, algo)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "end_to_end = True\n",
    "optimizer='adam' #Optimizer function\n",
    "lr=0.05 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "\n",
    "\n",
    "hidden_sizes = [16, 16, 32, 32, 16, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = []#.5, .5, .5]\n",
    "single_loss=1.0\n",
    "multi_loss =0.0\n",
    "\n",
    "KL = True\n",
    "metric = None\n",
    "\n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'ccr1', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "        \n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'mae', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "    \n",
    "'''KL = True\n",
    "metric = 'ccr'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'ccr1'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mae'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mse'\n",
    "for k in range(10):\n",
    "    run_network()'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader again, this time without shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_shape = 'Spiral'\n",
    "data_date = '18_01_31'\n",
    "data_dir = './saved_models_github/' + data_shape + '/' + data_date\n",
    "\n",
    "run_dirs = sorted(os.listdir(data_dir))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:110]\n",
    "mae_dirs = last_dirs[110:]\n",
    "all_dirs = [ccr1_dirs, mae_dirs]\n",
    "\n",
    "\n",
    "'''run_dirs = sorted(os.listdir('./saved_models/test'))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:100]\n",
    "mae_dirs = last_dirs[100:]\n",
    "\n",
    "pure_ccr1 = ['Ordinal_January24  14:10:01_last',\n",
    "             'Ordinal_January24  14:11:08_last',\n",
    "             'Ordinal_January24  14:12:14_last',\n",
    "             'Ordinal_January24  14:13:21_last',\n",
    "             'Ordinal_January24  14:14:27_last',\n",
    "             'Ordinal_January24  14:15:34_last',\n",
    "             'Ordinal_January24  14:16:40_last',\n",
    "             'Ordinal_January24  14:17:47_last',\n",
    "             'Ordinal_January24  14:18:54_last',\n",
    "             'Ordinal_January24  14:20:00_last',]\n",
    "\n",
    "pure_mae = ['Ordinal_January24  14:21:07_last',\n",
    "             'Ordinal_January24  14:22:13_last',\n",
    "             'Ordinal_January24  14:23:19_last',\n",
    "             'Ordinal_January24  14:24:26_last',\n",
    "             'Ordinal_January24  14:25:32_last',\n",
    "             'Ordinal_January24  14:26:38_last',\n",
    "             'Ordinal_January24  14:27:45_last',\n",
    "             'Ordinal_January24  14:28:52_last',\n",
    "             'Ordinal_January24  14:29:58_last',\n",
    "             'Ordinal_January24  14:31:05_last',]'''\n",
    "                \n",
    "len(mae_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.load('./saved_models/ord/Ordinal_January24  10:24:20_last', map_location={'cuda:0': 'cpu'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model_dir, phase='train'):\n",
    "    if use_gpu:\n",
    "        model = torch.load(model_dir)\n",
    "    else:\n",
    "        model = torch.load(model_dir, map_location={'cuda:0': 'cpu'})\n",
    "    model.train(False)\n",
    "\n",
    "    labels_arr = np.asarray([]);\n",
    "    preds_arr = np.asarray([]);\n",
    "    for data in dset_loaders[phase]:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = np.argmax(model(inputs).cpu().data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.cpu().data.numpy())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            outputs = np.argmax(model(inputs).data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.data.numpy())\n",
    "          \n",
    "        preds_arr = np.append(preds_arr, outputs)\n",
    "    return preds_arr\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:24:20_last')\n",
    "#print(np.min(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(18,15))\n",
    "\n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+1)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR$ loss' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+6)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[50+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$0.5CCR$ loss + $0.5CCR_1$ loss \\n' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+11)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[100+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR_1$ loss ' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "plt.savefig('variance_of_results.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_and_mean(root_dir, sub_dirs, phase='train'):\n",
    "    scores_arr = np.zeros((label_train.shape[0],9))\n",
    "    for sub_dir in sub_dirs:\n",
    "        if use_gpu:\n",
    "            model = torch.load(root_dir + '/' + sub_dir)\n",
    "        else:\n",
    "            model = torch.load(root_dir + '/' + sub_dir, map_location={'cuda:0': 'cpu'})\n",
    "        model.train(False)\n",
    "        #print(model)\n",
    "        score_arr = np.zeros((1,9))\n",
    "        for data in dset_loaders[phase]:\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                outputs = model(inputs).cpu().data.numpy()\n",
    "                #print(outputs.shape)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                outputs = model(inputs).data.numpy()\n",
    "                \n",
    "            score_arr = np.append(score_arr, outputs, axis=0)\n",
    "        scores_arr += score_arr[1:,:]\n",
    "        \n",
    "    return scores_arr\n",
    "#scores_tr = validate_and_mean('./saved_models/test_circular', last_dirs[:10])\n",
    "#pred_tr = np.argmax(scores_tr, axis=1)\n",
    "#print(np.mean(label_train == pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dirs = ['./saved_models/ord/Ordinal_January24  10:16:00_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:20:35_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:24:20_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:28:03_last']\n",
    "\n",
    "'''model_dirs = ['./saved_models/ord/Ordinal_January24  13:09:17_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:18:08_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:27:43_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:43:43_last']'''\n",
    "\n",
    "model_dirs = ['./saved_models/ord/Ordinal_January26  00:22:14_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:19:20_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:09:08_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:17:53_last']\n",
    "preds = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    preds.append(validate(model_dir))\n",
    "    \n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'CCR1'\n",
    "\n",
    "if metric is 'CCR1':\n",
    "    metric_code = 0\n",
    "elif metric is 'MAE':\n",
    "    metric_code = 1\n",
    "else:\n",
    "    print('Wrong metric')\n",
    "    \n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "metrics = np.zeros((11, 4))\n",
    "for k in range(10):\n",
    "    scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][k*10:(k+1)*10])\n",
    "    pred_tr = np.argmax(scores_tr, axis=1)\n",
    "    plt.subplot(4,3,k+2)\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    metrics[k,:] = [ccr,ccr1,mae,rmse]\n",
    "    plt.title('$\\lambda$=' + str(np.round(k*.1, decimals=1)) + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "              ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "              ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "    \n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:20:35_last')\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  13:18:08_last')\n",
    "\n",
    "scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(4,3,12)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "metrics[10,:] = [ccr,ccr1,mae,rmse]\n",
    "plt.title('$\\lambda$=1.0' + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt_title = data_shape + '_Data_CCR_' + metric + '_tradeoff_' + data_date + '.tiff'\n",
    "plt.savefig(plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "\n",
    "lmbdas = [.1*k for k in range(11)]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.plot(lmbdas, metrics[:,0], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR$')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lmbdas, metrics[:,1], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR_1$')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lmbdas, metrics[:,2], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$MAE$')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lmbdas, metrics[:,3], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$RMSE$')\n",
    "\n",
    "plt.savefig('spiral_plots_ccr1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR_1 loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/ord', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$MAE loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n$MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt.savefig('spiral_extreme.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR_1$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$MAE$ loss')\n",
    "\n",
    "plt.savefig('circular_extreme_hist.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.subplot(211)\n",
    "img = mpimg.imread('Circular_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)\n",
    "plt.subplot(212)\n",
    "img = mpimg.imread('Spiral_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
