{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5\n",
    "\n",
    "\n",
    "#from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "dim = 2\n",
    "\n",
    "def generateLinearData(num_samples = 10000, num_classes = num_classes, dim = dim, bound = 5, sigma_noise = .1,rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    label = np.dot((np.random.rand(1,dim)*bound*2-bound).reshape(1,-1),fvec)\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateLinearData(rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCircularData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    \n",
    "    fvec_l = np.sum(fvec**2, axis = 0).reshape(1,-1)\n",
    "    print(fvec_l.shape)\n",
    "    label = fvec_l\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateCircularData(num_classes =5, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Greys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = 9, dim = 2,\n",
    "                         bound = 1, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "    sample_per_class = int(num_samples/num_classes)\n",
    "    num_samples = sample_per_class*num_classes\n",
    "    fvec = np.zeros((dim, sample_per_class*num_classes))\n",
    "    label = np.zeros((1, sample_per_class*num_classes))\n",
    "    \n",
    "    t = np.linspace(0, 10, sample_per_class)\n",
    "    x = t * np.cos(t)\n",
    "    y = t * np.sin(t)\n",
    "    x = x.reshape(1, -1)\n",
    "    y = y.reshape(1, -1)\n",
    "\n",
    "    cons = .7\n",
    "    for k in range(0, num_classes):\n",
    "        r = np.linspace(0.05, 1, sample_per_class)\n",
    "        t = np.linspace(k*cons, (k+6)*cons, sample_per_class)\n",
    "        x = np.cos(t)\n",
    "        y = np.sin(t)\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        label[0, k*sample_per_class:(k+1)*sample_per_class] = rand_classes[k]\n",
    "        fvec[0, k*sample_per_class:(k+1)*sample_per_class] = bound * x * r\n",
    "        fvec[1, k*sample_per_class:(k+1)*sample_per_class] = bound * y * r\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "X, y = generateSpiralData(num_classes = 9, sigma_noise = 0.01, rand_label = False)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "\n",
    "    cons = 4\n",
    "    N = num_samples # number of points per class\n",
    "    D = dim # dimensionality\n",
    "    K = num_classes # number of classes\n",
    "\n",
    "    X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "    y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "    for j in range(K):\n",
    "      ix = range(N*j,N*(j+1))\n",
    "      r = np.linspace(0.0,1,N) # radius\n",
    "      t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*sigma_noise # theta\n",
    "      X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "      y[ix] = j\n",
    "    \n",
    "    label = y.astype(np.int)\n",
    "    fvec = X\n",
    "    \n",
    "    return fvec, label\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "fvec, label = generateCircularData(num_classes =9, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "fvec, label = generateSpiralData(num_classes = 3, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "#plt.savefig('circular_vs_spiral.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Regression Benchmark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_bins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "housing\n",
      "results.csv\n",
      "stock\n",
      "stocksdomain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/housing\", sep=',', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df = pd.read_csv(\"./dataset/regression/cal_housing\", sep='\\s+', header=None)\n",
    "train_df = pd.read_csv(\"./dataset/regression/cal_housing.data\", sep=',', header=None)\n",
    "#train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples per class is 2064.0\n",
      "[0.0, 82300.000100000005, 107200.00019999999, 134000.00030000001, 157300.00039999999, 179700.00049999999, 209400.0006, 241900.0007, 290000.00079999998, 376600.00089999998, 500001.00099999999]\n",
      "[0.0, 82300.000100000005, 107200.00019999999, 134000.00030000001, 157300.00039999999, 179700.00049999999, 209400.0006, 241900.0007, 290000.00079999998, 376600.00089999998, 500002.00099999999]\n",
      "500001.0\n",
      "Unique labels are [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1Ij/h1G12K9V58BcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05e9ec9208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_bins\n",
    "print('Number of Samples per class is ' + str(num_samples_per_class))\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_bins+1)]\n",
    "bins.insert(0,0.0)\n",
    "print(bins)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "k = 10\n",
    "\n",
    "print(label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]])\n",
    "for k in range(num_bins):\n",
    "    #print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print('Unique labels are ' + str(np.unique(label_ord)))\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "#print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.xlabel('Original Label')\n",
    "plt.ylabel('Ordinal Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAF6CAYAAAAnAED0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm4HGWd9//3NwkQQJZshJAAAUHWkS0DjDAKiQIiijIo\n0VHi/FAcZRwZ1/D4zBBlcOTngyCPCsSBMaBsooyoMBiDCCpbUGQLmCAgCWENmwiBhO/zR9eJfZY+\nS9Ld1af7/bquvk7VXXdVvl0c8sldfXdVZCaSJKl8I8ouQJIkVRjKkiS1CENZkqQWYShLktQiDGVJ\nklqEoSxJUoswlCVJaqCI+ERE3BURd0fEif31NZQlSWqQiNgd+DCwL7AHcERE7FCrv6EsSVLj7ALc\nnJl/zsxVwC+Ao2p1NpQlSWqcu4C/jYhxEbERcDiwda3Oo5pW1jAyfvz4nDp1atllSJIKt91225OZ\nOaHex91g3wPy1WefXuv9V/1+0d3AS1VNczNzbtdKZi6KiNOAnwIvALcDq2sdz1Duw9SpU1m4cGHZ\nZUiSChHxUCOO++qzTzPunIvWev/Hpu/1UmZO669PZp4HnAcQEV8CltbqayhLktRAEbFFZj4eEdtQ\n+Tx5/1p9DWVJkhrr+xExDngFOCEzn6nV0VCWJKmBMvNvB9vX2deSJLUIQ1mSpBZhKEuS1CIMZUmS\nWoShLElSizCUJUlqEU0L5Yh4MCLujIjbI2Jh0TY2IuZHxOLi55iq/idFxJKIuC8iDq1q36c4zpKI\nOCsiomjfICIuLdpvjoipVfvMKv6MxRExq1nvWZKkoWj2SPngzNyz6pZks4EFmbkjsKBYJyJ2BWYC\nuwGHAd+MiJHFPmdTeQzWjsXrsKL9OODpzNwBOAM4rTjWWOBkYD8qj846uTr8JUlqFWXfPORI4KBi\neR5wHfC5ov2SzFwJPBARS4B9I+JBYNPMvAkgIi4A3glcXewzpzjW5cDXi1H0ocD8zFxR7DOfSpBf\n3OD3JknD3pY/v71ux3r04D3rdqx21cyRcgI/i4jbIuL4om1iZi4vlh8FJhbLk4GHq/ZdWrRNpvuN\nvLvau+1TPLPyWWBcP8fqJiKOj4iFEbHwiSeeWLt3KEnSOmjmSPnAzFwWEVsA8yPi3uqNmZkRkU2s\np5viUVtzAaZNm1ZaHZLUjkYO3EU0MZQzc1nx8/GIuILK57uPRcSkzFweEZOAx4vuy+j+EOgpRduy\nYrlne/U+SyNiFLAZ8FTRflCPfa6r3zuTpM7g5efGa8rl64jYOCI26VoGDgHuAq4EumZDzwJ+WCxf\nCcwsZlRvR2VC1y3Fpe7nImL/4vPiY3vs03Wso4FrMzOBa4BDImJMMcHrkKJNkqSW0qyR8kTgiuLb\nS6OAizLzfyLiVuCyiDgOeAh4D0Bm3h0RlwH3AKuoPOpqdXGsjwHfBjakMsHr6qL9PODCYlLYCiqz\nt8nMFRFxCnBr0e+LXZO+JEm13fvM82WX0HGaEsqZ+Qdgjz7anwJm1NjnVODUPtoXArv30f4S8O4a\nxzofOH9oVUtSZ7toueOXZvOOXpKkPl2zwpFysxnKkqQ+PfnyqjXLhkVzeJ4lSX16oWp5dGlVdBZD\nWZI0oIkjo+wSOoKhLEka0Jd2mjJwJ60zQ1mSNKCDJ44ru4SOYChLknqp3HtJzWYoS5J6+fGyx8ou\noSMZypKkXj63+NGyS+hIhrIkqRfv5VUOQ1mS1C+/o9w8hrIkqV9f2n7LskvoGIayJKlfM7feouwS\nhrWI+JeIuDsi7oqIiyOi5sWHZj26UZI0TLyyalW39REj2nf8tj338838u7Xe/80DbI+IycA/A7tm\n5ovFY4lnUnkEcS/te6YlSWvly/cvLbuEdjMK2DAiRgEbAY/U6mgoS5K6+dFjz5RdQtvIzGXA/wH+\nCCwHns3Mn9bqbyhLkrp5eHXZFQwr4yNiYdXr+OqNETEGOBLYDtgK2Dgi3l/rYH6mLEnqpvoGmxuX\nVsWw8WRmTutn+5uBBzLzCYCI+AHwBuA7fXV2pCxJqmmH0Y7d1tEfgf0jYqOICGAGsKhWZ0NZklTT\nqTttU3YJw1pm3gxcDvwGuJNK7s6t1d9/AkmS1njkhRe7rU8bu2lJlbSPzDwZOHkwfR0pS5LW+PCd\n95ddQkczlCVJa9z24qqBO6lhDGVJklqEoSxJAmCHn9/ebf094zYqqZLOZShLkgD4U4/1s17/ulLq\n6GSGsiRJLcJQliT1stdG65VdQkcylCVJ/PnF7t9Pvnq/3UqqpLMZypIkDrzpvrJLEIayJIl+HvCr\npjKUJUndjCy7gA5mKEuSuvnKayeWXULHMpQlqcN97Pbfd1t/3zaTSqpEhrIkdbgfPP3nsktQwVCW\nJKlFGMqSpDX+e5etyy6hoxnKktTBfrL8yW7r+285rqRKBIayJHW0E+9dWnYJqmIoS1IHe77sAtSN\noSxJAsCnJ5fPUJakDrVq1apu6/cd6EMoymYoS1KHevdvFnVbX289H9dYNkNZkjrUjS+sLrsE9WAo\nS5LUIkaVXYAkqfluf6z795MXTXttSZWU6/nnx3HD9R9YhyN8oW61gCNlSepIh93T/fvJYzbZpKRK\nVM1QliSpRRjKktRhVq5c2W39zZtuWFIl6slQlqQOM+3X3b8K9Z19diqpkvYXETtFxO1Vr+ci4sRa\n/Z3oJUkd5omyC+ggmXkfsCdARIwElgFX1OrvSFmSpOaYAdyfmQ/V6tDUUI6IkRHx24j4cbE+NiLm\nR8Ti4ueYqr4nRcSSiLgvIg6tat8nIu4stp0VEVG0bxARlxbtN0fE1Kp9ZhV/xuKImNW8dyxJreXl\nHrfW/PyUzUqqpG2Mj4iFVa/j++k7E7i4v4M1e6T8CaD6w4zZwILM3BFYUKwTEbtSKX434DDgm8Ww\nH+Bs4MPAjsXrsKL9OODpzNwBOAM4rTjWWOBkYD9gX+Dk6vCXpE5ywK/u6rb+8R23K6mStvFkZk6r\nes3tq1NErA+8A/hefwdrWihHxBTgbcB/VjUfCcwrlucB76xqvyQzV2bmA8ASYN+ImARsmpk3ZWYC\nF/TYp+tYlwMzilH0ocD8zFyRmU8D8/lLkEtSR3n41bIr6FhvBX6TmY/116mZI+Uzgc8C1b8SEzNz\nebH8KDCxWJ4MPFzVb2nRNrlY7tnebZ/MXAU8C4zr51iSJDXLexng0jU0KZQj4gjg8cy8rVafYuSb\nzainLxFxfNdnAk884dxESe1nu5/f3m39/NdNKqmSzhIRGwNvAX4wUN9mjZQPAN4REQ8ClwDTI+I7\nwGPFJWmKn48X/ZcBW1ftP6VoW1Ys92zvtk9EjAI2A57q51jdZObcrs8EJkyYsPbvVJJa1Is91g+f\nPLHPfqqvzHwhM8dl5rMD9W1KKGfmSZk5JTOnUpnAdW1mvh+4EuiaDT0L+GGxfCUws5hRvR2VCV23\nFJe6n4uI/YvPi4/tsU/XsY4u/owErgEOiYgxxQSvQ4o2SeoYT7/wQrd1p3e1prJvHvJl4LKIOA54\nCHgPQGbeHRGXAfcAq4ATMrPrwZ8fA74NbAhcXbwAzgMujIglwAoq4U9mroiIU4Bbi35fzMwVjX5j\nktRKdrllcbf1Gw/es6RK1J+mh3JmXgdcVyw/ReXL1H31OxU4tY/2hcDufbS/BLy7xrHOB85f25ol\nSWoG7+glSR3m7zYbXXYJqsFQlqQ2t3+PWdff2HvnkirRQAxlSWpzD5ZdgAbNUJakDrJR2QWoX4ay\nJLWxt//qjm7rf3DWdUszlCWpjd36sje7Hk4MZUnqEGXfmEIDM5QlqU39zS9up/qRAku9dN3yDGVJ\nalMPrF5dyeRMuj+gT63KUJakNnT99W9li6qn1m7b+zk8akF+xCBJbeiVVb/nDD7FAt7EJjzHSQdf\nXnZJGgRDWZLa2Ax+UXYJGgIvX0tSm1lwbfcJXdMPXlJSJRoqQ1mS2s7z3dYqj5/XcGAoS1IbWXDt\na3u0bFVKHVo7hrIktbEZ028ouwQNgaEsSW2i9yjZm4UMN86+lqQ2NWP698suoeWNz0350Esz1nr/\nL/CFOlbjSFmS2kLvUfK4UurQujGUJakNzZh+S9klaC0YypI0zPUcJW839ZslVaJ1ZShLUpvZfvtD\nyy5Ba8lQlqRhrOcoedy4fyipEtWDs68laRh65ZVXuP6GnXu177nH/y6hGtWLI2VJGob6CuTX/9Wv\nSqhEA4mIzSPi8oi4NyIWRcTf1OrrSFmShpkF1+7SZ/uECVs2uRIN0teA/8nMoyNifWCjWh0NZUka\ndl7u1TJj+v0l1KGBRMRmwBuBDwJk5sv09R+w4OVrSRpGet8kZKKBXK7xEbGw6nV8j+3bAU8A/xUR\nv42I/4yIjWsdzFCWpGHioYeu79U2Y/qvS6hEVZ7MzGlVr7k9to8C9gbOzsy9gBeA2bUOZihL0jCx\n5P7uX3faeacLS6pEQ7AUWJqZNxfrl1MJ6T4ZypI0DPS+bA2TJ7+hhEo0FJn5KPBwROxUNM0A7qnV\n34lektTiHn54Sa82P0ceVj4OfLeYef0HoOYdXgxlSWpxv1/c/baZe+7hwyaGk8y8HZg2mL5evpak\nFtbXZetx43wsY7sylCWpRS24dnqvNi9btzdDWZJa1kPd1raadG5JdahZDGVJakF9XbbeZZc3l1CJ\nmslQlqQW88tfHtOrzcvWncFQlqQWs/Llhd3W3/TG+0qqRM1mKEtSC+nrsvWoUX57tVMYypLUIu7/\nw+W92rxs3VkMZUlqEQ8++Llu6xus/46SKlFZDGVJagF9XbY+8MAzSqhEZTKUJalky5ff2avNy9ad\nyVCWpJLds+id3dZHjjigpEpUNkNZkkr0+8U/6tV20EEXlFCJWoGhLEklevjhE7ut//W0+SVVolZg\nKEtSSfqa3LXpptuXUIlahaEsSSV45ZVXerU5uUuGsiSV4Pobdu7RslMpdai1eO82SWqy5ct/26tt\nxvSrSqhET698lEsfOK3sMtZwpCxJTXbPoqO7re+5xy0lVaJW05RQjojREXFLRPwuIu6OiC8U7WMj\nYn5ELC5+jqna56SIWBIR90XEoVXt+0TEncW2syIiivYNIuLSov3miJhatc+s4s9YHBGzmvGeJakv\ni5d8p1fbuHHjSqhErahZI+WVwPTM3APYEzgsIvYHZgMLMnNHYEGxTkTsCswEdgMOA74ZESOLY50N\nfBjYsXgdVrQfBzydmTsAZwCnFccaC5wM7AfsC5xcHf6S1Ex//OPJ3dad3KVqTQnlrPhTsbpe8Urg\nSGBe0T4P6LqtzZHAJZm5MjMfAJYA+0bEJGDTzLwpMxO4oMc+Xce6HJhRjKIPBeZn5orMfBqYz1+C\nXJKapq+vQEnVmvaZckSMjIjbgcephOTNwMTMXF50eRSYWCxPBh6u2n1p0Ta5WO7Z3m2fzFwFPAuM\n6+dYktQ0Tz/9ZK82R8nqqWmhnJmrM3NPYAqVUe/uPbYnldFzKSLi+IhYGBELn3jiibLKkNSmfvPb\n/Xq0bFhKHWptTZ99nZnPAD+ncgn5seKSNMXPx4tuy4Ctq3abUrQtK5Z7tnfbJyJGAZsBT/VzrJ51\nzc3MaZk5bcKECevyFiWpmxtu+HivthnT7yqhErW6Zs2+nhARmxfLGwJvAe4FrgS6ZkPPAn5YLF8J\nzCxmVG9HZULXLcWl7uciYv/i8+Jje+zTdayjgWuL0fc1wCERMaaY4HVI0SZJDffII8t4+ZXu30Ge\nts9vSqpGra5ZNw+ZBMwrZlCPAC7LzB9HxI3AZRFxHPAQ8B6AzLw7Ii4D7gFWASdk5uriWB8Dvk3l\n2s/VxQvgPODCiFgCrKAye5vMXBERpwC3Fv2+mJkrGvpuJamw6N439mrbbLPNSqhEw0FTQjkz7wD2\n6qP9KWBGjX1OBU7to30hsHsf7S8B765xrPOB84dWtSStm5/Ofy0jRkDlbgoVTu7qPBHxIPA8sBpY\nlZnTavX1jl6S1ABz5swxkFXt4Mzcs79ABkNZkupuzpw5AGTxfZJMmLrt98orSMOGD6SQpDrqCmSA\nX/3yfWy++SO85jX78eYZe5dXlMqWwM8iYjVwbmbOrdXRUJakOrnhhht6tIzkmWe25sQTjy+lHjXF\n+IhYWLU+t4/QPTAzl0XEFsD8iLg3M6/v62CGsiTVwbPPPsuCBQt6tVePnNWWnhzoc+LMXFb8fDwi\nrqDyHIY+Q9nPlCWpDs4444xebQayImLjiNika5nKvTJq3jnGkbIkraO+wtdAVmEicEXxlOFRwEWZ\n+T+1OhvKkrQODGT1JzP/AOwx2P6GsiSthVrB+/nPf765hait9BvKEfH/DeYgxR2zJKkj1Arkf/3X\nf2XkyJHNLUZtZaCR8gcGcYzEW1hK6hC1Avld73qXgax11m8oZ+bBzSpEklpdrUB++9vfzh57DPpj\nQ6mmIX2mHBHjgMOBLTPzKxGxFTAiM5c2pDpJahG1AtlJXaqnQYdyRLwJ+D6wEDgA+AqV5xx/Gnh7\nQ6qTpJKde+65LF++vFf7VlttxfHHe6cu1ddQRspnAsdk5oKIeLpou5nKnUkkqe3UGgV/5jOfYeON\nN25uMeoIQwnlqZnZdQ+54tknvDzEY0jSsODlapVhKLfZvCciDu3R9mbgzjrWI0mlM5BVlqGMcj8F\n/DgifgJsGBHnUvks+ciGVCZJTfbiiy9y2mmn9bnNQFYzDDqUM/OmiNgD+Hsq30t+GNjXmdeS2kVf\ngbzzzjszc+bMEqpRJxrS58HF8yC/Aoyn8riqHGgfSWp1jz76KOecc06v9tmzZzN69OgSKlKnGvRn\nyhGxeURcCLwIPAq8GBEXRsTYhlUnSU3QVyDPmTPHQFbTDWWk/F/AamAv4CFgW+ALVC5lv7P+pUlS\nY9X6DvKnP/3pEqpRGWLkREaP+eQ6HOEndasFhhbK06ncyevFYn1RRHwQeKSuFUlSEzjDWq1oKF+J\nuheY2qNtG+C+ulUjSU1gIKtVDeXRjQuAnxafKz8MbA28H7iwceVJUn0ZyGplQ3104xLgb4oXwP1V\ny5LUsp555hnOPPPMPrcZyGoVPrpRUttbvHgx3/3ud/vcZiCrlazVfasjIoDoWs/MV+tWkSTVUa3Q\nPeqoo3j961/f3GKkAQzl0Y2Tga8DbwQ277F5ZD2LkqR68PNjDTdDGSmfA/wZmAH8gko4zwGuqn9Z\nkrT2lp5yA//50oLK33DRfZuBrFY2lFB+A7BNZr4QEZmZv4uI44BfA99qTHmSNDRLZ99QWVivaEjW\nBLOBrFY3lFBeDawqlp+JiAnAc8DkulclSUO0JowL73vlAC5a/1cAvP0db2efffYpoyxpSIYSyjcD\nhwNXANcAl1K5D/atDahLkgatZyADbMRoPvTyDKZ8+W9LqEhaO0MJ5Q/wlzuAnUjl+cpjgM3qXZQk\nDcbSO+6Fi57oc9v6n9yJLbbYoskVSetmKM9TfqZq+UXg3yNiNPAC8KEG1CZJNfU1Ou7i6FjD1Vp9\nT7lK1RQKSWq8pXNugJdqbNwFpswykNV6ImIksBBYlplH1Oq3rqEMlWCWpIbKTJad9Mua2x0dq8V9\nAlgEbNpfpwFDOSKm97N5/SEWJUlD1t+lajCQ1doiYgrwNuBUoN+HNw9mpHzeANv/OMi6JGlIHl36\nKKu+vrjmdsNYw8SZwGeBTQbqOGAoZ+Z29ahIkgZroJEx79uSKa/fsTnFSP0bHxELq9bnZubcrpWI\nOAJ4PDNvi4iDBjpYPT5TlqS6WHrtHfDTZ/vt4+hYLebJzJzWz/YDgHdExOHAaGDTiPhOZr6/r86G\nsqSWMNDoePJ/HEjlAXXS8JGZJwEnARQj5U/XCmQwlCWVbOncG+APNTZuCVNOdGSszmEoSyrF0rNv\ngIdqb/cytdpNZl4HXNdfH0NZUtP1e6l6HEz5jIGszmQoS2oav28s9c9QltRwhrE0OIaypIbqL5C3\n+tIBjBgxouZ2qdMYypIa4vav/ZSxyzYgRozo86k1jo6l3gxlSXV3+jFH8J6pn4Xo/Rg5w1iqzVCW\nVDevvvoqZ7z3Hd3aMpOIYMNP78q48eNKqkwaHgxlSXVx0Ve+xPKFv16zftNjP2HfLd7KK6+8wg5n\nvKXEyqThoykzLCJi64j4eUTcExF3R8QnivaxETE/IhYXP8dU7XNSRCyJiPsi4tCq9n0i4s5i21lR\n3HcvIjaIiEuL9psjYmrVPrOKP2NxRMxqxnuWOsnpxxzRLZAB/vji3Sza/X4DWRqCZk17XAV8KjN3\nBfYHToiIXYHZwILM3BFYUKxTbJsJ7AYcBnwzIkYWxzob+DCwY/E6rGg/Dng6M3cAzgBOK441FjgZ\n2A/YFzi5OvwlrZvTjzmiz/aP/OfFHHbscU2uRhremnL5OjOXA8uL5ecjYhEwGTgSOKjoNo/K7cc+\nV7RfkpkrgQciYgmwb0Q8CGyamTcBRMQFwDuBq4t95hTHuhz4ejGKPhSYn5krin3mUwnyixv3jqX2\nd/qso+Gll/rc9qlLf9zkaqS1s+nzf2T6dSeUXcYaTf+CYHFZeS/gZmBiEdgAjwITi+XJwMNVuy0t\n2iYXyz3bu+2TmauAZ4Fx/RxL0lo6/Zgj+gzk2HRTA1laB02d6BURrwG+D5yYmc9VP4YtMzMispn1\n9KjteOB4gG222aasMqSWVutSNcB7/s/ZbL311k2sRmo/TRspR8R6VAL5u5n5g6L5sYiYVGyfBDxe\ntC8Dqv/vnlK0LSuWe7Z32yciRgGbAU/1c6xuMnNuZk7LzGkTJkxY27cptaVfX/WjfgP5n+ZdbiBL\nddCs2dcBnAcsysyvVm26EuiaDT0L+GFV+8xiRvV2VCZ03VJc6n4uIvYvjnlsj326jnU0cG1mJnAN\ncEhEjCkmeB1StEkawMqVKzn9mCO4cd65fW4/9FOf51OX/pgNRo9ucmVSe2rW5esDgA8Ad0bE7UXb\n/wK+DFwWEcdRebLqewAy8+6IuAy4h8rM7RMyc3Wx38eAbwMbUpngdXXRfh5wYTEpbAWV2dtk5oqI\nOAW4tej3xa5JX5L6dv2VV3Drd8/rt4+fHUv116zZ17+k9932usyosc+pwKl9tC8Edu+j/SXg3TWO\ndT5w/mDrlTrV6R+cCS/+qd8+hrHUON7RSxLQ/yQugBMv+iEjR47st4+kdWMoSx0qM/nqzLcP2O8D\nZ53HFhMnDthP0rozlKUO8/zzzzP3Q+8dsJ+XqaXmM5SlDjHQ5eku/3LxlYwY0fT7CknCUJba3mDC\n+OCPfpK9D5rehGok9cdQltrUYML4b/7+Q7zhHe9sQjWSBsNQltrMN/7xWl56+kf99vHzYqk1GcpS\nm/jGP15btfZAn30MY6m1GcrSMNc9jCtGbfIxVj1/1pp1w1gaHgxlaZjqK4y7jBo1ilFjPskJ5zh5\nSxpODGVpmOkvjLsYxtLwZChLw8Dq1as554RfDNjPMJZaS0SMBq4HNqCSuZdn5sm1+hvKUgv705/+\nxLxP39Jvn1ET4COnGMZSi1oJTM/MP0XEesAvI+LqzLypr86GstSCBhPGBJxwtmEstbLMTKDr0Wvr\nFa+s1d9QllrIYD4vHv9aOOYzhrHUIsZHxMKq9bmZObe6Q0SMBG4DdgC+kZk31zqYoSy1gMGE8VtP\n3J7td57a+GIkDcWTmTmtvw6ZuRrYMyI2B66IiN0z866++hrKUpNlJt/86M8H3X+jreAf/s2RsTTc\nZeYzEfFz4DDAUJbK9I0Tr4WXBt//H766PxtttFHjCpLUcBExAXilCOQNgbcAp9XqbyhLDTSoCVtV\nxr0OZn7SUbHURiYB84rPlUcAl2VmzVvsGcpSA3zj8C/DlGkwIoAYsP8xc/Zk/JZjG1+YpKbKzDuA\nvQbb31CW6mTRv/4bfO97lZU3fb1o7TuQjznl9YyfML45hUkaNgxlaR0t2nmXPloTCMiEqATzZtvD\n+z/rpWlJtRnK0lrqO4wr/vqXn+XW/b4Er7zACRf+XROrkjScGcrSEPUXxl32vfs37NuEWiS1F0NZ\nGoTHli9nxcEDX3re5d5FTahGUrsylKUBDGZkbBhLw9P9k+A9J61DFH6wbqUAle9MSeph0fe/z6Kd\nd+k/kN/2Nna5d5GBLKluHClLVRZ961tw+lf77WMIS2oUQ1licJeoOfxwdvnq6Y0vRlLHMpTV0QYT\nxhv/9Bq22WabJlQjqdMZyuo4i37xC/jIPw7Yb+wvrmPixIlNqEiSKgxldYRBXZ4u+JmxpLIYympr\ngw7jbbdhl2uuaWwxkjQAQ1ltaeHOu7Ahg/jO3/nnscsb3tCEiiRpYIay2soh8w7hwKse5uiBOp71\nNXY55JBmlCRJg2Yoqy1842ff4Jxl5wCw28N/aS+e1QT4WbGk1mcoa1i78Q83cvwNx3drm/ORUVz0\nH6sYAawE9jaMJQ0ThrKGrb+a91c1t73vpFHcOevOJlYjSevOUNaw018YA/z273/LqFH+aksafvyb\nS8PGQGH866N+zSabbNKkaiSp/gxltbyBwvjYKcfymRmfaVI1ktQ4hrJa1kBhvHVszVXHXtWkaiSp\n8QxltZyrfnsVn7vjczW3b8iG3DLrliZWJEnNYSirZbxp3ptYwYp++zijWlI7M5RVuo9f/nGue+G6\nfvsYxpI6gaGs0jzyyCMcOv/QfvsYxpI6iaGspjvqgqNYnIv77WMYS+pEhrKaYqCZ1F0MY0ntJCK2\nBi4AJlK5Hf/czPxarf6GshrKMJbU4VYBn8rM30TEJsBtETE/M+/pq7OhrIbYa95erGLVgP0MY0nt\nLDOXA8uL5ecjYhEwGTCU1QSP3MtfXf0uGDmysh7Rq4tBLKmNjI+IhVXrczNzbl8dI2IqsBdwc62D\nGcqqnzmbVX5O3dowltQpnszMaQN1iojXAN8HTszM52r1M5S17rrCuMuq1TDqLyNlw1hSJ4uI9agE\n8ncz8wf99R3RpILOj4jHI+KuqraxETE/IhYXP8dUbTspIpZExH0RcWhV+z4RcWex7ayIynAsIjaI\niEuL9puLSwRd+8wq/ozFETGrGe+3Y8zZrHcgA3cufYQ7H3yYO4+9w0CW1NGKnDoPWJSZXx2of1NC\nGfg2cFjY/wyDAAANFElEQVSPttnAgszcEVhQrBMRuwIzgd2Kfb4ZEcWwi7OBDwM7Fq+uYx4HPJ2Z\nOwBnAKcVxxoLnAzsB+wLnFwd/lpLNcJ4jf1PgTnPwohm/XpJUss6APgAMD0ibi9eh9fq3JTL15l5\nffXotXAkcFCxPA+4Dvhc0X5JZq4EHoiIJcC+EfEgsGlm3gQQERcA7wSuLvaZUxzrcuDrxb9ODgXm\nZ+aKYp/5VIL84nq/x7a3ejWcMnaATgFznmlKOZI0HGTmL4Hek2xqKPMz5YnFVHGAR6l8sRoqU8Vv\nquq3tGh7pVju2d61z8MAmbkqIp4FxlW397FPNxFxPHA8wDbbbLN276gd/fBL8NvTBu4359nG1yJJ\nba4lJnplZkZEllzDXGAuwLRp00qtpSX0d3m62j/dC+MnNbYWSeoQZYbyYxExKTOXR8Qk4PGifRmw\ndVW/KUXbsmK5Z3v1PksjYhSwGfBU0X5Qj32uq+/baCPnvheWXzVwv5gEJ9/b+HokqcF2W/kyCx/4\n41rvP+jr0oNUZihfCcwCvlz8/GFV+0UR8VVgKyoTum7JzNUR8VxE7E/li9fHAv+3x7FuBI4Gri1G\n39cAX6qa3HUIcFLj39owM9hR8cnP9Pn9Y0lSfTQllCPiYioj1vERsZTKjOgvA5dFxHHAQ8B7ADLz\n7oi4jMotyFYBJ2Tm6uJQH6Myk3tDKhO8ri7azwMuLCaFraAye5vMXBERpwC3Fv2+2DXpSww+jP28\nWJKaolmzr99bY9OMGv1PBU7to30hsHsf7S8B765xrPOB8wddbLt7/nk4fcrA/WZeBTsf0Ph6JElr\ntMRELzXBoEbFo2HOYw0vRZLUN0O53Q0mjDfaGj5718D9JEkNZSi3q8GE8f4nw2GfbHwtkqRBMZTb\nzILb7uTgHx5IRK2J0tvA//4tjPI/vSS1Gv9mbiNTZ/+ET8YFTF+/j0COLeHk+0qpS5I0OIZyG/js\nf83nsvteBuDH+QY+zv+QxT3JIvArTZI0TBjKw9zU2T/ptv57duBvV57Cu7iJT335opKqkiStDUN5\nGOsZyF2u+l8fZNNN/7nJ1UiS1pWhPAx98eLrOP93L/S57cEvv63J1UiS6sVQHkZmz7uOSxb1HcZg\nIEvScGcoDwMvvvgiu3zh2prbj9p5A776wTc3sSJJUiMYyi2u1ufGXRwdS1L7MJRb0BW/Wsi//Kj/\ne1Dff+phjBw5skkVSZKawVBuMQONjG/55F+zxRZbNKkaSVIzGcot4uWXX+Z1/za/5vaffGgndtth\nhyZWJElqNkO5BWw3+ydkjW17bjma/z6xz8dOS5LajKFcslqXq3faPLhm9uFNrkaSVCZDuSRfvOTn\nnH/7n/vc5oxqSepMhnIJ+pvMZSBLUucylJusViAv+OjuvHbbbZtcjSSplRjKTeLoWJI0kBFlF9AJ\nagXyme+YYiBLUhuLiPMj4vGIuGsw/R0pN1itQF7y74cyapSnX5La3LeBrwMXDKazI+UG6iuQN6Ry\nudpAlqT2l5nXAysG299kaJDF99/fq+1zB4/no4fuV0I1kqThwFBukLd8695u69tshIEsSe1nfEQs\nrFqfm5lz1/ZghnIDPPf8n3q1Xf9vTuiSpDb0ZGZOq9fB/Ey5AV5/6i+6rTvDWpI0GIayJEkNEhEX\nAzcCO0XE0og4rr/+Xr5usP945+vKLkGSVMOduT1TXzpzHY5wRL9bM/O9QzmaI+U6u+X+x7utv3f/\nHUuqRJI03BjKdfb925aWXYIkaZgylOts6dMvlV2CJGmYMpTrbMsxG65Znjxm/RIrkSQNN4Zynd2w\n+Mk1y39emSVWIkkabgzlOnt19V+CeOxGTm6XJA2eoVxne287Zs3ysQdsV2IlkqThxlCus2dfWrVm\nefRIT68kafBMjTp76KkX1iw/9vzKEiuRJA03hnKdbTNuozXL+203tsRKJEnDjaFcZy+venXN8pab\njC6xEknScGMo19miR55bs/yrPzxVYiWSpOHGUK6z2W/dBYCN1h/BMdOmlFyNJGk48Yu0dbb7lM0Y\n/5r12WfbMYwY4b95JEmDZ2rU2bd/9QBP/ullfnr3Yzz951fKLkeSNIwYynV2zd2PApDAqtWv9t9Z\nkqQqhnKdrVd1w5ARUWIhkqRhx1CusxtnT2ff7cbwH0ftzni/EiVJGgInetXZ5htvwGUfeUPZZUiS\nhiFHypIktQhDWZKkFmEoS5LUIjomlCPisIi4LyKWRMTssuuRJKmnjgjliBgJfAN4K7Ar8N6I2LXc\nqiRJ6q4jQhnYF1iSmX/IzJeBS4AjS65JkqRuOiWUJwMPV60vLdrWiIjjI2JhRCx84oknmlqcJEnQ\nOaE8oMycm5nTMnPahAkTyi5HktSBOiWUlwFbV61PKdokSWqooUw07pRQvhXYMSK2i4j1gZnAlSXX\nJElqc0OdaNwRoZyZq4B/Aq4BFgGXZebd5VYlSeoAQ5po3DH3vs7Mq4Cryq5DktRR+ppovF+tzh0T\nykNx2223PRkRD63jYcYDT9ajng7jeVt7nru157lbO808b9s24qAvP7rkmodOO2L8OhxidEQsrFqf\nm5lz1/ZghnIfMnOdp19HxMLMnFaPejqJ523tee7Wnudu7bTDecvMwxr8RwxponFHfKYsSVJJhjTR\n2JGyJEkNkpmrIqJrovFI4Pz+Jhobyo2z1p8pdDjP29rz3K09z93a8bwNwlAmGkdmNrgcSZI0GH6m\nLElSizCU68znNvcWEQ9GxJ0RcXvXVwciYmxEzI+IxcXPMVX9TyrO330RcWhV+z7FcZZExFkREWW8\nn0aKiPMj4vGIuKuqrW7nKiI2iIhLi/abI2JqM99fI9U4d3MiYlnxu3d7RBxetc1zB0TE1hHx84i4\nJyLujohPFO3+3pUhM33V6UXlQ/z7ge2B9YHfAbuWXVfZL+BBYHyPtv8fmF0szwZOK5Z3Lc7bBsB2\nxfkcWWy7BdgfCOBq4K1lv7cGnKs3AnsDdzXiXAEfA84plmcCl5b9nht87uYAn+6jr+fuL+diErB3\nsbwJ8Pvi/Ph7V8LLkXJ9+dzmwTsSmFcszwPeWdV+SWauzMwHgCXAvhExCdg0M2/Kyv/ZF1Tt0zYy\n83pgRY/mep6r6mNdDsxolysONc5dLZ67QmYuz8zfFMvPU7kV8WT8vSuFoVxfAz63uUMl8LOIuC0i\nji/aJmbm8mL5UWBisVzrHE4ulnu2d4J6nqs1+2TlnvDPAuMaU3bL+HhE3FFc3u66BOu560NxWXkv\n4Gb8vSuFoaxmODAz96TylJQTIuKN1RuLf1X7NYBB8FwN2dlUPk7aE1gOnF5uOa0rIl4DfB84MTOf\nq97m713zGMr15XOb+5CZy4qfjwNXULnM/1hxuYvi5+NF91rncFmx3LO9E9TzXK3ZJyJGAZsBTzWs\n8pJl5mOZuTozXwW+ReV3Dzx33UTEelQC+buZ+YOi2d+7EhjK9eVzm3uIiI0jYpOuZeAQ4C4q52VW\n0W0W8MNi+UpgZjFbcztgR+CW4jLacxGxf/FZ1LFV+7S7ep6r6mMdDVxbjILaUleoFN5F5XcPPHdr\nFO/zPGBRZn61apO/d2Uoe6ZZu72Aw6nMXrwf+HzZ9ZT9onLp8HfF6+6uc0Ll86QFwGLgZ8DYqn0+\nX5y/+6iaYQ1Mo/KX6v3A1yluftNOL+BiKpdZX6Hymdxx9TxXwGjge1Qm59wCbF/2e27wubsQuBO4\ng0owTPLc9TpvB1K5NH0HcHvxOtzfu3Je3tFLkqQW4eVrSZJahKEsSVKLMJQlSWoRhrIkSS3CUJYk\nqUUYylKLK57cc9Ba7PftiPj3BpQkqUFGlV2ApP5l5m5l1yCpORwpS5LUIgxlqcVFxIMR8eaImBMR\nl0XEBRHxfHFZe1pVv70i4jfFtkup3EWp+jhHRMTtEfFMRPw6Il5ftL82IlZExN7F+lYR8cTaXDKX\ntG4MZWl4eQeV53RvTuW2kV8HKO61/t9Ubis5lsotDf+ua6eI2As4H/gIldsnngtcGREbZOb9wOeA\n70TERsB/AfMy87omvSdJBUNZGl5+mZlXZeZqKgG8R9G+P7AecGZmvpKZl1N5QEqX44FzM/PmrDw1\naR6wstiPzPwWlfsS3wxMonJvY0lNZihLw8ujVct/BkYXj8LbCliW3W9m/1DV8rbAp4pL189ExDNU\nHqW3VVWfbwG7A/83M1c2pnxJ/TGUpfawHJhcPDKvyzZVyw8Dp2bm5lWvjTLzYljzgPszqTzCb05E\njG1a5ZLWMJSl9nAjsAr454hYLyKOAvat2v4t4B8jYr+o2Dgi3tb1rGvga8DCzPwQ8BPgnKZWLwkw\nlKW2kJkvA0cBHwRWAMcAP6javhD4MJWJYU9T+fz4gwARcSRwGPDRovsngb0j4u+bU72kLj5PWZKk\nFuFIWZKkFmEoS5LUIgxlSZJahKEsSVKLMJQlSWoRhrIkSS3CUJYkqUUYypIktQhDWZKkFvH/ALl+\nlG6HcnaMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05e9cfa048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,\n",
    "            c=np.sort(label_ord[sorted_idx]), cmap = plt.get_cmap('tab10'))\n",
    "plt.colorbar()\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Label', fontsize=12)\n",
    "\n",
    "plt.savefig('cpu_act.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f05e689c2e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHmCAYAAABanLmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCGgAABgQ0AAAMCCgAQBgQEADAMDA/wfhKwP0I3MREQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05e6923588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coeff(n, metric, lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return [1]\n",
    "    elif metric is 'ccr1':\n",
    "        return [1, 1, 1]\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.arange(1,n)/(n-1)\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros(n-1)\n",
    "        coeff[0] = 2*n-3\n",
    "        for k in range(1, n-1):\n",
    "            coeff[k] = coeff[k-1] + 2*n - (2*(k+1)+1)\n",
    "        coeff = coeff /((n-1)**2)\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "    coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    coeff = coeff * lmbda\n",
    "    coeff[n-2] = 1\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type = 'cal_housing'\n",
    "num_samples = 10000\n",
    "num_classes = 9\n",
    "nclasses = num_classes\n",
    "dim = 2\n",
    "\n",
    "sigma_noise = 0.01\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=10 #Number of the first column in the excel file for writing the results.\n",
    "lr=.5 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "batch_size = 256\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "rand_label = False\n",
    "\n",
    "metric = 'ccr'\n",
    "coeff_lmbda =  1\n",
    "multi_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "KL = False #KL divergence for porbability measure\n",
    "\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any\n",
    "\n",
    "algo = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04774989 -0.34285623  0.08390143 -0.86602762 -0.83336499 -0.92026252\n",
      " -0.83603365 -0.53507248]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "(20640, 8)\n",
      "[6 4 1 ..., 3 5 2]\n",
      "{'train': 16512, 'val': 4128}\n",
      "OR\n",
      "Number of training images 5\n",
      "Number of validation images 5\n",
      "{'train': 16512, 'val': 4128}\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inputs, classes = next(iter(dset_loaders['train']))\\nprint(inputs.shape)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = 5\n",
    "random_seed = 1\n",
    "\n",
    "if data_type == 'circular':\n",
    "    fvec, label = generateCircularData(num_samples = num_samples, \n",
    "                                       num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'linear':\n",
    "    fvec, label = generateLinearData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'spiral':\n",
    "    fvec, label = generateSpiralData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "else:\n",
    "    num_classes = num_bins\n",
    "    nclasses = num_classes\n",
    "    \n",
    "    feat=train_df.values[:,:-2]\n",
    "    #Normalize the features\n",
    "\n",
    "    feat_max = np.amax(feat,axis=0)\n",
    "    feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "    feat=feat*2-1\n",
    "\n",
    "    '''feat_mean = np.mean(feat,axis=0)\n",
    "    feat_std = np.std(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_mean)/feat_std\n",
    "    '''\n",
    "    label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "    rand_idx = np.random.permutation(len(label_ord))\n",
    "    feat = feat[rand_idx, :]\n",
    "    label = label_ord[rand_idx]\n",
    "\n",
    "\n",
    "    print(np.mean(feat,axis=0))\n",
    "    print(np.min(feat,axis=0))\n",
    "    print(feat.shape)\n",
    "    print(label)\n",
    "\n",
    "    fvec=feat.copy()\n",
    "    dim = feat.shape[1]\n",
    "    \n",
    "    if not CV == 0: \n",
    "        dset_train= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "        dset_val= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "\n",
    "        '''Define dataset loaders''''''\n",
    "        dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                            num_workers=12)}\n",
    "\n",
    "\n",
    "        dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        print(dset_sizes)\n",
    "\n",
    "        if use_gpu:\n",
    "            print('GPU is available')\n",
    "        else:\n",
    "            print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "        inputs, classes = next(iter(dset_loaders['train']))\n",
    "        print(inputs.shape)'''\n",
    "        '''dset_train = datasets.ImageFolder(data_dir+'/train_val', data_transforms['train'])\n",
    "        dset_val = datasets.ImageFolder(data_dir+'/train_val', data_transforms['val'])'''\n",
    "\n",
    "        num_train = len(dset_train)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        splits = (num_train*np.linspace(0,1,CV+1)).astype(int)\n",
    "\n",
    "        val_idx = [indices[splits[k]:splits[k+1]] for k in range(CV)]\n",
    "        train_idx=[np.setdiff1d(indices,val_idx[k]) for k in range(CV)]\n",
    "        '''Sampler functions for validation and training'''\n",
    "        sampler_train = [torch.utils.data.sampler.SubsetRandomSampler(train_idx[k]) for k in range(CV)]\n",
    "        sampler_val = [torch.utils.data.sampler.SubsetRandomSampler(val_idx[k]) for k in range(CV)]\n",
    "\n",
    "        '''Define dataset loaders'''\n",
    "        dset_loaders_arr = [{'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train[k],\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val[k],\n",
    "                                                            num_workers=12)} for k in range(CV)]\n",
    "        dset_sizes={'train':int(len(dset_train)*(1-1/CV)),'val':int(len(dset_train)*(1/CV))}\n",
    "\n",
    "        print(dset_sizes)\n",
    "        print('OR')\n",
    "        print('Number of training images '+str(len(val_idx)))\n",
    "        print('Number of validation images '+str(len(train_idx)))\n",
    "    \n",
    "\n",
    "\n",
    "'''rand_idx = np.random.permutation(len(label))\n",
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "''''''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}\n",
    "\n",
    "\n",
    "dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "'''\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(dset_sizes)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "'''inputs, classes = next(iter(dset_loaders['train']))\n",
    "print(inputs.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(feat.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('runs_regression/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Feature Length: '+str(dim)+'\\n')\n",
    "    f.write('Number of classes: '+str(num_classes)+'\\n')\n",
    "    f.write('Data type: '+data_type+'\\n')\n",
    "    f.write('Random Noise: '+str(sigma_noise)+'\\n')\n",
    "    \n",
    "    f.write('Hidden sizes: '+ str(hidden_sizes)+'\\n')\n",
    "    f.write('Dropouts: '+str(dropouts)+'\\n')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Number of samples: '+str(num_samples)+'\\n')\n",
    "    \n",
    "    f.write('Optimizer: ' + optimizer + '\\n')\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='logs_regression.xlsx',iter_loc=10):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    \n",
    "    print(logname)\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    specs=(datetime.now().strftime('%B%d  %H:%M:%S'),data_type,str(hidden_sizes),str(dim),str(num_classes),\n",
    "           crt, str(lr), str(m_coeff), str(algo))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)\n",
    "#writeLog_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc0): Linear (2 -> 50)\n",
      "  (relu0): ReLU ()\n",
      "  (drop0): Dropout (p = 0)\n",
      "  (fc1): Linear (50 -> 50)\n",
      "  (relu1): ReLU ()\n",
      "  (drop1): Dropout (p = 0)\n",
      "  (fc2): Linear (50 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropouts, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.numHidden=len(hidden_sizes)\n",
    "        setattr(self, 'fc0', nn.Linear(input_size, hidden_sizes[0]))\n",
    "        setattr(self, 'relu0', nn.ReLU())\n",
    "        setattr(self, 'drop0', nn.Dropout(p=dropouts[0]))\n",
    "        for k in range(len(hidden_sizes)-1):\n",
    "            setattr(self, 'fc'+str(k+1), nn.Linear(hidden_sizes[k], hidden_sizes[k+1]))\n",
    "            setattr(self, 'relu'+str(k+1), nn.ReLU())\n",
    "            setattr(self, 'drop'+str(k+1), nn.Dropout(p=dropouts[k+1]))\n",
    "        setattr(self, 'fc'+str(len(hidden_sizes)), nn.Linear(hidden_sizes[-1], num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.fc0(x)\n",
    "        out = self.relu0(out)\n",
    "        out = self.drop0(out)\n",
    "        for k in range(self.numHidden-1):\n",
    "            fc = getattr(self,'fc'+str(k+1))\n",
    "            relu = getattr(self,'relu'+str(k+1))\n",
    "            drop = getattr(self,'drop'+str(k+1))\n",
    "            out = fc(out)\n",
    "            out = relu(out)\n",
    "            out = drop(out)\n",
    "        fc = getattr(self,'fc'+str(self.numHidden))\n",
    "        out = fc(out)\n",
    "        return out\n",
    "    \n",
    "model=Net(2, [50, 50], [0, 0], 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    nclasses=num_classes,\n",
    "                    hidden_sizes = hidden_sizes,\n",
    "                    dropouts = dropouts):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    model_ft = Net(dim, hidden_sizes , dropouts, num_classes)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "a_vec = Variable(torch.randn(10, 1), requires_grad=True)\n",
    "params = optimizer_ft.param_groups\n",
    "params[0]['params'].append(a_vec)\n",
    "optimizer_ft.param_groups = params\n",
    "print(optimizer_ft.param_groups)\n",
    "#optimizer_ft.add_param_group({'params': a_vec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_epochs(result_log, logname):\n",
    "    print(len(result_log))\n",
    "\n",
    "    wb_tr = openpyxl.Workbook()\n",
    "    ws_tr = wb_tr.active\n",
    "    wb_val = openpyxl.Workbook()\n",
    "    ws_val = wb_val.active\n",
    "    print(logname)\n",
    "\n",
    "    label_arr_tr = np.zeros((100000,1))\n",
    "    probs_arr_tr = np.zeros((100000, num_classes))\n",
    "    label_arr_val = np.zeros((100000,1))\n",
    "    probs_arr_val = np.zeros((100000, num_classes))\n",
    "\n",
    "    prev_epoch = 0\n",
    "    \n",
    "    count_tr = count_val = 0\n",
    "    for result in result_log:\n",
    "        epoch = result[1]\n",
    "        if not epoch == prev_epoch:\n",
    "            label_arr_tr = label_arr_tr[:count_tr]\n",
    "            probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "            label_arr_val = label_arr_val[:count_val]\n",
    "            probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            ws_tr.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "            ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "                ws_tr.append(probs)\n",
    "            #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "            ws_val.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "            ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_val[1:,:].T.tolist():\n",
    "                ws_val.append(probs)\n",
    "    \n",
    "\n",
    "            label_arr_tr = np.zeros((100000,1))\n",
    "            probs_arr_tr = np.zeros((100000, num_classes))\n",
    "            label_arr_val = np.zeros((100000,1))\n",
    "            probs_arr_val = np.zeros((100000, num_classes)) \n",
    "            count_tr = count_val = 0\n",
    "            prev_epoch = epoch\n",
    "\n",
    "        label = np.asarray(result[2]).reshape(-1,1)\n",
    "        scores = np.asarray(result[3])\n",
    "        exp_scores = np.exp(scores - np.max(scores,axis=1).reshape(-1, 1)*np.ones(num_classes))\n",
    "        probs = np.round(exp_scores/(np.sum(exp_scores,axis=1).reshape(-1, 1)*np.ones(num_classes)), decimals=2)\n",
    "        if result[0] == 'train':\n",
    "            label_arr_tr[count_tr:count_tr + len(label)]  = label\n",
    "            probs_arr_tr[count_tr:count_tr + len(label), :] = probs\n",
    "            count_tr += len(label)\n",
    "        elif result[0] == 'val':\n",
    "            label_arr_val[count_val:count_val + len(label)]  = label\n",
    "            probs_arr_val[count_val:count_val + len(label), :] = probs\n",
    "            count_val += len(label)\n",
    "\n",
    "\n",
    "    \n",
    "    label_arr_tr = label_arr_tr[:count_tr]\n",
    "    probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "    label_arr_val = label_arr_val[:count_val]\n",
    "    probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            \n",
    "    ws_tr.append(['Epoch ' + str(epoch)])\n",
    "    ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "    ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "        ws_tr.append(probs)\n",
    "    #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "    ws_val.append(['Epoch ' + str(epoch)])\n",
    "    ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "    ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_val[1:,:].T.tolist():\n",
    "        ws_val.append(probs)\n",
    "    wb_val.save('./runs_regression/'+logname + '/val.xlsx')\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, num_classes))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, num_classes))\n",
    "    prev_epoch = epoch\n",
    "    print('Finito')\n",
    "    \n",
    "    del label_arr_tr, probs_arr_tr, label_arr_val, probs_arr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "    \n",
    "def run_network():\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "    \n",
    "    \n",
    "    '''Name of the trial'''\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname='Ordinal_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('runs_regression/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    best_model, last_model, result_log = ft.train_model(model_ft,optimizer_ft, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=100,batch_size=batch_size,num_log=250,\n",
    "                            lr_decay_epoch=lr_decay_epoch,init_lr=lr,regression=False,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss,numOut=num_classes,\n",
    "                            logname='logs_regression.xlsx',\n",
    "                            multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL, algo = algo)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'./saved_models/ord/'+logname+'_best')\n",
    "    torch.save(last_model,'./saved_models/ord/'+logname+'_last')\n",
    "    \n",
    "    '''print('Writing results')\n",
    "    write_epochs(result_log, logname)\n",
    "    print('Wrote results')'''\n",
    "    '''Free up the memory'''\n",
    "    del model_ft, result_log\n",
    "    \n",
    "    writer.close\n",
    "    del writer\n",
    "    return last_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "end_to_end = True\n",
    "run_network()'''\n",
    "print(fvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=1 #Initial learning rate\n",
    "momentum=0.5\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=15 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]\n",
    "dropouts = [0, 0, 0, 0, 0, .5, .5, .5, 0, 0, 0]\n",
    "\n",
    "'''hidden_size = [64, 64, 128, 64, 32]\n",
    "dropouts = [0, 0, 0, 0, 0]'''\n",
    "\n",
    "single_loss=0.\n",
    "multi_loss =1.\n",
    "\n",
    "metric = 'mae'\n",
    "algo = 'cheng'\n",
    "for dset_loaders in dset_loaders_arr:\n",
    "    run_network()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numOut = 3\n",
    "numIns = 5\n",
    "\n",
    "log_j_fact = np.log(np.asarray([math.factorial(j) for j in range(numOut)]))\n",
    "ones_vec = Variable(torch.ones(numOut).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "j_vec = Variable(torch.range(0, numOut-1).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "log_j_fact = Variable(torch.from_numpy(log_j_fact).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "\n",
    "\n",
    "preds = Variable(torch.randn(numIns,1).cuda())\n",
    "softplus_step = torch.nn.Softplus()\n",
    "preds = softplus_step(preds)\n",
    "outputs = torch.mm(preds, ones_vec)\n",
    "outputs = j_vec * torch.log(outputs) - outputs - log_j_fact\n",
    "softmax_step = torch.nn.Softmax(dim=1)\n",
    "outputs_softmax = softmax_step(outputs)\n",
    "print(outputs_softmax.data.cpu().numpy())\n",
    "\n",
    "f = preds.data.cpu().numpy()\n",
    "pos_f = np.zeros((numIns,numOut))\n",
    "\n",
    "log_j = np.asarray([(np.log(math.factorial(k))) for k in range(numOut)]).reshape(numOut,1)\n",
    "for k in range(numOut):\n",
    "    print((k*np.log(f) -f - np.log(math.factorial(k))).shape)\n",
    "    pos_f[:, k] = (k*np.log(f) -f - np.log(math.factorial(k))).reshape(numIns)\n",
    "    \n",
    "soft_pos = np.exp(pos_f)\n",
    "soft_pos = soft_pos/(np.sum(soft_pos, axis=1).reshape(-1,1)*np.ones((1, numOut)))\n",
    "print(soft_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = (np.random.randint(0,5, size = (5,10))>0).astype(np.int)\n",
    "print(preds)\n",
    "print(np.sum(np.cumprod(preds,axis = 1), axis=1)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 40s\n",
      "Best val RMSE: 2.693527\n",
      "logs_regression.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 28s\n",
      "Best val RMSE: 2.592149\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 26s\n",
      "Best val RMSE: 2.809478\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 26s\n",
      "Best val RMSE: 2.890106\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 42s\n",
      "Best val RMSE: 2.563912\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 1.816497\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 6s\n",
      "Best val RMSE: 1.811088\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 3s\n",
      "Best val RMSE: 1.830909\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 4s\n",
      "Best val RMSE: 1.826869\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 3m 2s\n",
      "Best val RMSE: 1.785561\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.461638\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.436815\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.471878\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.476561\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 39s\n",
      "Best val RMSE: 1.448569\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.451076\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 37s\n",
      "Best val RMSE: 1.424794\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 36s\n",
      "Best val RMSE: 1.467757\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.465032\n",
      "logs_regression.xlsx\n",
      "Multi_coef is [ 0.20987654  0.39506173  0.55555556  0.69135802  0.80246914  0.88888889\n",
      "  0.95061728  0.98765432  1.          0.98765432  0.95061728  0.88888889\n",
      "  0.80246914  0.69135802  0.55555556  0.39506173  0.20987654]\n",
      "LR is set to 0.01\n",
      "LR is set to 0.001\n",
      "LR is set to 0.00010000000000000002\n",
      "Training complete in 2m 38s\n",
      "Best val RMSE: 1.463046\n"
     ]
    }
   ],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=40 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = [0, 0, .5, .5, .5, .5, .5, .5, .5, 0, 0]#.5, .5, .5]\n",
    "\n",
    "for lr_now in [0.01]:# [1, 0.1, 0.01]:\n",
    "    lr = lr_now\n",
    "    for kk in range(1):\n",
    "        \n",
    "        algo = 'None'\n",
    "        single_loss=1.\n",
    "        multi_loss =0.\n",
    "        KL = True\n",
    "        metric = 'mse'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        single_loss=0.\n",
    "        multi_loss =1.\n",
    "        metric = 'mse'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'learn_a_mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'fix_a_mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "            \n",
    "        '''algo = 'None'\n",
    "        single_loss=1.\n",
    "        multi_loss =0.\n",
    "        KL = True\n",
    "        metric = 'ccr'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'ccr1'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        single_loss=0.\n",
    "        multi_loss =1.\n",
    "        metric = 'ccr'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'ccr1'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        metric = 'mae'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'learn_a'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'fix_a'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'cheng'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'poisson'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()\n",
    "\n",
    "        algo = 'binomial'\n",
    "        for dset_loaders in dset_loaders_arr:\n",
    "            run_network()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='adam' #Optimizer function\n",
    "lr=0.05 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "\n",
    "\n",
    "hidden_sizes = [16, 16, 32, 32, 16, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = []#.5, .5, .5]\n",
    "single_loss=1.0\n",
    "multi_loss =0.0\n",
    "\n",
    "KL = True\n",
    "metric = None\n",
    "\n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'ccr1', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "        \n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'mae', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "    \n",
    "'''KL = True\n",
    "metric = 'ccr'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'ccr1'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mae'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mse'\n",
    "for k in range(10):\n",
    "    run_network()'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader again, this time without shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_shape = 'Spiral'\n",
    "data_date = '18_01_31'\n",
    "data_dir = './saved_models_github/' + data_shape + '/' + data_date\n",
    "\n",
    "run_dirs = sorted(os.listdir(data_dir))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:110]\n",
    "mae_dirs = last_dirs[110:]\n",
    "all_dirs = [ccr1_dirs, mae_dirs]\n",
    "\n",
    "\n",
    "'''run_dirs = sorted(os.listdir('./saved_models/test'))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:100]\n",
    "mae_dirs = last_dirs[100:]\n",
    "\n",
    "pure_ccr1 = ['Ordinal_January24  14:10:01_last',\n",
    "             'Ordinal_January24  14:11:08_last',\n",
    "             'Ordinal_January24  14:12:14_last',\n",
    "             'Ordinal_January24  14:13:21_last',\n",
    "             'Ordinal_January24  14:14:27_last',\n",
    "             'Ordinal_January24  14:15:34_last',\n",
    "             'Ordinal_January24  14:16:40_last',\n",
    "             'Ordinal_January24  14:17:47_last',\n",
    "             'Ordinal_January24  14:18:54_last',\n",
    "             'Ordinal_January24  14:20:00_last',]\n",
    "\n",
    "pure_mae = ['Ordinal_January24  14:21:07_last',\n",
    "             'Ordinal_January24  14:22:13_last',\n",
    "             'Ordinal_January24  14:23:19_last',\n",
    "             'Ordinal_January24  14:24:26_last',\n",
    "             'Ordinal_January24  14:25:32_last',\n",
    "             'Ordinal_January24  14:26:38_last',\n",
    "             'Ordinal_January24  14:27:45_last',\n",
    "             'Ordinal_January24  14:28:52_last',\n",
    "             'Ordinal_January24  14:29:58_last',\n",
    "             'Ordinal_January24  14:31:05_last',]'''\n",
    "                \n",
    "len(mae_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.load('./saved_models/ord/Ordinal_January24  10:24:20_last', map_location={'cuda:0': 'cpu'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model_dir, phase='train'):\n",
    "    if use_gpu:\n",
    "        model = torch.load(model_dir)\n",
    "    else:\n",
    "        model = torch.load(model_dir, map_location={'cuda:0': 'cpu'})\n",
    "    model.train(False)\n",
    "\n",
    "    labels_arr = np.asarray([]);\n",
    "    preds_arr = np.asarray([]);\n",
    "    for data in dset_loaders[phase]:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = np.argmax(model(inputs).cpu().data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.cpu().data.numpy())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            outputs = np.argmax(model(inputs).data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.data.numpy())\n",
    "          \n",
    "        preds_arr = np.append(preds_arr, outputs)\n",
    "    return preds_arr\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:24:20_last')\n",
    "#print(np.min(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(18,15))\n",
    "\n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+1)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR$ loss' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+6)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[50+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$0.5CCR$ loss + $0.5CCR_1$ loss \\n' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+11)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[100+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR_1$ loss ' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "plt.savefig('variance_of_results.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_and_mean(root_dir, sub_dirs, phase='train'):\n",
    "    scores_arr = np.zeros((label_train.shape[0],9))\n",
    "    for sub_dir in sub_dirs:\n",
    "        if use_gpu:\n",
    "            model = torch.load(root_dir + '/' + sub_dir)\n",
    "        else:\n",
    "            model = torch.load(root_dir + '/' + sub_dir, map_location={'cuda:0': 'cpu'})\n",
    "        model.train(False)\n",
    "        #print(model)\n",
    "        score_arr = np.zeros((1,9))\n",
    "        for data in dset_loaders[phase]:\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                outputs = model(inputs).cpu().data.numpy()\n",
    "                #print(outputs.shape)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                outputs = model(inputs).data.numpy()\n",
    "                \n",
    "            score_arr = np.append(score_arr, outputs, axis=0)\n",
    "        scores_arr += score_arr[1:,:]\n",
    "        \n",
    "    return scores_arr\n",
    "#scores_tr = validate_and_mean('./saved_models/test_circular', last_dirs[:10])\n",
    "#pred_tr = np.argmax(scores_tr, axis=1)\n",
    "#print(np.mean(label_train == pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dirs = ['./saved_models/ord/Ordinal_January24  10:16:00_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:20:35_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:24:20_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:28:03_last']\n",
    "\n",
    "'''model_dirs = ['./saved_models/ord/Ordinal_January24  13:09:17_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:18:08_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:27:43_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:43:43_last']'''\n",
    "\n",
    "model_dirs = ['./saved_models/ord/Ordinal_January26  00:22:14_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:19:20_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:09:08_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:17:53_last']\n",
    "preds = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    preds.append(validate(model_dir))\n",
    "    \n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'CCR1'\n",
    "\n",
    "if metric is 'CCR1':\n",
    "    metric_code = 0\n",
    "elif metric is 'MAE':\n",
    "    metric_code = 1\n",
    "else:\n",
    "    print('Wrong metric')\n",
    "    \n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "metrics = np.zeros((11, 4))\n",
    "for k in range(10):\n",
    "    scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][k*10:(k+1)*10])\n",
    "    pred_tr = np.argmax(scores_tr, axis=1)\n",
    "    plt.subplot(4,3,k+2)\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    metrics[k,:] = [ccr,ccr1,mae,rmse]\n",
    "    plt.title('$\\lambda$=' + str(np.round(k*.1, decimals=1)) + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "              ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "              ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "    \n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:20:35_last')\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  13:18:08_last')\n",
    "\n",
    "scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(4,3,12)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "metrics[10,:] = [ccr,ccr1,mae,rmse]\n",
    "plt.title('$\\lambda$=1.0' + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt_title = data_shape + '_Data_CCR_' + metric + '_tradeoff_' + data_date + '.tiff'\n",
    "plt.savefig(plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "\n",
    "lmbdas = [.1*k for k in range(11)]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.plot(lmbdas, metrics[:,0], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR$')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lmbdas, metrics[:,1], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR_1$')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lmbdas, metrics[:,2], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$MAE$')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lmbdas, metrics[:,3], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$RMSE$')\n",
    "\n",
    "plt.savefig('spiral_plots_ccr1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR_1 loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/ord', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$MAE loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n$MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt.savefig('spiral_extreme.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR_1$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$MAE$ loss')\n",
    "\n",
    "plt.savefig('circular_extreme_hist.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.subplot(211)\n",
    "img = mpimg.imread('Circular_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)\n",
    "plt.subplot(212)\n",
    "img = mpimg.imread('Spiral_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
