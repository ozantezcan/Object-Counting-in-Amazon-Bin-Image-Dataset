{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5\n",
    "\n",
    "\n",
    "#from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "dim = 2\n",
    "\n",
    "def generateLinearData(num_samples = 10000, num_classes = num_classes, dim = dim, bound = 5, sigma_noise = .1,rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    label = np.dot((np.random.rand(1,dim)*bound*2-bound).reshape(1,-1),fvec)\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateLinearData(rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateCircularData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    \n",
    "    fvec_l = np.sum(fvec**2, axis = 0).reshape(1,-1)\n",
    "    print(fvec_l.shape)\n",
    "    label = fvec_l\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateCircularData(num_classes =5, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Greys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = 9, dim = 2,\n",
    "                         bound = 1, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "    sample_per_class = int(num_samples/num_classes)\n",
    "    num_samples = sample_per_class*num_classes\n",
    "    fvec = np.zeros((dim, sample_per_class*num_classes))\n",
    "    label = np.zeros((1, sample_per_class*num_classes))\n",
    "    \n",
    "    t = np.linspace(0, 10, sample_per_class)\n",
    "    x = t * np.cos(t)\n",
    "    y = t * np.sin(t)\n",
    "    x = x.reshape(1, -1)\n",
    "    y = y.reshape(1, -1)\n",
    "\n",
    "    cons = .7\n",
    "    for k in range(0, num_classes):\n",
    "        r = np.linspace(0.05, 1, sample_per_class)\n",
    "        t = np.linspace(k*cons, (k+6)*cons, sample_per_class)\n",
    "        x = np.cos(t)\n",
    "        y = np.sin(t)\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        label[0, k*sample_per_class:(k+1)*sample_per_class] = rand_classes[k]\n",
    "        fvec[0, k*sample_per_class:(k+1)*sample_per_class] = bound * x * r\n",
    "        fvec[1, k*sample_per_class:(k+1)*sample_per_class] = bound * y * r\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "X, y = generateSpiralData(num_classes = 9, sigma_noise = 0.01, rand_label = False)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "\n",
    "    cons = 4\n",
    "    N = num_samples # number of points per class\n",
    "    D = dim # dimensionality\n",
    "    K = num_classes # number of classes\n",
    "\n",
    "    X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "    y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "    for j in range(K):\n",
    "      ix = range(N*j,N*(j+1))\n",
    "      r = np.linspace(0.0,1,N) # radius\n",
    "      t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*sigma_noise # theta\n",
    "      X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "      y[ix] = j\n",
    "    \n",
    "    label = y.astype(np.int)\n",
    "    fvec = X\n",
    "    \n",
    "    return fvec, label\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "fvec, label = generateCircularData(num_classes =9, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "fvec, label = generateSpiralData(num_classes = 3, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "#plt.savefig('circular_vs_spiral.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Regression Benchmark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_bins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "housing\n",
      "results.csv\n",
      "stock\n",
      "stocksdomain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/cal_housing.data\", sep=',', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/stock\", sep='\\s+', header=None)\n",
    "#train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples per class is 2064.0\n",
      "[0.0, 1.9038999999999999, 2.3525, 2.7404000000000002, 3.141, 3.5352000000000001, 3.9672999999999998, 4.4382000000000001, 5.1105, 6.1600999999999999, 15.001099999999999]\n",
      "[0.0, 1.9038999999999999, 2.3525, 2.7404000000000002, 3.141, 3.5352000000000001, 3.9672999999999998, 4.4382000000000001, 5.1105, 6.1600999999999999, 16.001100000000001]\n",
      "15.0001\n",
      "Unique labels are [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCANfkhph4EtSIwx8SWqEgS9Jjfj/xuSa4lmPPc4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc16251dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_bins\n",
    "print('Number of Samples per class is ' + str(num_samples_per_class))\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_bins+1)]\n",
    "bins.insert(0,0.0)\n",
    "print(bins)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "k = 10\n",
    "\n",
    "print(label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]])\n",
    "for k in range(num_bins):\n",
    "    #print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print('Unique labels are ' + str(np.unique(label_ord)))\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "#print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.xlabel('Original Label')\n",
    "plt.ylabel('Ordinal Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>label</th>\n",
       "      <th>label_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat0  feat1  feat2   feat3   feat4   feat5   feat6   label  label_ord\n",
       "0 -122.23  37.88   41.0   880.0   129.0   322.0   126.0  8.3252        9.0\n",
       "1 -122.22  37.86   21.0  7099.0  1106.0  2401.0  1138.0  8.3014        9.0\n",
       "2 -122.24  37.85   52.0  1467.0   190.0   496.0   177.0  7.2574        9.0\n",
       "3 -122.25  37.85   52.0  1274.0   235.0   558.0   219.0  5.6431        8.0\n",
       "4 -122.25  37.85   52.0  1627.0   280.0   565.0   259.0  3.8462        5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbc0fc21f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAF6CAYAAACUSGjuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1AADU5KkBhiYkiQ1wMCUJKkB/z/n8FBnXIT7oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc16251b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,\n",
    "            c=np.sort(label_ord[sorted_idx]), cmap = plt.get_cmap('tab10'))\n",
    "plt.colorbar()\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Ordinal Label', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbc16251278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHmCAYAAABanLmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AAAMEBAAwDAAAENAAAD/h88h2pj4m2y0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc0fb240b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coeff(n, metric, lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return [1]\n",
    "    elif metric is 'ccr1':\n",
    "        return [1, 1, 1]\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.arange(1,n)/(n-1)\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros(n-1)\n",
    "        coeff[0] = 2*n-3\n",
    "        for k in range(1, n-1):\n",
    "            coeff[k] = coeff[k-1] + 2*n - (2*(k+1)+1)\n",
    "        coeff = coeff /((n-1)**2)\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "    coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    coeff = coeff * lmbda\n",
    "    coeff[n-2] = 1\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type = 'call_housing'\n",
    "num_samples = 10000\n",
    "num_classes = 9\n",
    "nclasses = num_classes\n",
    "dim = 2\n",
    "\n",
    "sigma_noise = 0.01\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=10 #Number of the first column in the excel file for writing the results.\n",
    "lr=.5 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "batch_size = 256\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "rand_label = False\n",
    "\n",
    "metric = 'ccr'\n",
    "coeff_lmbda =  1\n",
    "multi_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "KL = False #KL divergence for porbability measure\n",
    "\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04774989 -0.34285623  0.08390143 -0.86602762 -0.83336499 -0.92026252\n",
      " -0.83603365]\n",
      "[-1. -1. -1. -1. -1. -1. -1.]\n",
      "(20640, 7)\n",
      "[3 5 0 ..., 3 8 3]\n",
      "{'train': 16512, 'val': 4128}\n",
      "OR\n",
      "Number of training images 5\n",
      "Number of validation images 5\n",
      "{'train': 16512, 'val': 4128}\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inputs, classes = next(iter(dset_loaders['train']))\\nprint(inputs.shape)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = 5\n",
    "random_seed = 1\n",
    "\n",
    "if data_type == 'circular':\n",
    "    fvec, label = generateCircularData(num_samples = num_samples, \n",
    "                                       num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'linear':\n",
    "    fvec, label = generateLinearData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'spiral':\n",
    "    fvec, label = generateSpiralData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "else:\n",
    "    num_classes = num_bins\n",
    "    nclasses = num_classes\n",
    "    \n",
    "    feat=train_df.values[:,:-2]\n",
    "    #Normalize the features\n",
    "\n",
    "    feat_max = np.amax(feat,axis=0)\n",
    "    feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "    feat=feat*2-1\n",
    "\n",
    "    '''feat_mean = np.mean(feat,axis=0)\n",
    "    feat_std = np.std(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_mean)/feat_std\n",
    "    '''\n",
    "    label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "    rand_idx = np.random.permutation(len(label_ord))\n",
    "    feat = feat[rand_idx, :]\n",
    "    label = label_ord[rand_idx]\n",
    "\n",
    "\n",
    "    print(np.mean(feat,axis=0))\n",
    "    print(np.min(feat,axis=0))\n",
    "    print(feat.shape)\n",
    "    print(label)\n",
    "\n",
    "    fvec=feat.copy()\n",
    "    dim = feat.shape[1]\n",
    "    \n",
    "    if not CV == 0: \n",
    "        dset_train= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "        dset_val= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "\n",
    "        '''Define dataset loaders''''''\n",
    "        dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                            num_workers=12)}\n",
    "\n",
    "\n",
    "        dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        print(dset_sizes)\n",
    "\n",
    "        if use_gpu:\n",
    "            print('GPU is available')\n",
    "        else:\n",
    "            print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "        inputs, classes = next(iter(dset_loaders['train']))\n",
    "        print(inputs.shape)'''\n",
    "        '''dset_train = datasets.ImageFolder(data_dir+'/train_val', data_transforms['train'])\n",
    "        dset_val = datasets.ImageFolder(data_dir+'/train_val', data_transforms['val'])'''\n",
    "\n",
    "        num_train = len(dset_train)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        splits = (num_train*np.linspace(0,1,CV+1)).astype(int)\n",
    "\n",
    "        val_idx = [indices[splits[k]:splits[k+1]] for k in range(CV)]\n",
    "        train_idx=[np.setdiff1d(indices,val_idx[k]) for k in range(CV)]\n",
    "        '''Sampler functions for validation and training'''\n",
    "        sampler_train = [torch.utils.data.sampler.SubsetRandomSampler(train_idx[k]) for k in range(CV)]\n",
    "        sampler_val = [torch.utils.data.sampler.SubsetRandomSampler(val_idx[k]) for k in range(CV)]\n",
    "\n",
    "        '''Define dataset loaders'''\n",
    "        dset_loaders_arr = [{'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train[k],\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val[k],\n",
    "                                                            num_workers=12)} for k in range(CV)]\n",
    "        dset_sizes={'train':int(len(dset_train)*(1-1/CV)),'val':int(len(dset_train)*(1/CV))}\n",
    "\n",
    "        print(dset_sizes)\n",
    "        print('OR')\n",
    "        print('Number of training images '+str(len(val_idx)))\n",
    "        print('Number of validation images '+str(len(train_idx)))\n",
    "    \n",
    "\n",
    "\n",
    "'''rand_idx = np.random.permutation(len(label))\n",
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "''''''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}\n",
    "\n",
    "\n",
    "dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "'''\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(dset_sizes)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "'''inputs, classes = next(iter(dset_loaders['train']))\n",
    "print(inputs.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(fvec_test[:, 0], fvec_test[:, 1], c=label_test)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('runs_regression/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Feature Length: '+str(dim)+'\\n')\n",
    "    f.write('Number of classes: '+str(num_classes)+'\\n')\n",
    "    f.write('Data type: '+data_type+'\\n')\n",
    "    f.write('Random Noise: '+str(sigma_noise)+'\\n')\n",
    "    \n",
    "    f.write('Hidden sizes: '+ str(hidden_sizes)+'\\n')\n",
    "    f.write('Dropouts: '+str(dropouts)+'\\n')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Number of samples: '+str(num_samples)+'\\n')\n",
    "    \n",
    "    f.write('Optimizer: ' + optimizer + '\\n')\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='logs_regression.xlsx',iter_loc=10):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    specs=(datetime.now().strftime('%B%d  %H:%M:%S'),data_type,str(hidden_sizes),str(dim),str(num_classes),\n",
    "           crt, str(lr), str(m_coeff), str(KL))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc0): Linear(in_features=2, out_features=50)\n",
      "  (relu0): ReLU()\n",
      "  (drop0): Dropout(p=0)\n",
      "  (fc1): Linear(in_features=50, out_features=50)\n",
      "  (relu1): ReLU()\n",
      "  (drop1): Dropout(p=0)\n",
      "  (fc2): Linear(in_features=50, out_features=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropouts, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.numHidden=len(hidden_sizes)\n",
    "        setattr(self, 'fc0', nn.Linear(input_size, hidden_sizes[0]))\n",
    "        setattr(self, 'relu0', nn.ReLU())\n",
    "        setattr(self, 'drop0', nn.Dropout(p=dropouts[0]))\n",
    "        for k in range(len(hidden_sizes)-1):\n",
    "            setattr(self, 'fc'+str(k+1), nn.Linear(hidden_sizes[k], hidden_sizes[k+1]))\n",
    "            setattr(self, 'relu'+str(k+1), nn.ReLU())\n",
    "            setattr(self, 'drop'+str(k+1), nn.Dropout(p=dropouts[k+1]))\n",
    "        setattr(self, 'fc'+str(len(hidden_sizes)), nn.Linear(hidden_sizes[-1], num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.fc0(x)\n",
    "        out = self.relu0(out)\n",
    "        out = self.drop0(out)\n",
    "        for k in range(self.numHidden-1):\n",
    "            fc = getattr(self,'fc'+str(k+1))\n",
    "            relu = getattr(self,'relu'+str(k+1))\n",
    "            drop = getattr(self,'drop'+str(k+1))\n",
    "            out = fc(out)\n",
    "            out = relu(out)\n",
    "            out = drop(out)\n",
    "        fc = getattr(self,'fc'+str(self.numHidden))\n",
    "        out = fc(out)\n",
    "        return out\n",
    "    \n",
    "model=Net(2, [50, 50], [0, 0], 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    nclasses=num_classes,\n",
    "                    hidden_sizes = hidden_sizes,\n",
    "                    dropouts = dropouts):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    model_ft = Net(dim, hidden_sizes , dropouts, num_classes)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_epochs(result_log, logname):\n",
    "    print(len(result_log))\n",
    "\n",
    "    wb_tr = openpyxl.Workbook()\n",
    "    ws_tr = wb_tr.active\n",
    "    wb_val = openpyxl.Workbook()\n",
    "    ws_val = wb_val.active\n",
    "    print(logname)\n",
    "\n",
    "    label_arr_tr = np.zeros((100000,1))\n",
    "    probs_arr_tr = np.zeros((100000, num_classes))\n",
    "    label_arr_val = np.zeros((100000,1))\n",
    "    probs_arr_val = np.zeros((100000, num_classes))\n",
    "\n",
    "    prev_epoch = 0\n",
    "    \n",
    "    count_tr = count_val = 0\n",
    "    for result in result_log:\n",
    "        epoch = result[1]\n",
    "        if not epoch == prev_epoch:\n",
    "            label_arr_tr = label_arr_tr[:count_tr]\n",
    "            probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "            label_arr_val = label_arr_val[:count_val]\n",
    "            probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            ws_tr.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "            ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "                ws_tr.append(probs)\n",
    "            #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "            ws_val.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "            ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_val[1:,:].T.tolist():\n",
    "                ws_val.append(probs)\n",
    "    \n",
    "\n",
    "            label_arr_tr = np.zeros((100000,1))\n",
    "            probs_arr_tr = np.zeros((100000, num_classes))\n",
    "            label_arr_val = np.zeros((100000,1))\n",
    "            probs_arr_val = np.zeros((100000, num_classes)) \n",
    "            count_tr = count_val = 0\n",
    "            prev_epoch = epoch\n",
    "\n",
    "        label = np.asarray(result[2]).reshape(-1,1)\n",
    "        scores = np.asarray(result[3])\n",
    "        exp_scores = np.exp(scores - np.max(scores,axis=1).reshape(-1, 1)*np.ones(num_classes))\n",
    "        probs = np.round(exp_scores/(np.sum(exp_scores,axis=1).reshape(-1, 1)*np.ones(num_classes)), decimals=2)\n",
    "        if result[0] == 'train':\n",
    "            label_arr_tr[count_tr:count_tr + len(label)]  = label\n",
    "            probs_arr_tr[count_tr:count_tr + len(label), :] = probs\n",
    "            count_tr += len(label)\n",
    "        elif result[0] == 'val':\n",
    "            label_arr_val[count_val:count_val + len(label)]  = label\n",
    "            probs_arr_val[count_val:count_val + len(label), :] = probs\n",
    "            count_val += len(label)\n",
    "\n",
    "\n",
    "    \n",
    "    label_arr_tr = label_arr_tr[:count_tr]\n",
    "    probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "    label_arr_val = label_arr_val[:count_val]\n",
    "    probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            \n",
    "    ws_tr.append(['Epoch ' + str(epoch)])\n",
    "    ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "    ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "        ws_tr.append(probs)\n",
    "    #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "    ws_val.append(['Epoch ' + str(epoch)])\n",
    "    ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "    ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_val[1:,:].T.tolist():\n",
    "        ws_val.append(probs)\n",
    "    wb_val.save('./runs_regression/'+logname + '/val.xlsx')\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, num_classes))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, num_classes))\n",
    "    prev_epoch = epoch\n",
    "    print('Finito')\n",
    "    \n",
    "    del label_arr_tr, probs_arr_tr, label_arr_val, probs_arr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "    \n",
    "def run_network():\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "    \n",
    "    \n",
    "    '''Name of the trial'''\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname='Ordinal_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('runs_regression/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    best_model, last_model, result_log = ft.train_model(model_ft,optimizer_ft, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=100,batch_size=batch_size,num_log=250,\n",
    "                            multi_prob=False,lr_decay_epoch=lr_decay_epoch,init_lr=lr,mse_loss=False,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss,numOut=num_classes,\n",
    "                            logname='logs_regression.xlsx',\n",
    "                            multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'./saved_models/ord/'+logname+'_best')\n",
    "    torch.save(last_model,'./saved_models/ord/'+logname+'_last')\n",
    "    \n",
    "    '''print('Writing results')\n",
    "    write_epochs(result_log, logname)\n",
    "    print('Wrote results')'''\n",
    "    '''Free up the memory'''\n",
    "    del model_ft, result_log\n",
    "    \n",
    "    writer.close\n",
    "    del writer\n",
    "    return last_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "end_to_end = True\n",
    "run_network()'''\n",
    "print(fvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_coef is [ 0.11111111  0.22222222  0.33333333  0.44444444  0.55555556  0.66666667\n",
      "  0.77777778  0.88888889  1.          0.88888889  0.77777778  0.66666667\n",
      "  0.55555556  0.44444444  0.33333333  0.22222222  0.11111111]\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR is set to 1.0\n",
      "train Loss: 0.0025 Acc: 0.1017 CIR-1: 0.3013 RMSE 3.0046 MAE 2.5354\n",
      "val Loss: 0.0026 Acc: 0.1122 CIR-1: 0.3343 RMSE 2.7334 MAE 2.3069\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.0025 Acc: 0.1171 CIR-1: 0.3607 RMSE 2.6499 MAE 2.2009\n",
      "val Loss: 0.0027 Acc: 0.1298 CIR-1: 0.3813 RMSE 3.1028 MAE 2.4615\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 0.1332 CIR-1: 0.4028 RMSE 2.5595 MAE 2.0733\n",
      "val Loss: 0.0025 Acc: 0.1570 CIR-1: 0.4520 RMSE 2.4499 MAE 1.9399\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9456:\n",
      "Process Process-9454:\n",
      "Process Process-9445:\n",
      "Process Process-9446:\n",
      "Process Process-9451:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-face4a64f5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdset_loaders\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_loaders_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b03f0d318d1c>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0miter_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_loc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumOut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0mlogname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs_regression.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                             multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m'''Save the models'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mtezcan/New Volume/amazon/notebook/functions/fine_tune.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, lr_scheduler, dset_loaders, dset_sizes, writer, use_gpu, num_epochs, batch_size, num_log, init_lr, lr_decay_epoch, multi_prob, mse_loss, cross_loss, multi_loss, numOut, logname, iter_loc, multi_coeff, single_coeff, KL)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmulti_loss\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mlabels_multi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                             \u001b[0mextend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_coeff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                             \u001b[0mlabel_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumOut\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9447:\n",
      "Process Process-9453:\n",
      "Process Process-9452:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-9448:\n",
      "Process Process-9449:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-9450:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-9455:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=1 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=20 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = [0, 0, 0, 0, 0, .5, .5, .5, 0, 0, 0]#.5, .5, .5]\n",
    "single_loss=0.\n",
    "multi_loss =1.\n",
    "\n",
    "KL = False\n",
    "\n",
    "metric = 'mae'\n",
    "\n",
    "for dset_loaders in dset_loaders_arr:\n",
    "    run_network()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='adam' #Optimizer function\n",
    "lr=0.05 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "\n",
    "\n",
    "hidden_sizes = [16, 16, 32, 32, 16, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = []#.5, .5, .5]\n",
    "single_loss=1.0\n",
    "multi_loss =0.0\n",
    "\n",
    "KL = True\n",
    "metric = None\n",
    "\n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'ccr1', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "        \n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'mae', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "    \n",
    "'''KL = True\n",
    "metric = 'ccr'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'ccr1'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mae'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mse'\n",
    "for k in range(10):\n",
    "    run_network()'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader again, this time without shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_shape = 'Spiral'\n",
    "data_date = '18_01_31'\n",
    "data_dir = './saved_models_github/' + data_shape + '/' + data_date\n",
    "\n",
    "run_dirs = sorted(os.listdir(data_dir))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:110]\n",
    "mae_dirs = last_dirs[110:]\n",
    "all_dirs = [ccr1_dirs, mae_dirs]\n",
    "\n",
    "\n",
    "'''run_dirs = sorted(os.listdir('./saved_models/test'))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:100]\n",
    "mae_dirs = last_dirs[100:]\n",
    "\n",
    "pure_ccr1 = ['Ordinal_January24  14:10:01_last',\n",
    "             'Ordinal_January24  14:11:08_last',\n",
    "             'Ordinal_January24  14:12:14_last',\n",
    "             'Ordinal_January24  14:13:21_last',\n",
    "             'Ordinal_January24  14:14:27_last',\n",
    "             'Ordinal_January24  14:15:34_last',\n",
    "             'Ordinal_January24  14:16:40_last',\n",
    "             'Ordinal_January24  14:17:47_last',\n",
    "             'Ordinal_January24  14:18:54_last',\n",
    "             'Ordinal_January24  14:20:00_last',]\n",
    "\n",
    "pure_mae = ['Ordinal_January24  14:21:07_last',\n",
    "             'Ordinal_January24  14:22:13_last',\n",
    "             'Ordinal_January24  14:23:19_last',\n",
    "             'Ordinal_January24  14:24:26_last',\n",
    "             'Ordinal_January24  14:25:32_last',\n",
    "             'Ordinal_January24  14:26:38_last',\n",
    "             'Ordinal_January24  14:27:45_last',\n",
    "             'Ordinal_January24  14:28:52_last',\n",
    "             'Ordinal_January24  14:29:58_last',\n",
    "             'Ordinal_January24  14:31:05_last',]'''\n",
    "                \n",
    "len(mae_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.load('./saved_models/ord/Ordinal_January24  10:24:20_last', map_location={'cuda:0': 'cpu'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate(model_dir, phase='train'):\n",
    "    if use_gpu:\n",
    "        model = torch.load(model_dir)\n",
    "    else:\n",
    "        model = torch.load(model_dir, map_location={'cuda:0': 'cpu'})\n",
    "    model.train(False)\n",
    "\n",
    "    labels_arr = np.asarray([]);\n",
    "    preds_arr = np.asarray([]);\n",
    "    for data in dset_loaders[phase]:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = np.argmax(model(inputs).cpu().data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.cpu().data.numpy())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            outputs = np.argmax(model(inputs).data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.data.numpy())\n",
    "          \n",
    "        preds_arr = np.append(preds_arr, outputs)\n",
    "    return preds_arr\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:24:20_last')\n",
    "#print(np.min(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(18,15))\n",
    "\n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+1)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR$ loss' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+6)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[50+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$0.5CCR$ loss + $0.5CCR_1$ loss \\n' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+11)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[100+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR_1$ loss ' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "plt.savefig('variance_of_results.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_and_mean(root_dir, sub_dirs, phase='train'):\n",
    "    scores_arr = np.zeros((label_train.shape[0],9))\n",
    "    for sub_dir in sub_dirs:\n",
    "        if use_gpu:\n",
    "            model = torch.load(root_dir + '/' + sub_dir)\n",
    "        else:\n",
    "            model = torch.load(root_dir + '/' + sub_dir, map_location={'cuda:0': 'cpu'})\n",
    "        model.train(False)\n",
    "        #print(model)\n",
    "        score_arr = np.zeros((1,9))\n",
    "        for data in dset_loaders[phase]:\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                outputs = model(inputs).cpu().data.numpy()\n",
    "                #print(outputs.shape)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                outputs = model(inputs).data.numpy()\n",
    "                \n",
    "            score_arr = np.append(score_arr, outputs, axis=0)\n",
    "        scores_arr += score_arr[1:,:]\n",
    "        \n",
    "    return scores_arr\n",
    "#scores_tr = validate_and_mean('./saved_models/test_circular', last_dirs[:10])\n",
    "#pred_tr = np.argmax(scores_tr, axis=1)\n",
    "#print(np.mean(label_train == pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dirs = ['./saved_models/ord/Ordinal_January24  10:16:00_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:20:35_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:24:20_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:28:03_last']\n",
    "\n",
    "'''model_dirs = ['./saved_models/ord/Ordinal_January24  13:09:17_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:18:08_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:27:43_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:43:43_last']'''\n",
    "\n",
    "model_dirs = ['./saved_models/ord/Ordinal_January26  00:22:14_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:19:20_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:09:08_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:17:53_last']\n",
    "preds = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    preds.append(validate(model_dir))\n",
    "    \n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric = 'CCR1'\n",
    "\n",
    "if metric is 'CCR1':\n",
    "    metric_code = 0\n",
    "elif metric is 'MAE':\n",
    "    metric_code = 1\n",
    "else:\n",
    "    print('Wrong metric')\n",
    "    \n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "metrics = np.zeros((11, 4))\n",
    "for k in range(10):\n",
    "    scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][k*10:(k+1)*10])\n",
    "    pred_tr = np.argmax(scores_tr, axis=1)\n",
    "    plt.subplot(4,3,k+2)\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    metrics[k,:] = [ccr,ccr1,mae,rmse]\n",
    "    plt.title('$\\lambda$=' + str(np.round(k*.1, decimals=1)) + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "              ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "              ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "    \n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:20:35_last')\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  13:18:08_last')\n",
    "\n",
    "scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(4,3,12)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "metrics[10,:] = [ccr,ccr1,mae,rmse]\n",
    "plt.title('$\\lambda$=1.0' + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt_title = data_shape + '_Data_CCR_' + metric + '_tradeoff_' + data_date + '.tiff'\n",
    "plt.savefig(plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "\n",
    "lmbdas = [.1*k for k in range(11)]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.plot(lmbdas, metrics[:,0], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR$')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lmbdas, metrics[:,1], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR_1$')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lmbdas, metrics[:,2], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$MAE$')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lmbdas, metrics[:,3], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$RMSE$')\n",
    "\n",
    "plt.savefig('spiral_plots_ccr1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR_1 loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/ord', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$MAE loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n$MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt.savefig('spiral_extreme.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR_1$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$MAE$ loss')\n",
    "\n",
    "plt.savefig('circular_extreme_hist.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.subplot(211)\n",
    "img = mpimg.imread('Circular_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)\n",
    "plt.subplot(212)\n",
    "img = mpimg.imread('Spiral_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
