{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5\n",
    "\n",
    "\n",
    "#from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f90711116a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAD8CAYAAAAylrwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90d8ac1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "dim = 2\n",
    "\n",
    "def generateLinearData(num_samples = 10000, num_classes = num_classes, dim = dim, bound = 5, sigma_noise = .1,rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    label = np.dot((np.random.rand(1,dim)*bound*2-bound).reshape(1,-1),fvec)\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateLinearData(rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateCircularData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "        \n",
    "    fvec = np.random.rand(dim, num_samples)*bound*2-bound\n",
    "    \n",
    "    fvec_l = np.sum(fvec**2, axis = 0).reshape(1,-1)\n",
    "    print(fvec_l.shape)\n",
    "    label = fvec_l\n",
    "\n",
    "    sorted_idx = np.argsort(label)\n",
    "    bin_size = label.shape[1]/num_classes\n",
    "\n",
    "    for k in range(0, num_classes):\n",
    "        label[0, sorted_idx[0, np.floor(k*bin_size).astype(int):np.floor((k+1)*bin_size).astype(int)]] = rand_classes[k]\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "fvec, label = generateCircularData(num_classes =5, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Greys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = 9, dim = 2,\n",
    "                         bound = 1, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "    sample_per_class = int(num_samples/num_classes)\n",
    "    num_samples = sample_per_class*num_classes\n",
    "    fvec = np.zeros((dim, sample_per_class*num_classes))\n",
    "    label = np.zeros((1, sample_per_class*num_classes))\n",
    "    \n",
    "    t = np.linspace(0, 10, sample_per_class)\n",
    "    x = t * np.cos(t)\n",
    "    y = t * np.sin(t)\n",
    "    x = x.reshape(1, -1)\n",
    "    y = y.reshape(1, -1)\n",
    "\n",
    "    cons = .7\n",
    "    for k in range(0, num_classes):\n",
    "        r = np.linspace(0.05, 1, sample_per_class)\n",
    "        t = np.linspace(k*cons, (k+6)*cons, sample_per_class)\n",
    "        x = np.cos(t)\n",
    "        y = np.sin(t)\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        label[0, k*sample_per_class:(k+1)*sample_per_class] = rand_classes[k]\n",
    "        fvec[0, k*sample_per_class:(k+1)*sample_per_class] = bound * x * r\n",
    "        fvec[1, k*sample_per_class:(k+1)*sample_per_class] = bound * y * r\n",
    "\n",
    "    label = label.astype(np.int)\n",
    "    n = sigma_noise * np.random.randn(dim, num_samples)\n",
    "    fvec = fvec + n\n",
    "    \n",
    "    return fvec.T, label.reshape(label.shape[1])\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "X, y = generateSpiralData(num_classes = 9, sigma_noise = 0.01, rand_label = False)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generateSpiralData(num_samples = 10000, num_classes = num_classes, dim = dim,\n",
    "                         bound = 5, sigma_noise = .1, rand_label = False):\n",
    "    \n",
    "    if  rand_label:\n",
    "        rand_classes = np.random.permutation(num_classes)\n",
    "    else:\n",
    "        rand_classes = np.arange(num_classes)\n",
    "    \n",
    "    #rand_classes = [1, 1.5, -1, -1.5]\n",
    "\n",
    "    cons = 4\n",
    "    N = num_samples # number of points per class\n",
    "    D = dim # dimensionality\n",
    "    K = num_classes # number of classes\n",
    "\n",
    "    X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "    y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "    for j in range(K):\n",
    "      ix = range(N*j,N*(j+1))\n",
    "      r = np.linspace(0.0,1,N) # radius\n",
    "      t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*sigma_noise # theta\n",
    "      X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "      y[ix] = j\n",
    "    \n",
    "    label = y.astype(np.int)\n",
    "    fvec = X\n",
    "    \n",
    "    return fvec, label\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "fvec, label = generateCircularData(num_classes =9, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "fvec, label = generateSpiralData(num_classes = 3, sigma_noise = 0, rand_label = False)\n",
    "plt.scatter(fvec[:, 0], fvec[:, 1], c=label, cmap = plt.get_cmap('Set1'))\n",
    "plt.colorbar()\n",
    "#plt.savefig('circular_vs_spiral.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Regression Benchmark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_bins=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "housing\n",
      "results.csv\n",
      "stock\n",
      "stocksdomain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/housing\", sep=',', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv(\"./dataset/regression/housing\", sep='\\s+', header=None)\n",
    "train_df = pd.read_csv(\"./dataset/regression/cpu_act.data\", sep=',', header=None)\n",
    "#train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_bins\n",
    "print('Number of Samples per class is ' + str(num_samples_per_class))\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_bins+1)]\n",
    "bins.insert(0,0.0)\n",
    "print(bins)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "k = 10\n",
    "\n",
    "print(label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]])\n",
    "for k in range(num_bins):\n",
    "    #print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print('Unique labels are ' + str(np.unique(label_ord)))\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "#print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.xlabel('Original Label')\n",
    "plt.ylabel('Ordinal Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,\n",
    "            c=np.sort(label_ord[sorted_idx]), cmap = plt.get_cmap('tab10'))\n",
    "plt.colorbar()\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Label', fontsize=12)\n",
    "\n",
    "plt.savefig('cpu_act.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coeff(n, metric, lmbda = 1):\n",
    "    if metric is 'ccr':\n",
    "        return [1]\n",
    "    elif metric is 'ccr1':\n",
    "        return [lmbda, 1, lmbda]\n",
    "    elif metric is 'mae':\n",
    "        coeff = np.arange(1,n)/(n-1)\n",
    "    elif metric is 'mse':\n",
    "        coeff = np.zeros(n-1)\n",
    "        coeff[0] = 2*n-3\n",
    "        for k in range(1, n-1):\n",
    "            coeff[k] = coeff[k-1] + 2*n - (2*(k+1)+1)\n",
    "        coeff = coeff /((n-1)**2)\n",
    "    else:\n",
    "        print('Undefined Metric: ' + metric)\n",
    "    coeff = np.concatenate((coeff, coeff[::-1][1:]), axis=0)\n",
    "    coeff = coeff * lmbda\n",
    "    coeff[n-2] = 1\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type = 'cpu_act'\n",
    "num_samples = 10000\n",
    "num_classes = 9\n",
    "nclasses = num_classes\n",
    "dim = 2\n",
    "\n",
    "sigma_noise = 0.01\n",
    "optimizer='sgd' #Optimizer function\n",
    "iter_loc=11 #Number of the first column in the excel file for writing the results.\n",
    "lr=.5 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "batch_size = 256\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "rand_label = False\n",
    "\n",
    "metric = 'ccr'\n",
    "coeff_lmbda =  1\n",
    "multi_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "KL = False #KL divergence for porbability measure\n",
    "\n",
    "\n",
    "'''Multipliers for loss functions'''\n",
    "single_loss=1.\n",
    "multi_loss=0.\n",
    "\n",
    "comment=' ' #Additional comments if any\n",
    "\n",
    "algo = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV = 5\n",
    "random_seed = 1\n",
    "\n",
    "if data_type == 'circular':\n",
    "    fvec, label = generateCircularData(num_samples = num_samples, \n",
    "                                       num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'linear':\n",
    "    fvec, label = generateLinearData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "elif data_type == 'spiral':\n",
    "    fvec, label = generateSpiralData(num_samples = num_samples, \n",
    "                                     num_classes = num_classes, dim = dim, bound = 5,\n",
    "                                       sigma_noise = sigma_noise, rand_label = rand_label)\n",
    "else:\n",
    "    num_classes = num_bins\n",
    "    nclasses = num_classes\n",
    "    \n",
    "    feat=train_df.values[:,:-2]\n",
    "    #Normalize the features\n",
    "\n",
    "    feat_max = np.amax(feat,axis=0)\n",
    "    feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "    feat=feat*2-1\n",
    "\n",
    "    '''feat_mean = np.mean(feat,axis=0)\n",
    "    feat_std = np.std(feat,axis=0)\n",
    "\n",
    "    feat=(feat-feat_mean)/feat_std\n",
    "    '''\n",
    "    label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "    rand_idx = np.random.permutation(len(label_ord))\n",
    "    feat = feat[rand_idx, :]\n",
    "    label = label_ord[rand_idx]\n",
    "\n",
    "\n",
    "    print(np.mean(feat,axis=0))\n",
    "    print(np.min(feat,axis=0))\n",
    "    print(feat.shape)\n",
    "    print(label)\n",
    "\n",
    "    fvec=feat.copy()\n",
    "    dim = feat.shape[1]\n",
    "    \n",
    "    if not CV == 0: \n",
    "        dset_train= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "        dset_val= torch.utils.data.TensorDataset(torch.from_numpy(fvec).type(torch.FloatTensor),\n",
    "                                                       torch.from_numpy(label).type(torch.LongTensor))\n",
    "\n",
    "        '''Define dataset loaders''''''\n",
    "        dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                            num_workers=12)}\n",
    "\n",
    "\n",
    "        dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        print(dset_sizes)\n",
    "\n",
    "        if use_gpu:\n",
    "            print('GPU is available')\n",
    "        else:\n",
    "            print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "        inputs, classes = next(iter(dset_loaders['train']))\n",
    "        print(inputs.shape)'''\n",
    "        '''dset_train = datasets.ImageFolder(data_dir+'/train_val', data_transforms['train'])\n",
    "        dset_val = datasets.ImageFolder(data_dir+'/train_val', data_transforms['val'])'''\n",
    "\n",
    "        num_train = len(dset_train)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        splits = (num_train*np.linspace(0,1,CV+1)).astype(int)\n",
    "\n",
    "        val_idx = [indices[splits[k]:splits[k+1]] for k in range(CV)]\n",
    "        train_idx=[np.setdiff1d(indices,val_idx[k]) for k in range(CV)]\n",
    "        '''Sampler functions for validation and training'''\n",
    "        sampler_train = [torch.utils.data.sampler.SubsetRandomSampler(train_idx[k]) for k in range(CV)]\n",
    "        sampler_val = [torch.utils.data.sampler.SubsetRandomSampler(val_idx[k]) for k in range(CV)]\n",
    "\n",
    "        '''Define dataset loaders'''\n",
    "        dset_loaders_arr = [{'train':torch.utils.data.DataLoader(dset_train, batch_size=batch_size,sampler=sampler_train[k],\n",
    "                                                            num_workers=12),\n",
    "                        'val':torch.utils.data.DataLoader(dset_val, batch_size=batch_size,sampler=sampler_val[k],\n",
    "                                                            num_workers=12)} for k in range(CV)]\n",
    "        dset_sizes={'train':int(len(dset_train)*(1-1/CV)),'val':int(len(dset_train)*(1/CV))}\n",
    "\n",
    "        print(dset_sizes)\n",
    "        print('OR')\n",
    "        print('Number of training images '+str(len(val_idx)))\n",
    "        print('Number of validation images '+str(len(train_idx)))\n",
    "    \n",
    "\n",
    "\n",
    "'''rand_idx = np.random.permutation(len(label))\n",
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "''''''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=True,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}\n",
    "\n",
    "\n",
    "dset_sizes={'train':len(dsets['train']),'val':len(dsets['val'])}\n",
    "'''\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(dset_sizes)\n",
    "\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')\n",
    "\n",
    "'''inputs, classes = next(iter(dset_loaders['train']))\n",
    "print(inputs.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99954906 -0.16560622 -0.737447   ..., -0.3860466  -0.8387096\n",
      "   0.1111112 ]\n",
      " [-0.99927812 -0.21041293 -0.9931948  ..., -0.3866878  -0.8776978   0.5       ]\n",
      " [-0.98771741 -0.12755575 -0.3179312  ..., -0.066578   -0.8767388\n",
      "  -0.4691358 ]\n",
      " ..., \n",
      " [-0.9982203  -0.10983841 -0.9871126  ..., -0.7396072  -0.9310344  -0.076923  ]\n",
      " [-0.99995302 -0.06024094 -1.         ..., -0.5068494  -1.         -1.        ]\n",
      " [-0.99937017 -0.09932965 -0.941941   ..., -0.8111964  -0.7362638  -0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "print(feat.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    '''\n",
    "    Creates a text file named Network_properties.txt inside runs/'logname'\n",
    "    '''\n",
    "    f=open('runs_regression/'+logname+'/Network_properties.txt','w')\n",
    "    f.write('Feature Length: '+str(dim)+'\\n')\n",
    "    f.write('Number of classes: '+str(num_classes)+'\\n')\n",
    "    f.write('Data type: '+data_type+'\\n')\n",
    "    f.write('Random Noise: '+str(sigma_noise)+'\\n')\n",
    "    \n",
    "    f.write('Hidden sizes: '+ str(hidden_sizes)+'\\n')\n",
    "    f.write('Dropouts: '+str(dropouts)+'\\n')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Number of samples: '+str(num_samples)+'\\n')\n",
    "    \n",
    "    f.write('Optimizer: ' + optimizer + '\\n')\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    f.write('Criterion: '+crt+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "def writeLog_xlsx(logname='logs_regression.xlsx',iter_loc=11):\n",
    "    '''\n",
    "    Adds a line to logs.xlsx with the network properties and outcomes.\n",
    "    :param iter_loc: First column to record the outcomes.\n",
    "    '''\n",
    "    \n",
    "    print(logname)\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    specs=(datetime.now().strftime('%B%d  %H:%M:%S'),data_type,str(hidden_sizes),str(dim),str(num_classes),\n",
    "           crt, str(lr), str(metric), str(coeff_lmbda), str(algo))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    book.save(logname)\n",
    "#writeLog_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc0): Linear (2 -> 50)\n",
      "  (relu0): ReLU ()\n",
      "  (drop0): Dropout (p = 0)\n",
      "  (fc1): Linear (50 -> 50)\n",
      "  (relu1): ReLU ()\n",
      "  (drop1): Dropout (p = 0)\n",
      "  (fc2): Linear (50 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropouts, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.numHidden=len(hidden_sizes)\n",
    "        setattr(self, 'fc0', nn.Linear(input_size, hidden_sizes[0]))\n",
    "        setattr(self, 'relu0', nn.ReLU())\n",
    "        setattr(self, 'drop0', nn.Dropout(p=dropouts[0]))\n",
    "        for k in range(len(hidden_sizes)-1):\n",
    "            setattr(self, 'fc'+str(k+1), nn.Linear(hidden_sizes[k], hidden_sizes[k+1]))\n",
    "            setattr(self, 'relu'+str(k+1), nn.ReLU())\n",
    "            setattr(self, 'drop'+str(k+1), nn.Dropout(p=dropouts[k+1]))\n",
    "        setattr(self, 'fc'+str(len(hidden_sizes)), nn.Linear(hidden_sizes[-1], num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.fc0(x)\n",
    "        out = self.relu0(out)\n",
    "        out = self.drop0(out)\n",
    "        for k in range(self.numHidden-1):\n",
    "            fc = getattr(self,'fc'+str(k+1))\n",
    "            relu = getattr(self,'relu'+str(k+1))\n",
    "            drop = getattr(self,'drop'+str(k+1))\n",
    "            out = fc(out)\n",
    "            out = relu(out)\n",
    "            out = drop(out)\n",
    "        fc = getattr(self,'fc'+str(self.numHidden))\n",
    "        out = fc(out)\n",
    "        return out\n",
    "    \n",
    "model=Net(2, [50, 50], [0, 0], 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_loader(comment=comment,\n",
    "                    optimizer=optimizer,\n",
    "                    iter_loc=iter_loc,\n",
    "                    lr=lr,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    lr_decay_epoch=lr_decay_epoch,\n",
    "                    nclasses=num_classes,\n",
    "                    hidden_sizes = hidden_sizes,\n",
    "                    dropouts = dropouts):\n",
    "    \n",
    "    '''Load the network from pytorch'''\n",
    "    model_ft = Net(dim, hidden_sizes , dropouts, num_classes)\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "\n",
    "    '''Define the optimizer function'''\n",
    "    if(optimizer=='adam'):\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif(optimizer=='sgd'):\n",
    "        if(end_to_end):\n",
    "            optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "        else:\n",
    "            optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n",
    "    return model_ft, optimizer_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end_to_end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6fc291b403a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                             \u001b[0mlr_decay_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_decay_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                             nclasses=num_classes)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0ma_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c06a19410825>\u001b[0m in \u001b[0;36mnetwork_loader\u001b[0;34m(comment, optimizer, iter_loc, lr, momentum, weight_decay, lr_scheduler, lr_decay_epoch, nclasses, hidden_sizes, dropouts)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_to_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end_to_end' is not defined"
     ]
    }
   ],
   "source": [
    "model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "a_vec = Variable(torch.randn(10, 1), requires_grad=True)\n",
    "params = optimizer_ft.param_groups\n",
    "params[0]['params'].append(a_vec)\n",
    "optimizer_ft.param_groups = params\n",
    "print(optimizer_ft.param_groups)\n",
    "#optimizer_ft.add_param_group({'params': a_vec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_epochs(result_log, logname):\n",
    "    print(len(result_log))\n",
    "\n",
    "    wb_tr = openpyxl.Workbook()\n",
    "    ws_tr = wb_tr.active\n",
    "    wb_val = openpyxl.Workbook()\n",
    "    ws_val = wb_val.active\n",
    "    print(logname)\n",
    "\n",
    "    label_arr_tr = np.zeros((100000,1))\n",
    "    probs_arr_tr = np.zeros((100000, num_classes))\n",
    "    label_arr_val = np.zeros((100000,1))\n",
    "    probs_arr_val = np.zeros((100000, num_classes))\n",
    "\n",
    "    prev_epoch = 0\n",
    "    \n",
    "    count_tr = count_val = 0\n",
    "    for result in result_log:\n",
    "        epoch = result[1]\n",
    "        if not epoch == prev_epoch:\n",
    "            label_arr_tr = label_arr_tr[:count_tr]\n",
    "            probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "            label_arr_val = label_arr_val[:count_val]\n",
    "            probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            ws_tr.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "            ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "                ws_tr.append(probs)\n",
    "            #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "            ws_val.append(['Epoch ' + str(prev_epoch)])\n",
    "            ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "            ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "            for probs in probs_arr_val[1:,:].T.tolist():\n",
    "                ws_val.append(probs)\n",
    "    \n",
    "\n",
    "            label_arr_tr = np.zeros((100000,1))\n",
    "            probs_arr_tr = np.zeros((100000, num_classes))\n",
    "            label_arr_val = np.zeros((100000,1))\n",
    "            probs_arr_val = np.zeros((100000, num_classes)) \n",
    "            count_tr = count_val = 0\n",
    "            prev_epoch = epoch\n",
    "\n",
    "        label = np.asarray(result[2]).reshape(-1,1)\n",
    "        scores = np.asarray(result[3])\n",
    "        exp_scores = np.exp(scores - np.max(scores,axis=1).reshape(-1, 1)*np.ones(num_classes))\n",
    "        probs = np.round(exp_scores/(np.sum(exp_scores,axis=1).reshape(-1, 1)*np.ones(num_classes)), decimals=2)\n",
    "        if result[0] == 'train':\n",
    "            label_arr_tr[count_tr:count_tr + len(label)]  = label\n",
    "            probs_arr_tr[count_tr:count_tr + len(label), :] = probs\n",
    "            count_tr += len(label)\n",
    "        elif result[0] == 'val':\n",
    "            label_arr_val[count_val:count_val + len(label)]  = label\n",
    "            probs_arr_val[count_val:count_val + len(label), :] = probs\n",
    "            count_val += len(label)\n",
    "\n",
    "\n",
    "    \n",
    "    label_arr_tr = label_arr_tr[:count_tr]\n",
    "    probs_arr_tr = probs_arr_tr[:count_tr, :]\n",
    "    label_arr_val = label_arr_val[:count_val]\n",
    "    probs_arr_val = probs_arr_val[:count_val, :]\n",
    "            \n",
    "    ws_tr.append(['Epoch ' + str(epoch)])\n",
    "    ws_tr.append(label_arr_tr[1:].reshape(-1).tolist())\n",
    "    ws_tr.append(np.argmax(probs_arr_tr[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_tr[1:,:].T.tolist():\n",
    "        ws_tr.append(probs)\n",
    "    #wb_tr.save('./runs_ord/'+logname + '/train.xlsx')\n",
    "    ws_val.append(['Epoch ' + str(epoch)])\n",
    "    ws_val.append(label_arr_val[1:].reshape(-1).tolist())\n",
    "    ws_val.append(np.argmax(probs_arr_val[1:,:], axis=1).reshape(-1).tolist())\n",
    "    for probs in probs_arr_val[1:,:].T.tolist():\n",
    "        ws_val.append(probs)\n",
    "    wb_val.save('./runs_regression/'+logname + '/val.xlsx')\n",
    "    label_arr_tr = np.zeros((1,1))\n",
    "    probs_arr_tr = np.zeros((1, num_classes))\n",
    "    label_arr_val = np.zeros((1,1))\n",
    "    probs_arr_val = np.zeros((1, num_classes))\n",
    "    prev_epoch = epoch\n",
    "    print('Finito')\n",
    "    \n",
    "    del label_arr_tr, probs_arr_tr, label_arr_val, probs_arr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ft)\n",
    "    \n",
    "def run_network():\n",
    "    '''\n",
    "    Cretaes the log files and starts the training\n",
    "    '''\n",
    "    model_ft, optimizer_ft = network_loader(comment=comment, #'Tested for three rooms'\n",
    "                                            optimizer=optimizer,\n",
    "                                            iter_loc=iter_loc,\n",
    "                                            lr=lr,\n",
    "                                            momentum=momentum,\n",
    "                                            weight_decay=weight_decay,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            lr_decay_epoch=lr_decay_epoch,\n",
    "                                            nclasses=num_classes)\n",
    "    \n",
    "    \n",
    "    '''Name of the trial'''\n",
    "    crt=str(single_loss)+'xsingle + '+str(multi_loss)+'Xmulti'\n",
    "    logname='Ordinal_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "    writer = SummaryWriter('runs_regression/'+logname) #For tensorboard\n",
    "    writeLog(logname)\n",
    "    writeLog_xlsx()\n",
    "    \n",
    "    '''Start trianing'''\n",
    "    if metric:\n",
    "        m_coeff = make_coeff(nclasses, metric, coeff_lmbda)\n",
    "    else:\n",
    "        m_coeff = multi_coeff\n",
    "    best_model, last_model, result_log = ft.train_model(model_ft,optimizer_ft, lr_scheduler,dset_loaders,\n",
    "                            dset_sizes,writer,use_gpu=use_gpu,num_epochs=100,batch_size=batch_size,num_log=250,\n",
    "                            lr_decay_epoch=lr_decay_epoch,init_lr=lr,regression=False,\n",
    "                            iter_loc=iter_loc,cross_loss=single_loss,multi_loss=multi_loss,numOut=num_classes,\n",
    "                            logname='logs_regression.xlsx',\n",
    "                            multi_coeff = m_coeff, single_coeff = m_coeff, KL = KL, algo = algo)\n",
    "    \n",
    "    '''Save the models'''\n",
    "    torch.save(best_model,'./saved_models/ord/'+logname+'_best')\n",
    "    torch.save(last_model,'./saved_models/ord/'+logname+'_last')\n",
    "    \n",
    "    '''print('Writing results')\n",
    "    write_epochs(result_log, logname)\n",
    "    print('Wrote results')'''\n",
    "    '''Free up the memory'''\n",
    "    del model_ft, result_log\n",
    "    \n",
    "    writer.close\n",
    "    del writer\n",
    "    return last_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''hidden_sizes = [50, 50]\n",
    "dropouts = [0, 0]\n",
    "end_to_end = True\n",
    "run_network()'''\n",
    "print(fvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=1 #Initial learning rate\n",
    "momentum=0.5\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=15 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]\n",
    "dropouts = [0, 0, 0, 0, 0, .5, .5, .5, 0, 0, 0]\n",
    "\n",
    "'''hidden_size = [64, 64, 128, 64, 32]\n",
    "dropouts = [0, 0, 0, 0, 0]'''\n",
    "\n",
    "single_loss=0.\n",
    "multi_loss =1.\n",
    "coeff_lmbda = .1\n",
    "\n",
    "metric = 'ccr1'\n",
    "algo = 'None'\n",
    "for dset_loaders in dset_loaders_arr:\n",
    "    run_network()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numOut = 3\n",
    "numIns = 5\n",
    "\n",
    "log_j_fact = np.log(np.asarray([math.factorial(j) for j in range(numOut)]))\n",
    "ones_vec = Variable(torch.ones(numOut).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "j_vec = Variable(torch.range(0, numOut-1).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "log_j_fact = Variable(torch.from_numpy(log_j_fact).type(torch.FloatTensor).cuda().view(1, numOut))\n",
    "\n",
    "\n",
    "preds = Variable(torch.randn(numIns,1).cuda())\n",
    "softplus_step = torch.nn.Softplus()\n",
    "preds = softplus_step(preds)\n",
    "outputs = torch.mm(preds, ones_vec)\n",
    "outputs = j_vec * torch.log(outputs) - outputs - log_j_fact\n",
    "softmax_step = torch.nn.Softmax(dim=1)\n",
    "outputs_softmax = softmax_step(outputs)\n",
    "print(outputs_softmax.data.cpu().numpy())\n",
    "\n",
    "f = preds.data.cpu().numpy()\n",
    "pos_f = np.zeros((numIns,numOut))\n",
    "\n",
    "log_j = np.asarray([(np.log(math.factorial(k))) for k in range(numOut)]).reshape(numOut,1)\n",
    "for k in range(numOut):\n",
    "    print((k*np.log(f) -f - np.log(math.factorial(k))).shape)\n",
    "    pos_f[:, k] = (k*np.log(f) -f - np.log(math.factorial(k))).reshape(numIns)\n",
    "    \n",
    "soft_pos = np.exp(pos_f)\n",
    "soft_pos = soft_pos/(np.sum(soft_pos, axis=1).reshape(-1,1)*np.ones((1, numOut)))\n",
    "print(soft_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = (np.random.randint(0,5, size = (5,10))>0).astype(np.int)\n",
    "print(preds)\n",
    "print(np.sum(np.cumprod(preds,axis = 1), axis=1)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='sgd' #Optimizer function\n",
    "lr=.01 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=40 #Number of epoch for learning rate decay\n",
    "\n",
    "hidden_sizes = [64, 64, 128, 128, 256, 512, 256, 128, 64, 32, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = [0, 0, .5, .5, .5, .5, .5, .5, .5, 0, 0]#.5, .5, .5]\n",
    "\n",
    "for lr_now in [1, 2, 3]:\n",
    "    lr = lr_now\n",
    "    for kk in range(1):\n",
    "            \n",
    "        algo = 'None'\n",
    "        single_loss=1.\n",
    "        multi_loss =0.\n",
    "        KL = True\n",
    "        metric = 'mae'\n",
    "        \n",
    "        for coeff_now in [0.1*k for k in range(1,10)]:\n",
    "            coeff_lmbda = coeff_now\n",
    "            for dset_loaders in dset_loaders_arr:\n",
    "                run_network()\n",
    "\n",
    "\n",
    "        single_loss=0.\n",
    "        multi_loss =1.\n",
    "        metric = 'mae'\n",
    "        \n",
    "        for coeff_now in [0.1*k for k in range(1,10)]:\n",
    "            coeff_lmbda = coeff_now\n",
    "            for dset_loaders in dset_loaders_arr:\n",
    "                run_network()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end_to_end = True\n",
    "optimizer='adam' #Optimizer function\n",
    "lr=0.05 #Initial learning rate\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler #Learning rate scheduler\n",
    "lr_decay_epoch=10 #Number of epoch for learning rate decay\n",
    "\n",
    "\n",
    "hidden_sizes = [16, 16, 32, 32, 16, 16]#8, 16, 8, 4, 4]\n",
    "dropouts = []#.5, .5, .5]\n",
    "single_loss=1.0\n",
    "multi_loss =0.0\n",
    "\n",
    "KL = True\n",
    "metric = None\n",
    "\n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'ccr1', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "        \n",
    "for lmbda_mae in [.1*k for k in range(11)]:\n",
    "    multi_coeff = lmbda_mae * np.asarray(make_coeff(nclasses, 'mae', coeff_lmbda))\n",
    "    multi_coeff[int((len(multi_coeff)-1)/2)] = 1.\n",
    "    for k in range(10):\n",
    "        run_network()\n",
    "    \n",
    "'''KL = True\n",
    "metric = 'ccr'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'ccr1'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mae'\n",
    "for k in range(10):\n",
    "    run_network()\n",
    "    \n",
    "metric = 'mse'\n",
    "for k in range(10):\n",
    "    run_network()'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader again, this time without shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fvec_norm = (fvec)/5\n",
    "mid_point = int(len(label)/2)#100*num_classes\n",
    "fvec_test = fvec_norm[rand_idx[:mid_point],:]\n",
    "fvec_train = fvec_norm[rand_idx[mid_point:],:]\n",
    "\n",
    "label_test = label[rand_idx[:mid_point]]\n",
    "label_train = label[rand_idx[mid_point:]]\n",
    "print(np.max(fvec_train))\n",
    "print(np.min(fvec_train))\n",
    "\n",
    "torch.from_numpy(label_train).type(torch.LongTensor)\n",
    "dsets={'train': torch.utils.data.TensorDataset(torch.from_numpy(fvec_train).type(torch.FloatTensor),\n",
    "                                               torch.from_numpy(label_train).type(torch.LongTensor)),\n",
    "       'val': torch.utils.data.TensorDataset(torch.from_numpy(fvec_test).type(torch.FloatTensor),\n",
    "                                             torch.from_numpy(label_test).type(torch.LongTensor))}\n",
    "\n",
    "'''Define dataset loaders'''\n",
    "dset_loaders = {'train':torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12),\n",
    "                'val':torch.utils.data.DataLoader(dsets['val'], batch_size=batch_size,shuffle=False,\n",
    "                                                    num_workers=12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_shape = 'Spiral'\n",
    "data_date = '18_01_31'\n",
    "data_dir = './saved_models_github/' + data_shape + '/' + data_date\n",
    "\n",
    "run_dirs = sorted(os.listdir(data_dir))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:110]\n",
    "mae_dirs = last_dirs[110:]\n",
    "all_dirs = [ccr1_dirs, mae_dirs]\n",
    "\n",
    "\n",
    "'''run_dirs = sorted(os.listdir('./saved_models/test'))\n",
    "last_dirs = run_dirs[1::2]\n",
    "ccr1_dirs = last_dirs[:100]\n",
    "mae_dirs = last_dirs[100:]\n",
    "\n",
    "pure_ccr1 = ['Ordinal_January24  14:10:01_last',\n",
    "             'Ordinal_January24  14:11:08_last',\n",
    "             'Ordinal_January24  14:12:14_last',\n",
    "             'Ordinal_January24  14:13:21_last',\n",
    "             'Ordinal_January24  14:14:27_last',\n",
    "             'Ordinal_January24  14:15:34_last',\n",
    "             'Ordinal_January24  14:16:40_last',\n",
    "             'Ordinal_January24  14:17:47_last',\n",
    "             'Ordinal_January24  14:18:54_last',\n",
    "             'Ordinal_January24  14:20:00_last',]\n",
    "\n",
    "pure_mae = ['Ordinal_January24  14:21:07_last',\n",
    "             'Ordinal_January24  14:22:13_last',\n",
    "             'Ordinal_January24  14:23:19_last',\n",
    "             'Ordinal_January24  14:24:26_last',\n",
    "             'Ordinal_January24  14:25:32_last',\n",
    "             'Ordinal_January24  14:26:38_last',\n",
    "             'Ordinal_January24  14:27:45_last',\n",
    "             'Ordinal_January24  14:28:52_last',\n",
    "             'Ordinal_January24  14:29:58_last',\n",
    "             'Ordinal_January24  14:31:05_last',]'''\n",
    "                \n",
    "len(mae_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.load('./saved_models/ord/Ordinal_January24  10:24:20_last', map_location={'cuda:0': 'cpu'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model_dir, phase='train'):\n",
    "    if use_gpu:\n",
    "        model = torch.load(model_dir)\n",
    "    else:\n",
    "        model = torch.load(model_dir, map_location={'cuda:0': 'cpu'})\n",
    "    model.train(False)\n",
    "\n",
    "    labels_arr = np.asarray([]);\n",
    "    preds_arr = np.asarray([]);\n",
    "    for data in dset_loaders[phase]:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = np.argmax(model(inputs).cpu().data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.cpu().data.numpy())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            outputs = np.argmax(model(inputs).data.numpy(), axis=1)\n",
    "            #labels_arr = np.append(labels_arr,labels.data.numpy())\n",
    "          \n",
    "        preds_arr = np.append(preds_arr, outputs)\n",
    "    return preds_arr\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:24:20_last')\n",
    "#print(np.min(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(18,15))\n",
    "\n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+1)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR$ loss' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+6)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[50+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$0.5CCR$ loss + $0.5CCR_1$ loss \\n' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "for k in range(5):\n",
    "    plt.subplot(3,5,k+11)\n",
    "    pred_tr = validate(data_dir + '/' + last_dirs[100+k])\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    #plt.scatter(fvec_train[:, 0], fvec_train[:, 1], c=label_train,vmin=-1, vmax=num_classes)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    plt.title('$CCR_1$ loss ' + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)))\n",
    "    \n",
    "plt.savefig('variance_of_results.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_and_mean(root_dir, sub_dirs, phase='train'):\n",
    "    scores_arr = np.zeros((label_train.shape[0],9))\n",
    "    for sub_dir in sub_dirs:\n",
    "        if use_gpu:\n",
    "            model = torch.load(root_dir + '/' + sub_dir)\n",
    "        else:\n",
    "            model = torch.load(root_dir + '/' + sub_dir, map_location={'cuda:0': 'cpu'})\n",
    "        model.train(False)\n",
    "        #print(model)\n",
    "        score_arr = np.zeros((1,9))\n",
    "        for data in dset_loaders[phase]:\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                outputs = model(inputs).cpu().data.numpy()\n",
    "                #print(outputs.shape)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                outputs = model(inputs).data.numpy()\n",
    "                \n",
    "            score_arr = np.append(score_arr, outputs, axis=0)\n",
    "        scores_arr += score_arr[1:,:]\n",
    "        \n",
    "    return scores_arr\n",
    "#scores_tr = validate_and_mean('./saved_models/test_circular', last_dirs[:10])\n",
    "#pred_tr = np.argmax(scores_tr, axis=1)\n",
    "#print(np.mean(label_train == pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dirs = ['./saved_models/ord/Ordinal_January24  10:16:00_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:20:35_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:24:20_last',\n",
    "             './saved_models/ord/Ordinal_January24  10:28:03_last']\n",
    "\n",
    "'''model_dirs = ['./saved_models/ord/Ordinal_January24  13:09:17_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:18:08_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:27:43_last',\n",
    "             './saved_models/ord/Ordinal_January24  13:43:43_last']'''\n",
    "\n",
    "model_dirs = ['./saved_models/ord/Ordinal_January26  00:22:14_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:19:20_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:09:08_last',\n",
    "              './saved_models/ord/Ordinal_January26  00:17:53_last']\n",
    "preds = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    preds.append(validate(model_dir))\n",
    "    \n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'CCR1'\n",
    "\n",
    "if metric is 'CCR1':\n",
    "    metric_code = 0\n",
    "elif metric is 'MAE':\n",
    "    metric_code = 1\n",
    "else:\n",
    "    print('Wrong metric')\n",
    "    \n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "metrics = np.zeros((11, 4))\n",
    "for k in range(10):\n",
    "    scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][k*10:(k+1)*10])\n",
    "    pred_tr = np.argmax(scores_tr, axis=1)\n",
    "    plt.subplot(4,3,k+2)\n",
    "    plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "    plt.colorbar()\n",
    "    ccr = np.mean(pred_tr==label_train)\n",
    "    ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "    mae = np.mean(np.abs(pred_tr-label_train))\n",
    "    rmse = np.mean((pred_tr-label_train)**2)\n",
    "    metrics[k,:] = [ccr,ccr1,mae,rmse]\n",
    "    plt.title('$\\lambda$=' + str(np.round(k*.1, decimals=1)) + \n",
    "              ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "              ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "              ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "              ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "    \n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  10:20:35_last')\n",
    "#pred_tr = validate('./saved_models/ord/Ordinal_January24  13:18:08_last')\n",
    "\n",
    "scores_tr = validate_and_mean(data_dir, all_dirs[metric_code][100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(4,3,12)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "metrics[10,:] = [ccr,ccr1,mae,rmse]\n",
    "plt.title('$\\lambda$=1.0' + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ', $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt_title = data_shape + '_Data_CCR_' + metric + '_tradeoff_' + data_date + '.tiff'\n",
    "plt.savefig(plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "\n",
    "lmbdas = [.1*k for k in range(11)]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.plot(lmbdas, metrics[:,0], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR$')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lmbdas, metrics[:,1], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$CCR_1$')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lmbdas, metrics[:,2], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$MAE$')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lmbdas, metrics[:,3], 'o-')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$RMSE$')\n",
    "\n",
    "plt.savefig('spiral_plots_ccr1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$CCR_1 loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n $MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/ord', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=pred_tr, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "ccr = np.mean(pred_tr==label_train)\n",
    "ccr1 = np.mean(np.abs(pred_tr-label_train)<=1)\n",
    "mae = np.mean(np.abs(pred_tr-label_train))\n",
    "rmse = np.mean((pred_tr-label_train)**2)\n",
    "plt.title('$MAE loss$'  + \n",
    "          ', $CCR$=' + str(np.round(ccr, decimals = 2)) +\n",
    "          ', $CCR_1$=' + str(np.round(ccr1, decimals = 2)) +\n",
    "          ',\\n$MAE$=' + str(np.round(mae, decimals = 2)) +\n",
    "          ', $RMSE$=' + str(np.round(rmse, decimals = 2)))\n",
    "\n",
    "plt.savefig('spiral_extreme.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(fvec_train[:, 0], fvec_train[:, 1], s=15, c=label_train, cmap = plt.get_cmap('Set1'),vmin=0, vmax=num_classes-1)\n",
    "plt.colorbar()\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[:10])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', ccr1_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$CCR_1$ loss')\n",
    "\n",
    "scores_tr = validate_and_mean('./saved_models/test_circular', mae_dirs[100:])\n",
    "pred_tr = np.argmax(scores_tr, axis=1)\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(pred_tr-label_train, bins = np.arange(-4.5,5.5,1))\n",
    "plt.title('$MAE$ loss')\n",
    "\n",
    "plt.savefig('circular_extreme_hist.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.subplot(211)\n",
    "img = mpimg.imread('Circular_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)\n",
    "plt.subplot(212)\n",
    "img = mpimg.imread('Spiral_Data_Extreme_Weights.eps')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
